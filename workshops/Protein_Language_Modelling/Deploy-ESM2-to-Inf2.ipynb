{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ab7591-1443-4854-881a-f0d37a7ad1d6",
   "metadata": {},
   "source": [
    "# Deploy pre-trained ESM-2 model to Inferentia2\n",
    "\n",
    "Note: This notebook was last tested in SageMaker Studio on the PyTorch 1.13 Python 3.9 CPU Optimized image on a ml.c5.4xlarge instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f5ab1-119a-482d-9377-84cc8088fec9",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Install neuronx and dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef07df43-b111-4625-87ff-3519e351b5ff",
   "metadata": {},
   "source": [
    "Install the neuronx compiler. NOTE: You will need to restart your notebook kernel after running this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b670bb6-2414-4b1a-81fa-213e21945c13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "apt-get update -y\n",
    "apt-get install gpg-agent -y\n",
    "wget -qO - https://apt.repos.neuron.amazonaws.com/GPG-PUB-KEY-AMAZON-AWS-NEURON.PUB | apt-key add -\n",
    "add-apt-repository https://apt.repos.neuron.amazonaws.com\n",
    "apt-get update -y\n",
    "apt-get install aws-neuronx-dkms=2.* aws-neuronx-collectives=2.* aws-neuronx-runtime-lib=2.* aws-neuronx-tools=2.* -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981be8bf-4e67-40fd-a900-6e6319ec1227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -q --upgrade pip\n",
    "%pip install -q --upgrade --extra-index-url https://pip.repos.neuron.amazonaws.com \\\n",
    "  neuronx-cc==2.* torch-neuronx torch sagemaker boto3 awscli transformers accelerate boto3 --no-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc16165-cb4b-4c31-a279-0e13f31d6552",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 2. Compile pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfdde14f-e621-4d0c-9a5c-267945b2c353",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForMaskedLM were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['lm_head.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model inference\n",
      "tensor([[[ 12.4939,  -7.4286,  -6.1493,  ..., -15.5151, -15.7623,  -7.3883],\n",
      "         [ -7.1894, -15.7947,  -7.4696,  ..., -15.7256, -15.9145, -15.7955],\n",
      "         [-10.4963, -17.5363, -10.8571,  ..., -16.3073, -16.2947, -17.5346],\n",
      "         ...,\n",
      "         [-10.6348, -18.9364,  -9.7578,  ..., -16.1243, -16.1494, -18.9432],\n",
      "         [-10.5313, -18.7101,  -9.6842,  ..., -16.1191, -16.1363, -18.7131],\n",
      "         [-10.5828, -18.6295,  -9.8384,  ..., -16.1243, -16.1400, -18.6290]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Beginning model trace\n",
      "Model trace completed in 39.0 seconds.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_neuronx\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "MODEL_ID=\"facebook/esm2_t6_8M_UR50D\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForMaskedLM.from_pretrained(MODEL_ID, torchscript=True)\n",
    "model.eval()\n",
    "\n",
    "sequence = (\n",
    "    \"QVQLVESGGGVVQPRSLTLSCAASGFTFSSYGL<mask>HWVRQAPGKGLEWVANIWYDGANKYYGDSVKGRFTISRDNSRNTLYLQMNSLTAEDTAVYYCARWIEYGSGKDAFDVWGQGTMVIVSS\"\n",
    ")\n",
    "max_length = 128\n",
    "tokenized_sequence = tokenizer.encode_plus(\n",
    "    sequence,\n",
    "    max_length=max_length,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "tracing_input = tokenized_sequence[\"input_ids\"], tokenized_sequence[\"attention_mask\"]\n",
    "\n",
    "print(\"Testing model inference\")\n",
    "print(model(*tracing_input)[0])\n",
    "\n",
    "\n",
    "print(\"Beginning model trace\")\n",
    "model_trace_start_time = timer()\n",
    "neuron_model = torch_neuronx.trace(model, tracing_input)\n",
    "neuron_model.save(\"traced_esm.pt\")\n",
    "print(\n",
    "    f\"Model trace completed in {round(timer() - model_trace_start_time, 0)} seconds.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f428b1f3-5b74-49fe-aa01-b2ce38d538b5",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Assemble model package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ae7cfaf-e7fb-4910-b3e2-6c21813d6560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traced_esm.pt\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf model.tar.gz traced_esm.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92364e-2aab-4a01-b917-2a83fefbc1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "sagemaker_execution_role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "print(f\"Assumed SageMaker role is {sagemaker_execution_role}\")\n",
    "\n",
    "S3_PREFIX = \"compiled-model\"\n",
    "S3_PATH = sagemaker.s3.s3_path_join(\"s3://\", S3_BUCKET, S3_PREFIX)\n",
    "print(f\"S3 path is {S3_PATH}\")\n",
    "\n",
    "s3_model_uri = sagemaker_session.upload_data(\"model.tar.gz\", S3_BUCKET, S3_PREFIX)\n",
    "print(f\"Model artifact uploaded to {s3_model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c91e85-e9d9-465c-9681-eb9d1797dca3",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Define inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dca6f59-d163-404d-961a-ad56e21b5741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/inference/inf2/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/inference/requirements.txt\n",
    "\n",
    "transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ff1e5c6-b9fa-4780-943f-3a0ff58b77ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/inference/inf2/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/inference/inference.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch_neuronx\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "JSON_CONTENT_TYPE = \"application/json\"\n",
    "MODEL_ID = \"facebook/esm2_t6_8M_UR50D\"\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Load the model from HuggingFace\"\"\"\n",
    "    tokenizer_init = AutoTokenizer.from_pretrained(MODEL_ID, device_map=\"auto\")\n",
    "    model_file = os.path.join(model_dir, \"traced_esm.pt\")\n",
    "    neuron_model = torch.jit.load(model_file)\n",
    "    return (neuron_model, tokenizer_init)\n",
    "\n",
    "\n",
    "def input_fn(serialized_input_data, content_type=JSON_CONTENT_TYPE):\n",
    "    \"\"\"Process the request payload\"\"\"\n",
    "\n",
    "    if content_type == JSON_CONTENT_TYPE:\n",
    "        input_data = json.loads(serialized_input_data)\n",
    "        return input_data\n",
    "    else:\n",
    "        raise Exception(\"Requested unsupported ContentType in Accept: \" + content_type)\n",
    "        return\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model_and_tokenizer):\n",
    "    \"\"\"Run model inference\"\"\"\n",
    "\n",
    "    model, tokenizer = model_and_tokenizer\n",
    "    max_length = 128\n",
    "    tokenized_sequence = tokenizer.encode_plus(\n",
    "        input_data,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    prediction_input = (\n",
    "        tokenized_sequence[\"input_ids\"],\n",
    "        tokenized_sequence[\"attention_mask\"],\n",
    "    )\n",
    "    output = model(*prediction_input)[0]\n",
    "    mask_token_index = (tokenized_sequence.input_ids == tokenizer.mask_token_id)[\n",
    "        0\n",
    "    ].nonzero(as_tuple=True)[0]\n",
    "    mask_index_predictions = output[0, mask_token_index]\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(mask_index_predictions)\n",
    "    return {\n",
    "        list(tokenizer.get_vocab().keys())[idx]: round(v.item(), 3)\n",
    "        for idx, v in enumerate(probs[0])\n",
    "    }\n",
    "\n",
    "\n",
    "def output_fn(prediction_output, accept=JSON_CONTENT_TYPE):\n",
    "    \"\"\"Process the response payload\"\"\"\n",
    "    if accept == JSON_CONTENT_TYPE:\n",
    "        return json.dumps(prediction_output), accept\n",
    "\n",
    "    raise Exception(\"Requested unsupported ContentType in Accept: \" + accept)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821c118-fe6b-45f1-903d-c90eaae929fd",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Deploy model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "328baaf5-28ff-42f3-8a2e-f8d576179c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "ecr_image = f\"763104351884.dkr.ecr.{sagemaker_session.boto_region_name}.amazonaws.com/pytorch-inference-neuronx:1.13.0-neuronx-py38-sdk2.9.0-ubuntu20.04\"\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=s3_model_uri,\n",
    "    role=sagemaker_execution_role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    source_dir=\"scripts/inference\",\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=ecr_image,\n",
    ")\n",
    "\n",
    "# Let SageMaker know that we've already compiled the model via neuron-cc\n",
    "pytorch_model._is_compiled_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9ee9841-f510-4186-a362-92ff9f24848c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!CPU times: user 727 ms, sys: 66.7 ms, total: 794 ms\n",
      "Wall time: 10min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = pytorch_model.deploy(\n",
    "    instance_type=\"ml.inf2.xlarge\", initial_instance_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11c23e55-c855-4f49-8ca9-d980e8c72a12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<cls>': 0.0,\n",
       " '<pad>': 0.0,\n",
       " '<eos>': 0.0,\n",
       " '<unk>': 0.0,\n",
       " 'L': 0.746,\n",
       " 'A': 0.83,\n",
       " 'G': 0.73,\n",
       " 'V': 0.764,\n",
       " 'S': 0.672,\n",
       " 'E': 0.809,\n",
       " 'R': 0.711,\n",
       " 'T': 0.618,\n",
       " 'I': 0.362,\n",
       " 'D': 0.546,\n",
       " 'P': 0.757,\n",
       " 'K': 0.531,\n",
       " 'Q': 0.731,\n",
       " 'N': 0.355,\n",
       " 'F': 0.354,\n",
       " 'Y': 0.28,\n",
       " 'M': 0.324,\n",
       " 'H': 0.422,\n",
       " 'W': 0.216,\n",
       " 'C': 0.18,\n",
       " 'X': 0.015,\n",
       " 'B': 0.0,\n",
       " 'U': 0.0,\n",
       " 'Z': 0.0,\n",
       " 'O': 0.0,\n",
       " '.': 0.0,\n",
       " '-': 0.0,\n",
       " '<null_1>': 0.0,\n",
       " '<mask>': 0.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()\n",
    "\n",
    "test_seq = \"QVQLVESGGGVVQ<mask>PGRSLTLSCAASGFTFSSYGLHWVRQAPGKGLE\"\n",
    "predictor.predict(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107bb09b-23a4-4837-8288-87803fddf8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    predictor.delete_endpoint()\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.c5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.13-cpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
