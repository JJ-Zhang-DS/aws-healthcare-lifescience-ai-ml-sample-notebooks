{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6e243f-a130-46b9-8f7a-0205c6886e70",
   "metadata": {},
   "source": [
    "# Pretraining Protein Language Models on UniRef Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2755ba40-e905-4b29-b3a7-6d19458d5889",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e6acb7-e78c-4ce3-a0ae-0a7fe440d392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "REGION_NAME = sagemaker_session.boto_region_name\n",
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "S3_PREFIX = \"plm-pretraining\"\n",
    "S3_FOLDER = sagemaker.s3.s3_path_join(\"s3://\", S3_BUCKET, S3_PREFIX)\n",
    "print(f\"S3 uri is {S3_FOLDER}\")\n",
    "\n",
    "EXPERIMENT_NAME = \"plm-pretraining\"\n",
    "\n",
    "SAGEMAKER_EXECUTION_ROLE = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "print(f\"Assumed SageMaker role is {SAGEMAKER_EXECUTION_ROLE}\")\n",
    "\n",
    "RAW_DATA_URI = os.path.join(S3_FOLDER, \"data\", \"raw\")\n",
    "print(f\"Raw data uri is {RAW_DATA_URI}\")\n",
    "\n",
    "PROCESSED_DATA_URI = os.path.join(S3_FOLDER, \"data\", \"processed\")\n",
    "print(f\"Processed data uri is {PROCESSED_DATA_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e11905-1cd4-4e9d-828a-233f6901887e",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3609b7d1-d703-44b3-9001-cf9adb96321f",
   "metadata": {},
   "source": [
    "## 2.1. Download UniRef50 FASTA File and Convert to Partitioned CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66c5b8-1b3f-4f2a-a3e2-7cb548a65ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "from sagemaker.processing import ProcessingOutput\n",
    "\n",
    "processor = PyTorchProcessor(\n",
    "    base_job_name=\"fasta-processing\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    framework_version=\"2.0.0\",\n",
    "    py_version=\"py310\",\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "processor.run(\n",
    "    arguments=[\n",
    "        \"--source\",\n",
    "        \"https://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref50/uniref50.fasta.gz\",\n",
    "        \"--output_dir\",\n",
    "        \"/opt/ml/processing/output\",\n",
    "        \"--max_records_per_partition\",\n",
    "        \"500000\",\n",
    "    ],\n",
    "    code=\"fasta_to_csv.py\",\n",
    "    source_dir=\"scripts/processing\",\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/output\",  # When the job finishes, SageMaker will copy data from here...\n",
    "            destination=RAW_DATA_URI,  # ...to here\n",
    "        )\n",
    "    ],\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4784b96-86c1-4597-b3d4-28908f72ce65",
   "metadata": {},
   "source": [
    "## 2.2. Convert CSVs to HuggingFace Dataset and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275c864-f12e-433b-b95c-03d1e365a437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "\n",
    "processor = PyTorchProcessor(\n",
    "    base_job_name=\"hf-tokenization\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.9xlarge\",\n",
    "    framework_version=\"2.0.0\",\n",
    "    py_version=\"py310\",\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    volume_size_in_gb=512,\n",
    ")\n",
    "\n",
    "processor.run(\n",
    "    arguments=[\n",
    "        \"--tokenizer_name\",\n",
    "        \"facebook/esm2_t30_150M_UR50D\",\n",
    "        \"--max_seq_length\",\n",
    "        \"512\",\n",
    "        \"--preprocessing_num_workers\",\n",
    "        \"24\",\n",
    "        \"--line_by_line\",\n",
    "        \"True\",\n",
    "        \"--train_size\",\n",
    "        \"10000000\",\n",
    "        \"--validation_size\",\n",
    "        \"50000\",\n",
    "        \"--test_size\",\n",
    "        \"50000\",\n",
    "    ],\n",
    "    code=\"tokenize_uniref_csv.py\",\n",
    "    source_dir=\"scripts/processing\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=os.path.join(\n",
    "                RAW_DATA_URI, \"csv\"\n",
    "            ),  # When the job starts, SageMaker will copy data from here...\n",
    "            destination=\"/opt/ml/processing/input\",  # ...to here\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/output\",  # When the job finishes, SageMaker will copy data from here...\n",
    "            destination=PROCESSED_DATA_URI,  # ...to here\n",
    "        )\n",
    "    ],\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3114c4d4-833c-4ec0-b4ce-4f35a4d3dc01",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa116c8-1e42-4e86-96f5-b2ddfc825066",
   "metadata": {},
   "source": [
    "### 3.1. CUDA on ml.p4d.24xlarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848a877-422c-4a5d-9384-9dfe9bbbaaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {\"Name\": \"TrainingLoss\", \"Regex\": \"'loss': ([0-9.]+)\"},\n",
    "    {\"Name\": \"Epoch\", \"Regex\": \"'epoch': ([0-9.]+)\"},\n",
    "    {\"Name\": \"TrainingRuntime\", \"Regex\": \"'train_runtime': ([0-9.]+)\"},\n",
    "    {\n",
    "        \"Name\": \"TrainingSamplesPerSecond\",\n",
    "        \"Regex\": \"'train_samples_per_second': ([0-9.]+)\",\n",
    "    },\n",
    "    {\"Name\": \"TrainingStepsPerSecond\", \"Regex\": \"'train_steps_per_second': ([0-9.]+)\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65411da-3b68-40c5-8da5-1e5e51a12809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "hyperparameters = {\n",
    "    \"bf16\": True,\n",
    "    \"config_name\": \"facebook/esm2_t30_150M_UR50D\",\n",
    "    \"dataloader_num_workers\": 8,\n",
    "    \"do_eval\": True,\n",
    "    \"do_preprocess\": False,\n",
    "    \"do_train\": True,\n",
    "    \"gradient_accumulation_steps\": 16,\n",
    "    \"logging_steps\": 16,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"output_dir\": \"/opt/ml/model\",\n",
    "    \"per_device_train_batch_size\": 24,\n",
    "    \"tokenizer_name\": \"facebook/esm2_t30_150M_UR50D\",\n",
    "    \"dataset_dir\": \"/opt/ml/input/data/training\",\n",
    "    \"torch_compile\": True,\n",
    "    \"pad_to_max_length\": True,\n",
    "    \"max_seq_length\": 512\n",
    "}\n",
    "\n",
    "p4_estimator = HuggingFace(\n",
    "    base_job_name=\"p4-plm-training\",\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    entry_point=\"run_mlm.py\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    metric_definitions=metric_definitions,\n",
    "    pytorch_version=\"2.0.0\",\n",
    "    py_version=\"py310\",\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    source_dir=\"scripts/training/cuda\",\n",
    "    transformers_version=\"4.28.1\",\n",
    ")\n",
    "\n",
    "with Run(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    p4_estimator.fit(\n",
    "        {\n",
    "            \"training\": TrainingInput(\n",
    "                s3_data=os.path.join(PROCESSED_DATA_URI, \"arrow\"), input_mode=\"File\"\n",
    "            ),\n",
    "        },\n",
    "        wait=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613441f-3d4b-4c8d-8f06-8754d38a82d2",
   "metadata": {},
   "source": [
    "### 4.3 Torch-NeuronX on ml.trn1.32xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90daf9cb",
   "metadata": {},
   "source": [
    "(Optional) Pre-compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "NEURON_CACHE = os.path.join(S3_FOLDER, \"parallel-neuron-cache\")\n",
    "IMAGE_URI = f\"763104351884.dkr.ecr.{REGION_NAME}.amazonaws.com/huggingface-pytorch-training-neuronx:1.13.1-transformers4.34.1-neuronx-py310-sdk2.15.0-ubuntu20.04\"\n",
    "MODEL_ID = \"facebook/esm2_t30_150M_UR50D\"\n",
    "\n",
    "hyperparameters = {\n",
    "    \"data_dir\": \"/opt/ml/input/data/training\",\n",
    "    \"gradient_accumulation_steps\": 8,\n",
    "    \"logging_steps\": 16,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"steps_this_run\": 64,\n",
    "    \"optim\": \"adamw_torch\",\n",
    "    \"per_device_train_batch_size\": 6,\n",
    "}\n",
    "\n",
    "trn1_estimator = PyTorch(\n",
    "    base_job_name=\"trn1-plm-precompilation\",\n",
    "    entry_point=\"torch_xla_train.py\",\n",
    "    source_dir=\"scripts/training/neuron\",\n",
    "    instance_type=\"ml.trn1.32xlarge\",\n",
    "    instance_count=1,\n",
    "    image_uri=IMAGE_URI,\n",
    "    output_path=f\"{S3_FOLDER}/output\",\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    hyperparameters=hyperparameters,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    environment={\n",
    "        \"NEURON_COMPILE_CACHE_URL\": NEURON_CACHE,\n",
    "        \"XLA_USE_BF16\": \"1\",\n",
    "        \"RUN_NEURON_PARALLEL_COMPILE\": \"1\",\n",
    "    },\n",
    "    tags=[{\"Key\": \"project\", \"Value\": \"esm-benchmarking\"}],\n",
    ")\n",
    "\n",
    "\n",
    "trn1_estimator.fit(\n",
    "    {\n",
    "        \"training\": TrainingInput(\n",
    "            s3_data=os.path.join(PROCESSED_DATA_URI, \"arrow\"), input_mode=\"File\"\n",
    "        ),\n",
    "    },\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada22b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"Epoch: (.*?),\"},\n",
    "    {\"Name\": \"step\", \"Regex\": \"Step: (.*?),\"},\n",
    "    {\"Name\": \"train_loss\", \"Regex\": \"Training Loss: (.*?),\"},\n",
    "    {\"Name\": \"train_perplexity\", \"Regex\": \"Training Perplexity: (.*?),\"},\n",
    "    {\n",
    "        \"Name\": \"train_samples_per_sec\",\n",
    "        \"Regex\": \"Training Samples/sec: (.*?),\",\n",
    "    },\n",
    "    {\"Name\": \"train_tokens_per_sec\", \"Regex\": \"Training Tokens/sec: (.*?)$\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8eec5a-b8d2-4dbb-a5e3-a82b828578d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "NEURON_CACHE = os.path.join(S3_FOLDER, \"parallel-neuron-cache\")\n",
    "IMAGE_URI = f\"763104351884.dkr.ecr.{REGION_NAME}.amazonaws.com/huggingface-pytorch-training-neuronx:1.13.1-transformers4.34.1-neuronx-py310-sdk2.15.0-ubuntu20.04\"\n",
    "MODEL_ID=\"facebook/esm2_t30_150M_UR50D\"\n",
    "\n",
    "hyperparameters = {\n",
    "    \"data_dir\": \"/opt/ml/input/data/training\",\n",
    "    \"gradient_accumulation_steps\": 8,\n",
    "    \"logging_steps\": 16,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"optim\": \"adamw_torch\",\n",
    "    \"per_device_train_batch_size\": 6,\n",
    "}\n",
    "\n",
    "trn1_estimator = PyTorch(\n",
    "    base_job_name=\"trn1-plm-training\",\n",
    "    entry_point=\"torch_xla_train.py\",\n",
    "    source_dir=\"scripts/training/neuron\",\n",
    "    instance_type=\"ml.trn1.32xlarge\",\n",
    "    instance_count=1,\n",
    "    image_uri=IMAGE_URI,\n",
    "    output_path=f\"{S3_FOLDER}/output\",\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    checkpoint_local_path=\"/opt/ml/checkpoints\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    environment={\n",
    "        \"NEURON_COMPILE_CACHE_URL\": NEURON_CACHE,\n",
    "        \"XLA_USE_BF16\": \"1\",\n",
    "    },\n",
    "    tags=[{\"Key\": \"project\", \"Value\": \"esm-benchmarking\"}],\n",
    ")\n",
    "\n",
    "with Run(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    trn1_estimator.fit(\n",
    "        {\n",
    "            \"training\": TrainingInput(s3_data=os.path.join(PROCESSED_DATA_URI,\"arrow\"), input_mode=\"File\"),\n",
    "        },\n",
    "        wait=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcfc145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
