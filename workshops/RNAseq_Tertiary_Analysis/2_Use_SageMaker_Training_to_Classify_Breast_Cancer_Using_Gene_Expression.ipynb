{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Breast Cancer Classification using Gene Expression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Use SageMaker processing, training, and hyperparameter tuning jobs to optimize cost and performance\n",
    "- Compare model performance using SageMaker Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Notes:\n",
    "This notebook was created and tested on an `ml.t3.medium (2 vCPU + 4 GiB)` notebook instance running the `Python 3 (Data Science)` kernel in SageMaker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Background](#1.-Background)\n",
    "    1. [Jobs](#1.A.-Jobs)\n",
    "    1. [Experiments](#1.B.-Experiments)\n",
    "1. [Preparation](#2.-Preparation)\n",
    "    1. [Import Python libraries](#2.A.-Import-Python-Libraries)\n",
    "    1. [Create Some Necessary Clients](#2.B.-Create-some-necessary-clients)\n",
    "    1. [Create an Experiment](#2.C.-Create-an-experiment)\n",
    "    1. [Specify S3 Bucket and Prefix](#2.D.-Specify-S3-bucket-and-prefix)\n",
    "    1. [Define Local Working Directories](#2.E.-Define-local-working-directories)\n",
    "1. [Data Preparation with Amazon SageMaker Processing](#3.-Data-Preparation-with-Amazon-SageMaker-Processing)\n",
    "    1. [Upload Raw Data to S3](#3.A.-Upload-Raw-Data-to-S3)\n",
    "    1. [Create SageMaker Processing Job Script](#3.B.-Create-SageMaker-Processing-Job-Script)\n",
    "    1. [Submit SageMaker Processing Job](#3.C.-Submit-SageMaker-Processing-Job)\n",
    "1. [Model Training](#4.-Model-Training)\n",
    "    1. [Train Model Using a SKLearn Random Forest Algorithm](#4.A.-Train-Model-Using-a-SKLearn-Random-Forest-Algorithm)\n",
    "    1. [Train Model using a Keras MLP](#4.B.-Train-Model-using-a-Keras-MLP)\n",
    "    1. [Train Model Using the XGBoost Algorithm](#4.C.-Train-Model-Using-the-XGBoost-Algorithm)\n",
    "1. [Model Evaluation](#5.-Model-Evaluation)\n",
    "    1. [Download and Run the Trained XGBoost Model](#5.A.-Download-and-Run-the-Trained-XGBoost-Model)\n",
    "    1. [Compare Model Results Using SageMaker Experiments](#5.B.-Compare-Model-Results-Using-SageMaker-Experiments)\n",
    "1. [Hyperparameter Optimization](#6.-Hyperparameter-Optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Background\n",
    "In notebook 1 of this series, we demonstrated using RNAseq data to predict HER2 status using the compute resources on the notebook server. However, using notebook server resources to process large amounts of data or train complex models is generally not a good idea. It's possible to scale up your notebook server, but any time you spend on non-compute intensive tasks (i.e. most of your time) will be wasted. A better idea is to run your notebook on a small server and submit compute-intensive tasks to independent jobs. SageMaker provides managed services for running data processing, model training, and hyperparameter tuning jobs. In this notebook, we'll demonstrate how to leverage these services to optimize the performance and cost of our tasks.\n",
    "\n",
    "Specifically, we'll demonstrate two best practices: Experiments and Jobs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.A. SageMaker Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html) processing, training, and tuning jobs allow data scientists to submit compute-heavy processes to external services. This keeps costs optimized and ensures that these tasks run in reproducible environments. It also improves data scientist productivity by allowing these jobs to run in \"the background\" and provides resiliancy if something happens to your notebook environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/jobs.png \"Jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.B. SageMaker Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/experiments.png \"Experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SageMaker Experiments](https://aws.amazon.com/blogs/aws/amazon-sagemaker-experiments-organize-track-and-compare-your-machine-learning-trainings) make it as easy as possible to track data preparation and analysis steps. Organizing your ML project into experiments helps you manage large numbers of trials and alternative algorithms. Experiments also ensure that any artifacts your generate for production use can be traced back to their source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The Python libraries that we'll use throughout the analysis\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.A. Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Collecting sagemaker-experiments\n",
      "  Using cached sagemaker_experiments-0.1.35-py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /root/.local/lib/python3.7/site-packages (from sagemaker-experiments) (1.20.43)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.43 in /root/.local/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.23.43)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /root/.local/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /root/.local/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.43->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /root/.local/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.43->boto3>=1.16.27->sagemaker-experiments) (1.26.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.43->boto3>=1.16.27->sagemaker-experiments) (1.14.0)\n",
      "Installing collected packages: sagemaker-experiments\n",
      "Successfully installed sagemaker-experiments-0.1.35\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker-experiments\n",
    "# !pip install xgboost==1.2.0 #this needs this specific version of xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29' not found (required by /root/.local/lib/python3.7/site-packages/pandas/_libs/window/aggregations.cpython-37m-x86_64-linux-gnu.so)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b6cd8a42e536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstrftime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m from pandas.core.api import (\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;31m# dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mInt8Dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m from pandas.core.groupby import (\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mGrouper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/groupby/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.core.groupby.generic import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mNamedAgg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_series_with_explicit_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    127\u001b[0m )\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m from pandas.core import (\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0malgorithms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_docs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_shared_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_indexer_indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m from pandas.core.window import (\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mExpanding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mExponentialMovingWindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/window/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.core.window.ewm import (  # noqa:F401\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mExponentialMovingWindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mExponentialMovingWindowGroupby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m from pandas.core.window.expanding import (  # noqa:F401\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/window/ewm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtslibs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwindow_aggregations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m from pandas._typing import (\n\u001b[1;32m     13\u001b[0m     \u001b[0mAxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.29' not found (required by /root/.local/lib/python3.7/site-packages/pandas/_libs/window/aggregations.cpython-37m-x86_64-linux-gnu.so)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from time import strftime\n",
    "from botocore.client import ClientError\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, session\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.analytics import ExperimentAnalytics, TrainingJobAnalytics\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.B. Create Some Necessary Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "sm_session = sagemaker.session.Session()\n",
    "region = session.region_name\n",
    "role = get_execution_role()\n",
    "s3 = boto3.client('s3', region_name=region)\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.C. Create an Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new SageMaker experiment specific to our scientific goal, in this case to predict HER2 status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_date = strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "brca_her2_experiment = Experiment.create(experiment_name = f\"BRCA-HER2-{create_date}\",\n",
    "                                    description = \"Predict HER2 status using TCGA RNAseq data.\",\n",
    "                                    tags = [{'Key': 'Creator', 'Value': 'bloyal'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.D. Specify S3 Bucket and Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 Buckets for this project\n",
    "bucket_name = f\"brca-her2-classifier-{account_id}\"\n",
    "print(f\"S3 bucket name is {bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.E. Define Local Working Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(WORKING_DIR, \"data\")\n",
    "print(f\"Working directory is {WORKING_DIR}\")\n",
    "print(f\"Data directory is {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation  with Amazon SageMaker Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Processing allows you to run steps for data pre- or post-processing, feature engineering, data validation, or model evaluation workloads on Amazon SageMaker. Processing jobs accept data from Amazon S3 as input and store data into Amazon S3 as output.\n",
    "\n",
    "![processing](https://sagemaker.readthedocs.io/en/stable/_images/amazon_sagemaker_processing_image1.png)\n",
    "\n",
    "Here, we'll import the dataset and transform it with SageMaker Processing, which can be used to process terabytes of data in a SageMaker-managed cluster separate from the instance running your notebook server. In a typical SageMaker workflow, notebooks are only used for prototyping and can be run on relatively inexpensive and less powerful instances, while processing, training and model hosting tasks are run on separate, more powerful SageMaker-managed instances.  SageMaker Processing includes off-the-shelf support for Scikit-learn, as well as a Bring Your Own Container option, so it can be used with many different data transformation technologies and tasks.    \n",
    "\n",
    "To use SageMaker Processing, simply supply a Python data preprocessing script as shown below.  For this example, we're using a SageMaker prebuilt Scikit-learn container, which includes many common functions for processing data.  There are few limitations on what kinds of code and operations you can run, and only a minimal contract:  input and output data must be placed in specified directories.  If this is done, SageMaker Processing automatically loads the input data from S3 and uploads transformed data back to S3 when the job is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.A. Upload Raw Data to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directories\n",
    "WORKING_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(WORKING_DIR, \"data\")\n",
    "print(f\"Working directory is {WORKING_DIR}\")\n",
    "print(f\"Data directory is {DATA_DIR}\")\n",
    "\n",
    "# Get TCGA BRCA Gene Expression Data\n",
    "!wget https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/HiSeqV2_PANCAN.gz -nc -P $DATA_DIR/input/raw/\n",
    "!gzip -df $DATA_DIR/input/raw/HiSeqV2_PANCAN.gz\n",
    "\n",
    "# Get TCGA BRCA Phenotype Data\n",
    "!wget https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/BRCA_clinicalMatrix -nc -P $DATA_DIR/input/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if bucket already exists. If it does not, create it\n",
    "try:\n",
    "    s3.head_bucket(Bucket=bucket_name)\n",
    "except ClientError:\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "    print(f\"Created Bucket: {bucket_name} in Region: {region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_source = sm_session.upload_data(f\"{DATA_DIR}/input/raw/BRCA_clinicalMatrix\", bucket=bucket_name, key_prefix='data/input')\n",
    "RNAseq_source = sm_session.upload_data(f\"{DATA_DIR}/input/raw/HiSeqV2_PANCAN\", bucket=bucket_name, key_prefix='data/input')\n",
    "print(f\"Clinical phenotypes now available at {clinical_source}\")\n",
    "print(f\"Normalized expression data now available at {RNAseq_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.B. Create SageMaker Processing Job Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder for processing script\n",
    "os.makedirs(os.path.join(WORKING_DIR,\"scripts/processing\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the script we want our processing job to use. Note that because this is run on a remote service, we don't need to install any of the dependencies locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/processing/processing.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def _parse_args():\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--train_test_split_ratio', type=float, default=0.2)\n",
    "    parser.add_argument('--local_path', type=str, default=\"/opt/ml/processing\")\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        \n",
    "    ### Command line parser\n",
    "    args, _ = _parse_args()\n",
    "\n",
    "    DATA_DIR = os.path.join(args.local_path, \"input\")\n",
    "    print(f\"Data directory is {DATA_DIR}\")\n",
    "    \n",
    "    ### Load Gene Expression RNA-seq\n",
    "    genom = pd.read_csv(os.path.join(DATA_DIR, \"HiSeqV2_PANCAN\"), sep='\\t')\n",
    "    genom_identifiers = genom[\"sample\"].values.tolist()\n",
    "\n",
    "    ### Load Phenotypes\n",
    "    phenotypes = pd.read_csv(os.path.join(DATA_DIR, \"BRCA_clinicalMatrix\"),sep='\\t')\n",
    "\n",
    "    #### Keep `HER2_Final_Status_nature2012` target variables\n",
    "    phenotypes_subset = phenotypes[[\"sampleID\", \"HER2_Final_Status_nature2012\"]].reset_index(drop=True)\n",
    "    phenotypes_subset.fillna(\"Negative\", inplace=True)\n",
    "\n",
    "    ### Transpose Methylation and Gene Expression datasets in order to join with Phenotypes on sampleID\n",
    "    genom_transpose = genom.set_index(\"sample\").transpose().reset_index().rename(columns={\"index\": \"sampleID\"})\n",
    "\n",
    "    ### Merge datasets\n",
    "    df = pd.merge(phenotypes_subset, genom_transpose, on=\"sampleID\", how=\"left\")\n",
    "\n",
    "    ### Encode target\n",
    "    df[\"target\"] = [0 if t == \"Negative\" else 1 for t in df['HER2_Final_Status_nature2012']]\n",
    "    df = df.drop(['HER2_Final_Status_nature2012','sampleID'], axis=1)\n",
    "    ## Move target to first column\n",
    "    df.insert(loc=0, column='target', value=df.pop('target'))\n",
    "    ## Drop rows with NaN values\n",
    "    df = df.dropna()\n",
    "\n",
    "    ### Train-Valid-Test split\n",
    "    # Hold out 20% of the data for testing\n",
    "    train_df, test_df = train_test_split(df, test_size=args.train_test_split_ratio)\n",
    "    # Hold out an additional 20% of the training data for validaton\n",
    "    train_df, val_df = train_test_split(train_df, test_size=args.train_test_split_ratio)\n",
    "\n",
    "    print(f\"The training data has {train_df.shape[0]} records and {train_df.shape[1]} columns.\")\n",
    "    print(f\"The validation data has {val_df.shape[0]} records and {val_df.shape[1]} columns.\")\n",
    "    print(f\"The test data has {test_df.shape[0]} records and {test_df.shape[1]} columns.\")\n",
    "   \n",
    "    # Save data\n",
    "\n",
    "    os.makedirs(os.path.join(args.local_path, \"output/train\"), exist_ok=True)\n",
    "    training_output_path = os.path.join(args.local_path,'output/train/train.csv')\n",
    "    train_df.to_csv(training_output_path, header=True, index=False)\n",
    "    print(f\"Training data saved to {training_output_path}\")\n",
    "    \n",
    "    os.makedirs(os.path.join(args.local_path, \"output/val\"), exist_ok=True)\n",
    "    val_output_path = os.path.join(args.local_path,'output/val/val.csv')\n",
    "    val_df.to_csv(val_output_path, header=True, index=False)\n",
    "    print(f\"Validation data saved to {val_output_path}\")\n",
    "          \n",
    "    os.makedirs(os.path.join(args.local_path, \"output/test\"), exist_ok=True)\n",
    "    test_output_path = os.path.join(args.local_path,'output/test/test.csv')\n",
    "    test_df.to_csv(test_output_path, header=True, index=False)\n",
    "    print(f\"Test data saved to {test_output_path}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment to test processing script locally\n",
    "# !python scripts/processing/processing.py --local_path data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.C. Submit SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the inputs for the processing job\n",
    "inputs = [ProcessingInput(source=f\"s3://{bucket_name}/data/input/\",\n",
    "                          destination='/opt/ml/processing/input',\n",
    "                          s3_data_distribution_type='ShardedByS3Key'\n",
    "                         )         \n",
    "         ]\n",
    "\n",
    "# Define the outputs for the processing job\n",
    "outputs = [ProcessingOutput(output_name='train',\n",
    "                            source='/opt/ml/processing/output/train',\n",
    "                            destination=f\"s3://{bucket_name}/data/output/train/\"\n",
    "                           ),\n",
    "           ProcessingOutput(output_name='validation',\n",
    "                            source='/opt/ml/processing/output/val',\n",
    "                            destination=f\"s3://{bucket_name}/data/output/val/\"\n",
    "                           ),\n",
    "           ProcessingOutput(output_name='test',\n",
    "                            source='/opt/ml/processing/output/test',\n",
    "                            destination=f\"s3://{bucket_name}/data/output/test/\"\n",
    "                           )\n",
    "          ]\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m5.xlarge',\n",
    "                                     instance_count=1)\n",
    "\n",
    "processing_run_name = f\"Processing-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "sklearn_processor.run(\n",
    "    job_name=processing_run_name,\n",
    "    code='scripts/processing/processing.py',\n",
    "    inputs=inputs,\n",
    "    outputs=outputs, \n",
    "    experiment_config={\n",
    "        \"ExperimentName\": brca_her2_experiment.experiment_name,\n",
    "        \"TrialComponentDisplayName\": processing_run_name\n",
    "        },\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Processed Data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session.download_data(f\"{DATA_DIR}/output/train\", bucket=bucket_name, key_prefix='data/output/train/train.csv')\n",
    "sm_session.download_data(f\"{DATA_DIR}/output/val\", bucket=bucket_name, key_prefix='data/output/val/val.csv')\n",
    "sm_session.download_data(f\"{DATA_DIR}/output/test\", bucket=bucket_name, key_prefix='data/output/test/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our training data is set up, we can train some models. To highlight the benefits of experiment tracking, we're going to train models using three different frameworks:\n",
    "- The XGBoost algorithm\n",
    "- The random forest model from Scikit Learm\n",
    "- A multi-layer perceptron (MLP) neural network in Keras\n",
    "\n",
    "Since we're using SageMaker jobs to run our training, we don't need to install any additional libraries or spin up expensive compute resources on our notebook server. The jobs use their own dependencies and we're only charged for the time they run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define some variables that all three training jobs will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "content_type = \"text/csv\"\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{bucket_name}/data/output/train/train.csv\", \n",
    "    content_type=content_type\n",
    ")\n",
    "\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{bucket_name}/data/output/val/val.csv\", \n",
    "    content_type=content_type\n",
    ")\n",
    "\n",
    "s3_input_test = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{bucket_name}/data/output/test/test.csv\", \n",
    "    content_type=content_type\n",
    ")\n",
    "\n",
    "model_output_path = f\"s3://{bucket_name}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.A. Train Model Using a SKLearn Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a trial\n",
    "rf_trial = Trial.create(\n",
    "        trial_name=f\"RF-Trial-{strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "        experiment_name=brca_her2_experiment.experiment_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder for RF training script\n",
    "os.makedirs(os.path.join(WORKING_DIR,\"scripts/rf_train\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/rf_train/rf_train.py\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Load model for inference\"\"\"\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "def _parse_args():\n",
    "    \"\"\"Parse job parameters.\"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Hyperparameters are described here.\n",
    "    parser.add_argument(\"--n-estimators\", type=int, default=10)\n",
    "    parser.add_argument(\"--min-samples-leaf\", type=int, default=3)\n",
    "    \n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--validation\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    \n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train.csv\")\n",
    "    parser.add_argument(\"--validation-file\", type=str, default=\"val.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"test.csv\")\n",
    "    \n",
    "    parser.add_argument(\"--target\", type=str, default=\"target\")\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    try:\n",
    "        my_tracker = Tracker.load()\n",
    "    except ValueError:\n",
    "        my_tracker = Tracker.create()\n",
    "    \n",
    "    print(\"extracting arguments\")\n",
    "    args, _ = _parse_args()\n",
    "    print(args)\n",
    "\n",
    "    print(\"Preparing data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    validation_df = pd.read_csv(os.path.join(args.validation, args.validation_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "    \n",
    "    train_labels = np.array(train_df.pop(\"target\"))\n",
    "    validation_labels = np.array(validation_df.pop(\"target\"))\n",
    "    test_labels = np.array(test_df.pop(\"target\"))\n",
    "    \n",
    "    train_np = np.array(train_df)\n",
    "    validation_np = np.array(validation_df)    \n",
    "    test_np = np.array(test_df)\n",
    "        \n",
    "    # Use the scale_pos_weight parameter to account for the imbalanced classes in our data\n",
    "    pos_weight = float(np.sum(train_labels == 0) / np.sum(train_labels == 1))\n",
    "\n",
    "    # train\n",
    "    print(\"training model\")\n",
    "    classifier = RandomForestClassifier(\n",
    "        n_estimators=args.n_estimators, \n",
    "        min_samples_leaf=args.min_samples_leaf, \n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1, \n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    classifier.fit(train_np, train_labels)\n",
    "    \n",
    "    print(\"Evaluating model\")\n",
    "\n",
    "    # evaluate test data\n",
    "    test_predictions = classifier.predict(test_np)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:accuracy', value=accuracy)  \n",
    "    \n",
    "    precision = precision_score(test_labels, test_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:precision', value=precision) \n",
    "    \n",
    "    f1 = f1_score(test_labels, test_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:f1', value=f1)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "        \n",
    "    my_tracker.close()    \n",
    "    \n",
    "    print(\"Saving model\")\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(classifier, path)\n",
    "    print(\"Model saved to \" + path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `requirements.txt` file in the training script directory to install additional dependencies in the training container. This is a great way to install an extra package or two without creating your own container image from scratch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"sagemaker-experiments\" > scripts/rf_train/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_job_name= f\"RF-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "rf_estimator = SKLearn(\n",
    "    entry_point=\"rf_train.py\",\n",
    "    source_dir = \"scripts/rf_train\",   \n",
    "    output_path = model_output_path,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    enable_sagemaker_metrics=True,\n",
    "    base_job_name=rf_job_name,\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": 100,\n",
    "        \"min-samples-leaf\": 3,\n",
    "        \"target\": \"target\",\n",
    "    },\n",
    ")\n",
    "\n",
    "rf_estimator.fit(\n",
    "    {'train': s3_input_train, 'validation': s3_input_validation, 'test': s3_input_test},\n",
    "    job_name=rf_job_name,\n",
    "    experiment_config={\n",
    "            \"TrialName\": rf_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": rf_job_name,\n",
    "        },\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download model\n",
    "# print(rf_job_name)\n",
    "# print(bucket_name)\n",
    "# sm_session.download_data(\"models\", bucket=bucket_name, key_prefix=f\"{rf_job_name}/output/model.tar.gz\")\n",
    "# !tar xvfz models/model.tar.gz\n",
    "# from joblib import dump, load\n",
    "# rf_model = load('model.joblib') \n",
    "# rf_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.B. Train Model using a Keras MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a trial\n",
    "tf_trial = Trial.create(\n",
    "        trial_name=f\"TF-Trial-{strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "        experiment_name=brca_her2_experiment.experiment_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder for Keras training script\n",
    "os.makedirs(os.path.join(WORKING_DIR,\"scripts/tf_train\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/tf_train/tf_train.py\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical \n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, \\\n",
    " Conv1D, MaxPool1D, Flatten, concatenate\n",
    "\n",
    "def binary_mlp(metrics, output_bias=None):\n",
    "    ### Setup loss and output node activation\n",
    "\n",
    "    output_activation = \"sigmoid\"\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()#from_logits=True\n",
    "\n",
    "    \n",
    "    ### Gene Expression Encoder\n",
    "    genom_input = Input(shape = (20530,),\n",
    "                        name = 'genom_input'\n",
    "                       )\n",
    "    genom_layer = Dense(units = 64,\n",
    "                        kernel_regularizer = tf.keras.regularizers.l2(0.001),\n",
    "                        activation = 'relu',\n",
    "                        name = 'genom_layer1'\n",
    "                       )(genom_input)\n",
    "    #genom_layer = BatchNormalization(name = 'genom_layer1_normalized')(genom_layer)\n",
    "    genom_layer = Dense(units = 32,\n",
    "                        kernel_regularizer = tf.keras.regularizers.l2(0.001),\n",
    "                        activation = 'relu',\n",
    "                        name = 'genom_layer2'\n",
    "                       )(genom_layer)    \n",
    "    \n",
    "\n",
    "    X = BatchNormalization(name = 'X_normalized')(genom_layer)\n",
    "\n",
    "\n",
    "    X = Dense(units = 32,\n",
    "              activation = 'relu',\n",
    "              kernel_regularizer = tf.keras.regularizers.l2(0.001),\n",
    "              name = 'X1'\n",
    "             )(X)\n",
    "    X = Dense(units = 16,\n",
    "              activation = 'relu',\n",
    "              kernel_regularizer = tf.keras.regularizers.l2(0.001),\n",
    "              name = 'X2'\n",
    "             )(X)\n",
    "\n",
    "    output = Dense(units = 1, activation = output_activation)(X)\n",
    "    \n",
    "    ### Compile the model\n",
    "    model = tf.keras.Model(genom_input, output)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss,\n",
    "                  metrics=metrics\n",
    "                 )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def _parse_args():\n",
    "    \"\"\"Parse job parameters.\"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    parser.add_argument('--epochs', type=int, default=10)\n",
    "    parser.add_argument('--batch_size', type=int, default=100)\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.1)\n",
    "\n",
    "    # input data and model directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--validation\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    \n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train.csv\")\n",
    "    parser.add_argument(\"--validation-file\", type=str, default=\"val.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"test.csv\")\n",
    "    \n",
    "    parser.add_argument(\"--target\", type=str, default=\"target\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    try:\n",
    "        my_tracker = Tracker.load()\n",
    "    except ValueError:\n",
    "        my_tracker = Tracker.create()\n",
    "    \n",
    "    print(\"extracting arguments\")\n",
    "    args, _ = _parse_args()\n",
    "    print(args)\n",
    "\n",
    "    print(\"Preparing data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    validation_df = pd.read_csv(os.path.join(args.validation, args.validation_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "    \n",
    "    train_labels = np.array(train_df.pop(\"target\"))\n",
    "    validation_labels = np.array(validation_df.pop(\"target\"))\n",
    "    test_labels = np.array(test_df.pop(\"target\"))\n",
    "    \n",
    "    train_np = np.array(train_df)\n",
    "    validation_np = np.array(validation_df)    \n",
    "    test_np = np.array(test_df)\n",
    "    \n",
    "    EPOCHS = 150\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    EARLY_STOPPING = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        verbose=1,\n",
    "        patience=10,\n",
    "        mode='auto',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Instantiate classifier\n",
    "    classifier = binary_mlp(metrics=[\"accuracy\", \"binary_accuracy\"], output_bias=None)    \n",
    "    \n",
    "    # Fit classifier\n",
    "    history = classifier.fit(x=train_np,\n",
    "                                y=train_labels,\n",
    "                                validation_data=(validation_np,validation_labels),\n",
    "                                callbacks=[EARLY_STOPPING],               \n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                epochs=EPOCHS,\n",
    "                                verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"Evaluating model\")\n",
    "    for epoch, value in enumerate(history.history[\"loss\"]):\n",
    "        my_tracker.log_metric(metric_name='train:loss', value=value, iteration_number=epoch)\n",
    "        \n",
    "    for epoch, value in enumerate(history.history[\"val_loss\"]):\n",
    "        my_tracker.log_metric(metric_name='validation:loss', value=value, iteration_number=epoch)        \n",
    "\n",
    "    # evaluate test data\n",
    "    test_predictions = classifier(test_np)    \n",
    "    discrete_predictions = np.around(test_predictions).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, discrete_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:accuracy', value=accuracy) \n",
    "    \n",
    "    precision = precision_score(test_labels, discrete_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:precision', value=precision)   \n",
    "    \n",
    "    f1 = f1_score(test_labels, discrete_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:f1', value=f1)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "        \n",
    "    my_tracker.close()\n",
    "    \n",
    "    print(\"Saving model\")\n",
    "    classifier.save(args.model_dir)\n",
    "    print(f\"Model saved to {args.model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"sagemaker-experiments\" > scripts/tf_train/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_job_name= f\"TF-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "tf_estimator = TensorFlow(\n",
    "    entry_point=\"tf_train.py\",\n",
    "    source_dir=\"scripts/tf_train\",\n",
    "    output_path = model_output_path,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    enable_sagemaker_metrics=True,\n",
    "\n",
    "    framework_version=\"2.2\",\n",
    "    py_version=\"py37\",\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"test:accuracy\", \"Regex\": \"Accuracy: ([0-9.]+)$\"},\n",
    "        {\"Name\": \"test:precision\", \"Regex\": \"Precision: ([0-9.]+)$\"},\n",
    "        {\"Name\": \"test:f1\", \"Regex\": \"F1 Score: ([0-9.]+)$\"},        \n",
    "    ]\n",
    ")\n",
    "\n",
    "tf_estimator.fit(\n",
    "    {'train': s3_input_train, 'validation': s3_input_validation, 'test': s3_input_test},\n",
    "    job_name=tf_job_name,\n",
    "    experiment_config={\n",
    "            \"TrialName\": tf_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": tf_job_name,\n",
    "        },\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.C. Train Model Using the XGBoost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a trial\n",
    "xgb_trial = Trial.create(\n",
    "        trial_name=f\"XGBoost-Trial-{strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "        experiment_name=brca_her2_experiment.experiment_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder for XGB training script\n",
    "os.makedirs(os.path.join(WORKING_DIR,\"scripts/xgb_train\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/xgb_train/xgb_train.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize and return fitted model.\n",
    "\n",
    "    Note that this should have the same name as the serialized model in the _xgb_train method\n",
    "    \"\"\"\n",
    "    model_file = 'xgboost-model.pkl'\n",
    "    booster = pkl.load(open(os.path.join(model_dir, model_file), 'rb'))\n",
    "    return booster\n",
    "\n",
    "def _parse_args():\n",
    "    \"\"\"Parse job parameters.\"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Hyperparameters are described here.\n",
    "    parser.add_argument('--objective', type=str, default=\"binary:logistic\")\n",
    "    parser.add_argument('--booster', type=str, default=\"gbtree\")\n",
    "    parser.add_argument('--eval_metric', type=str, default=\"error\")\n",
    "    parser.add_argument('--n_estimators', type=int, default=15)\n",
    "    parser.add_argument('--max_depth', type=int, default=6)\n",
    "    parser.add_argument('--min_child_weight', type=float, default=1)\n",
    "    parser.add_argument('--subsample', type=float, default=1)\n",
    "    parser.add_argument('--gamma', type=float, default=0)  \n",
    "    parser.add_argument('--alpha', type=float, default=0)  \n",
    "    \n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--validation\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    \n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train.csv\")\n",
    "    parser.add_argument(\"--validation-file\", type=str, default=\"val.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"test.csv\")\n",
    "\n",
    "    return parser.parse_known_args()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    try:\n",
    "        my_tracker = Tracker.load()\n",
    "    except ValueError:\n",
    "        my_tracker = Tracker.create()\n",
    "    \n",
    "    print(\"extracting arguments\")\n",
    "    args, _ = _parse_args()\n",
    "    print(args)\n",
    "\n",
    "    hyper_params_dict = {\n",
    "        'objective': args.objective,\n",
    "        'booster': args.booster,\n",
    "        'eval_metric': args.eval_metric,\n",
    "        'n_estimators': args.n_estimators,\n",
    "        'max_depth': args.max_depth, \n",
    "        'min_child_weight': args.min_child_weight,\n",
    "        'subsample': args.subsample,\n",
    "        'gamma': args.gamma,\n",
    "        'alpha': args.alpha    \n",
    "    }\n",
    "\n",
    "    print(\"Preparing data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    validation_df = pd.read_csv(os.path.join(args.validation, args.validation_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "    \n",
    "    train_labels = np.array(train_df.pop(\"target\"))\n",
    "    validation_labels = np.array(validation_df.pop(\"target\"))\n",
    "    test_labels = np.array(test_df.pop(\"target\"))\n",
    "    \n",
    "    train_np = np.array(train_df)\n",
    "    validation_np = np.array(validation_df)    \n",
    "    test_np = np.array(test_df)\n",
    "        \n",
    "    # Use the scale_pos_weight parameter to account for the imbalanced classes in our data\n",
    "    pos_weight = float(np.sum(train_labels == 0) / np.sum(train_labels == 1))\n",
    "\n",
    "    classifier = xgb.XGBClassifier(\n",
    "        scale_pos_weight=pos_weight, # Use pos_weight value calculated above to account for unbalanced classes\n",
    "        use_label_encoder=False,\n",
    "        **hyper_params_dict\n",
    "    )\n",
    "\n",
    "    print(\"Fitting model\")\n",
    "    classifier.fit(\n",
    "        train_np,\n",
    "        train_labels,\n",
    "        eval_set=[(train_np, train_labels), (validation_np, validation_labels)], \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(\"Evaluating model\")\n",
    "    results = classifier.evals_result()    \n",
    "    for epoch, value in enumerate(results[\"validation_0\"][\"error\"]):\n",
    "        my_tracker.log_metric(metric_name='train:error', value=value, iteration_number=epoch)\n",
    "        \n",
    "    for epoch, value in enumerate(results[\"validation_1\"][\"error\"]):\n",
    "        print(f\"[{epoch}]#011validation-error:{value}\")  # Required for SageMaker to pick up this metric in the logs during HPO (See section 6)\n",
    "        my_tracker.log_metric(metric_name='validation:error', value=value, iteration_number=epoch)\n",
    "\n",
    "    # evaluate test data\n",
    "    test_predictions = classifier.predict(test_np)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:accuracy', value=accuracy)  \n",
    "    \n",
    "    precision = precision_score(test_labels, test_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:precision', value=precision)   \n",
    "    \n",
    "    f1 = f1_score(test_labels, test_predictions)\n",
    "    my_tracker.log_metric(metric_name='test:f1', value=f1)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "        \n",
    "    my_tracker.close()    \n",
    "    \n",
    "    print(\"Saving model\")\n",
    "    path = os.path.join(args.model_dir, \"xgboost-model.pkl\")\n",
    "    pkl.dump(classifier, open(path, 'wb'))\n",
    "    print(\"Model saved to \" + path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"sagemaker-experiments\" > scripts/xgb_train/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_job_name= f\"XGB-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "hyper_params_dict = {\n",
    "    'objective':             \"binary:logistic\",\n",
    "    'booster':               \"gbtree\",\n",
    "    'eval_metric':           \"error\",\n",
    "    'n_estimators':          15,\n",
    "    'max_depth':             6, \n",
    "    'min_child_weight':      1,\n",
    "    'subsample':             1,\n",
    "    'gamma':                 0,\n",
    "    'alpha':                 0\n",
    "}\n",
    "\n",
    "xgb_estimator = XGBoost(entry_point = \"xgb_train.py\", \n",
    "                    source_dir = \"scripts/xgb_train\",\n",
    "                    output_path = model_output_path,\n",
    "                    framework_version='1.2-1',\n",
    "                    hyperparameters=hyper_params_dict,\n",
    "                    role=role,\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.2xlarge',\n",
    "                    enable_sagemaker_metrics=True,\n",
    "                   )\n",
    "\n",
    "\n",
    "xgb_estimator.fit(\n",
    "    {'train': s3_input_train, 'validation': s3_input_validation,'test': s3_input_test},\n",
    "    job_name=xgb_job_name,\n",
    "    experiment_config={\n",
    "            \"TrialName\": xgb_trial.trial_name,\n",
    "            \"TrialComponentDisplayName\": xgb_job_name,\n",
    "        },\n",
    "    logs=True,\n",
    "    wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.A. Download and Run the Trained XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Notebook 1, we used a confusion matrix to evaluate the accuracy of our model. Let's download our trained XGBoost model and do the same thing here.\n",
    "\n",
    "First, we download the model artifact from S3 and load it into our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session.download_data(\"models\", bucket=bucket_name, key_prefix=f\"{xgb_job_name}/output/model.tar.gz\")\n",
    "!tar xvfz models/model.tar.gz -C models\n",
    "\n",
    "loaded_model = pickle.load(open(\"models/xgboost-model.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read in the test data and seperate it into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"{DATA_DIR}/output/test/test.csv\")\n",
    "test_labels = np.array(test_df.pop(\"target\"))\n",
    "test_np = np.array(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define a function for generating a confusion matrix and use it to analyze our test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom function for generating a confusion matrix for a given p-value\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    if len(set(list(labels))) == 2:\n",
    "        print('Correctly un-detected (True Negatives): ', cm[0][0])\n",
    "        print('Incorrectly detected (False Positives): ', cm[0][1])\n",
    "        print('Misses (False Negatives): ', cm[1][0])\n",
    "        print('Hits (True Positives): ', cm[1][1])\n",
    "        print('Total: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "test_predictions = loaded_model.predict(test_np)\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "precision = precision_score(test_labels, test_predictions)\n",
    "f1 = f1_score(test_labels, test_predictions)\n",
    "\n",
    "plot_cm(test_labels, np.array(test_predictions))\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.B. Compare Model Results Using SageMaker Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker Experiments saves key information about our models for easy viewing and comparison in the SageMaker Studio UI.\n",
    "\n",
    "To start, click on the SageMaker Resources icon on the Studio sidebar and select `Experiments and trials` from the menu. To view information about your experiment click on the name (should start with \"BRCA-HER2-\" and then select `Open in trial component list`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/sm-resources-tab.png \"Studio Resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Trial Component list has a record for each of the training jobs, plus the processing job. You can click on a trial component name for more information about that job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/trial-component-list.png \"Trial Component List\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the performance of our model training jobs by adding an additional metric to the table. To do this, click on the Gear on the Studio sidebar and then `test:f1` in the Metrics section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/metrics.png \"Metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the XGBoost model had the highest f1 score on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/tc-list-2.png \"Updated Trial Component List\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the same information programmatically by using the `ExperimentAnalytics` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_expression = {\n",
    "    \"Filters\": [\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Contains\",\n",
    "            \"Value\": \"Training\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sm_session,\n",
    "    experiment_name=brca_her2_experiment.experiment_name,\n",
    "    search_expression=search_expression,\n",
    "    sort_by=\"metrics.test:f1.last\",\n",
    "    sort_order=\"Descending\",\n",
    "    metric_names=[\"test:f1\"],\n",
    "    parameter_names=[\"SageMaker.InstanceType\"],\n",
    ")\n",
    "\n",
    "trial_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we saw that our XGBoost classifier gave the best results on our test dataset. However, we can likely improve its accuracy further through hyperparameter optimization (HPO). During HPO, we repeatedly train our model with small changes to one or more parameters each time. SageMaker Training is a great fit for this because it allows us to run multiple training jobs in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"alpha\": ContinuousParameter(0, 250, scaling_type=\"Auto\"),\n",
    "    \"eta\": ContinuousParameter(0.1, 0.5, scaling_type=\"Auto\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_log = HyperparameterTuner(\n",
    "    xgb_estimator,\n",
    "    objective_metric_name = \"validation:error\",\n",
    "    objective_type = \"Minimize\",\n",
    "    hyperparameter_ranges = hyperparameter_ranges,\n",
    "    max_jobs=25,\n",
    "    max_parallel_jobs=10,\n",
    ")\n",
    "\n",
    "tuner_log.fit(\n",
    "    {'train': s3_input_train, 'validation': s3_input_validation,'test': s3_input_test},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View tuning job results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_log = HyperparameterTuner.attach(\"sagemaker-xgboost-220126-1405\", estimator_cls=\"sagemaker.xgboost.estimator.XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner_description = tuner_log.describe()\n",
    "objective_name = tuner_description[\"HyperParameterTuningJobConfig\"][\"HyperParameterTuningJobObjective\"][\"MetricName\"]\n",
    "tuner = tuner_log.analytics()\n",
    "tuner.dataframe().sort_values(by=\"FinalObjectiveValue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# tuning_job_result = sm_client.(\n",
    "#     HyperParameterTuningJobName=tuning_job_name\n",
    "# )\n",
    "\n",
    "# status = tuning_job_result[\"HyperParameterTuningJobStatus\"]\n",
    "# if status != \"Completed\":\n",
    "#     print(\"Reminder: the tuning job has not been completed.\")\n",
    "\n",
    "# job_count = tuning_job_result[\"TrainingJobStatusCounters\"][\"Completed\"]\n",
    "# print(\"%d training jobs have completed\" % job_count)\n",
    "\n",
    "# objective = tuning_job_result[\"HyperParameterTuningJobConfig\"][\"HyperParameterTuningJobObjective\"]\n",
    "# is_minimize = objective[\"Type\"] != \"Maximize\"\n",
    "# objective_name = objective[\"MetricName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "import bokeh.io\n",
    "\n",
    "bokeh.io.output_notebook()\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "class HoverHelper:\n",
    "    def __init__(self, tuning_analytics):\n",
    "        self.tuner = tuning_analytics\n",
    "\n",
    "    def hovertool(self):\n",
    "        tooltips = [\n",
    "            (\"FinalObjectiveValue\", \"@FinalObjectiveValue\"),\n",
    "            (\"TrainingJobName\", \"@TrainingJobName\"),\n",
    "        ]\n",
    "        for k in self.tuner.tuning_ranges.keys():\n",
    "            tooltips.append((k, \"@{%s}\" % k))\n",
    "\n",
    "        ht = HoverTool(tooltips=tooltips)\n",
    "        return ht\n",
    "\n",
    "    def tools(self, standard_tools=\"pan,crosshair,wheel_zoom,zoom_in,zoom_out,undo,reset\"):\n",
    "        return [self.hovertool(), standard_tools]\n",
    "\n",
    "\n",
    "hover = HoverHelper(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tuner.dataframe()[tuner.dataframe()[\"FinalObjectiveValue\"] > -float(\"inf\")]\n",
    "\n",
    "\n",
    "ranges = tuner.tuning_ranges\n",
    "figures = []\n",
    "for hp_name, hp_range in ranges.items():\n",
    "    categorical_args = {}\n",
    "    if hp_range.get(\"Values\"):\n",
    "        # This is marked as categorical.  Check if all options are actually numbers.\n",
    "        def is_num(x):\n",
    "            try:\n",
    "                float(x)\n",
    "                return 1\n",
    "            except:\n",
    "                return 0\n",
    "\n",
    "        vals = hp_range[\"Values\"]\n",
    "        if sum([is_num(x) for x in vals]) == len(vals):\n",
    "            # Bokeh has issues plotting a \"categorical\" range that's actually numeric, so plot as numeric\n",
    "            print(\"Hyperparameter %s is tuned as categorical, but all values are numeric\" % hp_name)\n",
    "        else:\n",
    "            # Set up extra options for plotting categoricals.  A bit tricky when they're actually numbers.\n",
    "            categorical_args[\"x_range\"] = vals\n",
    "\n",
    "    # Now plot it\n",
    "    p = figure(\n",
    "        plot_width=500,\n",
    "        plot_height=500,\n",
    "        title=\"Objective vs %s\" % hp_name,\n",
    "        tools=hover.tools(),\n",
    "        x_axis_label=hp_name,\n",
    "        y_axis_label=objective_name,\n",
    "        **categorical_args,\n",
    "    )\n",
    "    p.circle(source=df, x=hp_name, y=\"FinalObjectiveValue\")\n",
    "    figures.append(p)\n",
    "show(bokeh.layouts.Column(*figures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
