{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba0bd89",
   "metadata": {},
   "source": [
    "# Fine-Tune the ESM-2 Protein Language Model on Paired Antibody Sequence Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d421d",
   "metadata": {},
   "source": [
    "Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "SPDX-License-Identifier: MIT-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e44e7de",
   "metadata": {},
   "source": [
    "Note: We recommend running this notebook on a **ml.m5.large** instance with the **Data Science 3.0** image.\n",
    "\n",
    "### What is a Protein?\n",
    "\n",
    "Proteins are complex molecules that are essential for life. The shape and structure of a protein determines what it can do in the body. Knowing how a protein is folded and how it works helps scientists design drugs that target it. For example, if a protein causes disease, a drug might be made to block its function. The drug needs to fit into the protein like a key in a lock. Understanding the protein's molecular structure reveals where drugs can attach. This knowledge helps drive the discovery of innovative new drugs.\n",
    "\n",
    "![Proteins are made up of long chains of amino acids](img/protein.png)\n",
    "\n",
    "### What is a Protein Language Model?\n",
    "\n",
    "Proteins are made up of linear chains of molecules called amino acids, each with its own chemical structure and properties. If we think of each amino acid in a protein like a word in a sentence, it becomes possible to analyze them using methods originally developed for analyzing human language. Scientists have trained these so-called, \"Protein Language Models\", or pLMs, on millions of protein sequences from thousands of organisms. With enough data, these models can begin to capture the underlying evolutionary relationships between different amino acid sequences.\n",
    "\n",
    "It can take a lot of time and compute to train a pLM from scratch for a certain task. For example, a team at Tsinghua University [recently described](https://www.biorxiv.org/content/10.1101/2023.07.05.547496v3) training a 100 Billion-parameter pLM on 768 A100 GPUs for 164 days! Fortunately, in many cases we can save time and resources by adapting an existing pLM to our needs. This technique is called \"fine-tuning\" and also allows us to borrow advanced tools from other types of language modeling\n",
    "\n",
    "### What is ESM-2?\n",
    "\n",
    "[ESM-2](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1) is a pLM trained using unsupervied masked language modelling on 250 Million protein sequences by researchers at [Facebook AI Research (FAIR)](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1). It is available in several sizes, ranging from 8 Million to 15 Billion parameters. The smaller models are suitable for various sequence and token classification tasks. The FAIR team also adapted the 3 Billion parameter version into the ESMFold protein structure prediction algorithm. They have since used ESMFold to predict the struture of [more than 700 Million metagenomic proteins](https://esmatlas.com/about). \n",
    "\n",
    "ESM-2 is a powerful pLM. However, it has traditionally required multiple A100 GPU chips to fine-tune. In this notebook, we demonstrate how to use QLoRA to fine-tune ESM-2 in on an inexpensive Amazon SageMaker training instance. We will use ESM-2 to predict [subcellular localization](https://academic.oup.com/nar/article/50/W1/W228/6576357). Understanding where proteins appear in cells can help us understand their role in disease and find new drug targets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a72cc7-b965-4c0d-ba93-9f57de11c1dd",
   "metadata": {},
   "source": [
    "Note: ESM checkpoint names\n",
    "\n",
    "- esm2_t48_15B_UR50D  \n",
    "- esm2_t36_3B_UR50D (12,009 MB)\n",
    "- esm2_t33_650M_UR50D (3,641 MB)\n",
    "- esm2_t30_150M_UR50D (1,643 MB)\n",
    "- esm2_t12_35M_UR50D (1,171 MB)\n",
    "- esm2_t6_8M_UR50D (1,037 MB))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9a220a-d8b8-4b48-a672-e0f7667d3889",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d361c0-9309-40f0-8efb-a71742463cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -U pip\n",
    "%pip install -U transformers datasets torchinfo accelerate bitsandbytes boto3 sagemaker peft nvidia-ml-py3\n",
    "# %pip install -U --disable-pip-version-check  --no-warn-conflicts -r notebook-requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1e6f7-4afe-4368-964d-936d72b730ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# from datasets import Dataset\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sagemaker\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from time import strftime\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "s3 = boto_session.client(\"s3\")\n",
    "sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "sagemaker_execution_role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "REGION_NAME = sagemaker_session.boto_region_name\n",
    "print(f\"Assumed SageMaker role is {sagemaker_execution_role}\")\n",
    "\n",
    "S3_PREFIX = \"esm-pair-oas-ft\"\n",
    "S3_PATH = sagemaker.s3.s3_path_join(\"s3://\", S3_BUCKET, S3_PREFIX)\n",
    "print(f\"S3 path is {S3_PATH}\")\n",
    "\n",
    "EXPERIMENT_NAME = \"esm-pair-oas-ft-\" + strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(f\"Experiment name is {EXPERIMENT_NAME}\")\n",
    "\n",
    "# import argparse\n",
    "# import boto3\n",
    "# import json\n",
    "# import logging\n",
    "# import math\n",
    "# import os\n",
    "# import random\n",
    "\n",
    "# import datasets\n",
    "# import torch\n",
    "# from accelerate import Accelerator\n",
    "# from accelerate.logging import get_logger\n",
    "# from accelerate.utils import set_seed, DistributedDataParallelKwargs\n",
    "\n",
    "# from datasets import load_dataset\n",
    "# import sagemaker\n",
    "# from sagemaker.experiments.run import Run\n",
    "# from sagemaker.huggingface import HuggingFace, HuggingFaceModel\n",
    "# from sagemaker.inputs import TrainingInput\n",
    "# from time import strftime\n",
    "# from torch.utils.data import DataLoader\n",
    "# from tqdm.auto import tqdm\n",
    "# from typing import Dict, List\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_MAPPING,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    get_scheduler,\n",
    "    EsmForMaskedLM,\n",
    "    EsmTokenizer,\n",
    ")\n",
    "\n",
    "# from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4eb635-f047-453d-b93d-e6226dd9e584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boto_session = boto3.session.Session()\n",
    "# sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "# S3_BUCKET = sagemaker_session.default_bucket()\n",
    "# s3 = boto_session.client(\"s3\")\n",
    "# sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "# sagemaker_execution_role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "# REGION_NAME = sagemaker_session.boto_region_name\n",
    "# print(f\"Assumed SageMaker role is {sagemaker_execution_role}\")\n",
    "\n",
    "# PREFIX = \"esm-oas-fine-tuning\"\n",
    "# S3_PATH = sagemaker.s3.s3_path_join(\"s3://\", S3_BUCKET, PREFIX)\n",
    "# print(f\"S3 path is {S3_PATH}\")\n",
    "\n",
    "# EXPERIMENT_NAME = PREFIX + strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "# print(f\"Experiment name is {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323c0ad-7f24-4f96-bb9c-d24ba34f9672",
   "metadata": {},
   "source": [
    "## 1. Prepare OAS Paired Sequence Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c4619a-1eaf-4721-b4dc-11dfa9d9dfeb",
   "metadata": {},
   "source": [
    "### 1.1. Download OAS Paired Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a422a7-e8d8-4c3f-8b85-ae2c6ded0bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL_NAME = \"facebook/esm2_t6_8M_UR50D\"\n",
    "DATASET_NAME = \"bloyal/oas-paired-sequence-data\"\n",
    "DATASET_CONFIG = \"rat_SD\"\n",
    "MAX_SEQ_LENGTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2054f4d0-659f-40cb-b650-446ecd178b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(DATASET_NAME, DATASET_CONFIG)\n",
    "raw_datasets[\"train\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b1a65-ff24-4f15-a868-cdb0d1d5ba1a",
   "metadata": {},
   "source": [
    "### 1.2. Remove duplicate Heavy Chain CDR3 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9359b61c-66b4-4c63-a118-733d569a7c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = raw_datasets[\"train\"].to_pandas()\n",
    "df = df.drop_duplicates([\"cdr3_aa_heavy\"], ignore_index=True)\n",
    "print(df.head())\n",
    "df = datasets.Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d22eec-0ea5-4fe2-a6f7-58515966b4c2",
   "metadata": {},
   "source": [
    "### 1.3. Split into train-validation-test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a222a2b-b69e-4c30-a75d-10a64a8d5208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 80% train, 20% test + validation\n",
    "train_test = df.train_test_split(test_size=0.2)\n",
    "# Split the 10% test + valid in half test, half valid\n",
    "test_valid = train_test[\"test\"].train_test_split(test_size=0.5)\n",
    "df = datasets.DatasetDict(\n",
    "    {\n",
    "        \"train\": train_test[\"train\"],\n",
    "        \"validation\": test_valid[\"train\"],\n",
    "        \"test\": test_valid[\"test\"],\n",
    "    }\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a680de-cea3-4ee6-a4a8-4c4eed84d337",
   "metadata": {},
   "source": [
    "### 1.4. Tokenize sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b9f47-84d6-4794-8a10-3cbb35456abf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.EsmTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "\n",
    "def get_cdr_mask(examples, max_length=256):\n",
    "    cdr_mask = []\n",
    "    for example in zip(*examples.values()):\n",
    "        example_mask = [0]\n",
    "        for chain in (example[1:5], example[5:9]):\n",
    "            seq = chain[0]\n",
    "            chain_mask = [0] * len(seq)\n",
    "            for i in range(1, 4):\n",
    "                cdr_start = seq.find(chain[i])\n",
    "                cdr_len = len(chain[i])\n",
    "                chain_mask = (\n",
    "                    chain_mask[:cdr_start]\n",
    "                    + [1] * cdr_len\n",
    "                    + chain_mask[(cdr_start + cdr_len) :]\n",
    "                )\n",
    "            example_mask += chain_mask + [0]\n",
    "        example_mask = (example_mask + [0] * max_length)[:max_length]\n",
    "        cdr_mask.append(example_mask)\n",
    "\n",
    "    return cdr_mask\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    tokenized_data = tokenizer(\n",
    "        examples[\"sequence_alignment_aa_heavy\"],\n",
    "        examples[\"sequence_alignment_aa_light\"],\n",
    "        return_special_tokens_mask=True,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_SEQ_LENGTH,\n",
    "    )\n",
    "    tokenized_data[\"cdr_mask\"] = get_cdr_mask(examples, max_length=MAX_SEQ_LENGTH)\n",
    "    return tokenized_data\n",
    "\n",
    "\n",
    "tokenized_datasets = df.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=os.cpu_count(),\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    "    desc=\"Creating and tokenizing paired sequences\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443aacc2-5ef2-4962-ae12-8de874fcca86",
   "metadata": {},
   "source": [
    "### 1.5. Validate a random sample from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8334876-877f-41ac-85f7-450fbda83797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index in random.sample(range(len(df[\"train\"])), 1):\n",
    "    decoded_seq = tokenizer.decode(tokenized_datasets[\"train\"][index][\"input_ids\"])\n",
    "    print(\n",
    "        f\"\"\"\n",
    "Sample {index} of the training set:\\n\n",
    "original_sequence:\n",
    "{decoded_seq}\\n\n",
    "original_cdrs:\n",
    "{\n",
    "    [\n",
    "        df['train'][index]['cdr1_aa_heavy'],\n",
    "        df['train'][index]['cdr2_aa_heavy'],\n",
    "        df['train'][index]['cdr3_aa_heavy'],\n",
    "        df['train'][index]['cdr1_aa_light'],\n",
    "        df['train'][index]['cdr2_aa_light'], \n",
    "        df['train'][index]['cdr3_aa_light']\n",
    "    ]}\\n\n",
    "{'#'*50}\\n\n",
    "sequence_length:\n",
    "{len(tokenized_datasets['train'][index]['input_ids'])}\\n\n",
    "input_ids:\n",
    "{tokenized_datasets['train'][index]['input_ids']}\\n\n",
    "special_tokens_mask:\n",
    "{tokenized_datasets['train'][index]['special_tokens_mask']}\\n\n",
    "attention_mask:\n",
    "{tokenized_datasets['train'][index]['attention_mask']}\\n\n",
    "cdr_mask:\n",
    "{tokenized_datasets['train'][index]['cdr_mask']}\\n\n",
    "Decoded CDRs:\"\"\"\n",
    "    )\n",
    "    print(\n",
    "        [\n",
    "            tokenizer.decode(seq) if cdr == 1 else 0\n",
    "            for seq, cdr in zip(\n",
    "                tokenized_datasets[\"train\"][index][\"input_ids\"],\n",
    "                tokenized_datasets[\"train\"][index][\"cdr_mask\"],\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960e9904-65df-4c91-986f-da97f1db63ed",
   "metadata": {},
   "source": [
    "### 1.6. Group pairs of sequences into chunks of 512 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4f0b3-d9a4-4895-a43c-b18632bdfe74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_seqs(examples):\n",
    "    result = {\n",
    "        k: [x + y for x, y in zip(examples[k][::2], examples[k][1::2])]\n",
    "        for k in examples.keys()\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(\n",
    "    chunk_seqs,\n",
    "    batched=True,\n",
    "    num_proc=os.cpu_count(),\n",
    "    desc=\"Combining pairs of tokenized sequences.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6b1a2-d1b1-4f22-9713-936bf62d9be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index in random.sample(range(len(tokenized_datasets[\"train\"])), 1):\n",
    "    print(\n",
    "        f\"\"\"\n",
    "Sample {index} of the training set:\\n\n",
    "\n",
    "sequence_length:\n",
    "{len(tokenized_datasets['train'][index]['input_ids'])}\\n\n",
    "input_ids:\n",
    "{tokenized_datasets['train'][index]['input_ids']}\\n\n",
    "special_tokens_mask:\n",
    "{tokenized_datasets['train'][index]['special_tokens_mask']}\\n\n",
    "attention_mask:\n",
    "{tokenized_datasets['train'][index]['attention_mask']}\\n\n",
    "cdr_mask:\n",
    "{tokenized_datasets['train'][index]['cdr_mask']}\\n\n",
    "Decoded CDRs:\"\"\"\n",
    "    )\n",
    "    print(\n",
    "        [\n",
    "            tokenizer.decode(seq) if cdr == 1 else 0\n",
    "            for seq, cdr in zip(\n",
    "                tokenized_datasets[\"train\"][index][\"input_ids\"],\n",
    "                tokenized_datasets[\"train\"][index][\"cdr_mask\"],\n",
    "            )\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755dc78-a82a-4a6b-b17b-87eccd6ca4a2",
   "metadata": {},
   "source": [
    "### 1.7. Save encoded data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1620afa-037e-4961-abbf-35438115fa58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_datasets[\"train\"].save_to_disk(S3_PATH + \"/data/train\")\n",
    "tokenized_datasets[\"validation\"].save_to_disk(S3_PATH + \"/data/validation\")\n",
    "tokenized_datasets[\"test\"].save_to_disk(S3_PATH + \"/data/test\")\n",
    "\n",
    "tokenized_datasets[\"train\"].save_to_disk(\"data/train\")\n",
    "tokenized_datasets[\"validation\"].save_to_disk(\"data/validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b645d5e9-6873-4792-bbb2-684c60470378",
   "metadata": {},
   "source": [
    "## 2.0. Define a custom data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cad4e-6300-4370-9118-8ebfb2476b62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union, Mapping\n",
    "from transformers.data.data_collator import _torch_collate_batch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForCDRLanguageModeling(DataCollatorForLanguageModeling):\n",
    "    cdr_probability: float = 0.3  # New attribute\n",
    "\n",
    "    def torch_mask_tokens(\n",
    "        self,\n",
    "        inputs: Any,\n",
    "        special_tokens_mask: Optional[Any] = None,\n",
    "        cdr_mask: Optional[Any] = None,  # New parameter\n",
    "    ) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\n",
    "        \"\"\"\n",
    "        import torch\n",
    "\n",
    "        labels = inputs.clone()\n",
    "        # We sample a few tokens in each sequence for MLM training (with probability `self.mlm_probability`)\n",
    "        probability_matrix = torch.full(labels.shape, self.mlm_probability)\n",
    "        if special_tokens_mask is None:\n",
    "            special_tokens_mask = [\n",
    "                self.tokenizer.get_special_tokens_mask(\n",
    "                    val, already_has_special_tokens=True\n",
    "                )\n",
    "                for val in labels.tolist()\n",
    "            ]\n",
    "            special_tokens_mask = torch.tensor(special_tokens_mask, dtype=torch.bool)\n",
    "        else:\n",
    "            special_tokens_mask = special_tokens_mask.bool()\n",
    "\n",
    "        probability_matrix.masked_fill_(special_tokens_mask, value=0.0)\n",
    "\n",
    "        # New Code ###########################\n",
    "        if cdr_mask is not None:\n",
    "            probability_matrix.masked_fill_(cdr_mask.bool(), value=self.cdr_probability)\n",
    "        # ###################################\n",
    "\n",
    "        masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "\n",
    "        # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
    "        indices_replaced = (\n",
    "            torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
    "        )\n",
    "        inputs[indices_replaced] = self.tokenizer.convert_tokens_to_ids(\n",
    "            self.tokenizer.mask_token\n",
    "        )\n",
    "\n",
    "        # 10% of the time, we replace masked input tokens with random word\n",
    "        indices_random = (\n",
    "            torch.bernoulli(torch.full(labels.shape, 0.5)).bool()\n",
    "            & masked_indices\n",
    "            & ~indices_replaced\n",
    "        )\n",
    "        random_words = torch.randint(\n",
    "            len(self.tokenizer), labels.shape, dtype=torch.long\n",
    "        )\n",
    "        inputs[indices_random] = random_words[indices_random]\n",
    "\n",
    "        # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
    "        return inputs, labels\n",
    "\n",
    "    def torch_call(\n",
    "        self, examples: List[Union[List[int], Any, Dict[str, Any]]]\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Handle dict or lists with proper padding and conversion to tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(examples[0], Mapping):\n",
    "            batch = self.tokenizer.pad(\n",
    "                examples,\n",
    "                return_tensors=\"pt\",\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            )\n",
    "        else:\n",
    "            batch = {\n",
    "                \"input_ids\": _torch_collate_batch(\n",
    "                    examples, self.tokenizer, pad_to_multiple_of=self.pad_to_multiple_of\n",
    "                )\n",
    "            }\n",
    "\n",
    "        # If special token mask has been preprocessed, pop it from the dict.\n",
    "        special_tokens_mask = batch.pop(\"special_tokens_mask\", None)\n",
    "        cdr_mask = batch.pop(\"cdr_mask\", None)  # New code\n",
    "        if self.mlm:\n",
    "            batch[\"input_ids\"], batch[\"labels\"] = self.torch_mask_tokens(\n",
    "                batch[\"input_ids\"],\n",
    "                special_tokens_mask=special_tokens_mask,\n",
    "                cdr_mask=cdr_mask,  # New code\n",
    "            )\n",
    "        else:\n",
    "            labels = batch[\"input_ids\"].clone()\n",
    "            if self.tokenizer.pad_token_id is not None:\n",
    "                labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "            batch[\"labels\"] = labels\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e1b48a-1fcd-4286-a280-d5b70574aeee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_collator = DataCollatorForCDRLanguageModeling(\n",
    "    tokenizer=tokenizer, cdr_probability=0.3, mlm_probability=0.1\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], shuffle=True, collate_fn=data_collator, batch_size=3\n",
    ")\n",
    "\n",
    "torch.set_printoptions(threshold=10_000)\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "print(\"---Example batch---\")\n",
    "print(f\"input_ids:\\n{batch['input_ids']}\")\n",
    "print(f\"attention_mask:\\n{batch['attention_mask']}\")\n",
    "print(f\"labels:\\n{batch['labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3595df-b063-46d7-8655-b9587b541884",
   "metadata": {},
   "source": [
    "## 3.0 Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954baa88-8efd-49ba-94eb-eee4bddee634",
   "metadata": {},
   "source": [
    "### 3.1. (Optional) Test the training loop locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d20f3-933f-4b35-bec9-9cc6a1e92f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !SM_CHANNEL_TRAIN=\"data/train\" \\\n",
    "#   SM_CHANNEL_VALIDATION=\"data/validation\" \\\n",
    "#   SM_MODEL_DIR=\"data/output\" \\\n",
    "#   python scripts/oas_mlm_accelerate.py \\\n",
    "#   --model_name_or_path=\"facebook/esm2_t6_8M_UR50D\" \\\n",
    "#   --output_dir=\"output\" \\\n",
    "#   --mixed_precision=\"bf16\" \\\n",
    "#   --max_train_steps=64 \\\n",
    "#   --lora=True \\\n",
    "#   --use_gradient_checkpointing=True \\\n",
    "#   --quantization=\"8bit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba436a8-d095-4e6f-837d-4f29eab60d3b",
   "metadata": {},
   "source": [
    "### 3.2. Submit SageMaker training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df90ee1-372a-496f-94a2-8d2161815f92",
   "metadata": {},
   "source": [
    "**esm2_t6_8M_UR50D**\n",
    "\n",
    "- bf16 only: 2.48, 0.70 GB, 169 sec\n",
    "- LoRA: 2.61, 0.62 GB, 172 sec.\n",
    "- LoRA + 8bit quant: 2.64, 0.89 GB, 389 sec.\n",
    "- LoRA + 4bit quant: 2.65, 0.83 GB, 236 sec\n",
    "\n",
    "**esm2_t30_150M_UR50D**\n",
    "\n",
    "- bf16 only: 1.57, 4.99 GB, 1148 sec\n",
    "- LoRA: 1.61, 3.74 GB, 1055 sec\n",
    "- LoRA + 8bit quant: \n",
    "- LoRA + 4bit quant: 1.62, 6.3 GB, 1359 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661f0dd-3788-4009-bcc4-2405207e237d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional training parameters\n",
    "hyperparameters = {\n",
    "    \"model_name_or_path\": \"facebook/esm2_t33_650M_UR50D\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    # \"max_train_steps\": 64,\n",
    "    \"mixed_precision\": \"bf16\",\n",
    "    \"lora\": True,\n",
    "    \"use_gradient_checkpointing\": True,\n",
    "    \"quantization\": \"4bit\",\n",
    "}\n",
    "\n",
    "# creates Hugging Face estimator\n",
    "huggingface_estimator = sagemaker.huggingface.HuggingFace(\n",
    "    base_job_name=\"esm-oas-mlm-lora-gc-4bit\",\n",
    "    entry_point=\"oas_mlm_accelerate.py\",\n",
    "    source_dir=\"scripts\",\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    instance_count=1,\n",
    "    transformers_version=\"4.28.1\",\n",
    "    pytorch_version=\"2.0.0\",\n",
    "    py_version=\"py310\",\n",
    "    output_path=f\"{S3_PATH}/output\",\n",
    "    role=sagemaker_execution_role,\n",
    "    hyperparameters=hyperparameters,\n",
    "    # metric_definitions=metric_definitions,\n",
    "    checkpoint_local_path=\"/opt/ml/checkpoints\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    keep_alive_period_in_seconds=1800,\n",
    "    tags=[{\"Key\": \"project\", \"Value\": \"esm-ft\"}],\n",
    ")\n",
    "\n",
    "with Run(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    huggingface_estimator.fit(\n",
    "        {\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=S3_PATH + \"/data/train\", input_mode=\"FastFile\"\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data=S3_PATH + \"/data/validation\", input_mode=\"FastFile\"\n",
    "            ),\n",
    "        },\n",
    "        wait=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1489f-b895-402d-82b3-f84e6e187e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
