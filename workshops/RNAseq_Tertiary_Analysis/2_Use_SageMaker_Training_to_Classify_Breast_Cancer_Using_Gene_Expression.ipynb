{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Use SageMaker Training Jobs to Accelerate Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Use SageMaker processing and training jobs to optimize cost and performance\n",
    "- Compare model performance using SageMaker MLflow\n",
    "- Deploy a model as an endpoint for real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Notes:\n",
    "This notebook was created and tested on an `ml.t3.medium (2 vCPU + 4 GiB)` notebook instance running the `Python 3.0 (Data Science)` kernel in SageMaker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Background\n",
    "In notebook 1 of this series, we demonstrated using RNAseq data to predict HER2 status using the compute resources on the notebook server. However, using notebook server resources to process large amounts of data or train complex models is generally not a good idea. It's possible to scale up your notebook server, but any time you spend on non-compute intensive tasks (i.e. most of your time) will be wasted. A better idea is to run your notebook on a small server and submit compute-intensive tasks to independent jobs. SageMaker provides managed services for running data processing, model training, and hyperparameter tuning jobs. In this notebook, we'll demonstrate how to leverage these services to optimize the performance and cost of our tasks.\n",
    "\n",
    "Specifically, we'll demonstrate two best practices: **Jobs** and **Experiments**.\n",
    "\n",
    "These best practices play a key role in the **Prepare Data** and **Model Development** phases of the Machine Learning Lifecycle. For more information, please refer to the [Machine Learning Best Practices in Healthcare and Life Sciences Whitepaper](https://d1.awsstatic.com/whitepapers/ML-best-practices-health-science.pdf?did=wp_card&trk=wp_card).\n",
    "\n",
    "![Machine Learning Life Cycle - Part 1](img/MLLC1.png \"ML Life Cycle - Part 1\")\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. SageMaker Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html) processing, training, and hyperparameter optimization (HPO) jobs allow data scientists to submit compute-heavy processes to external services. This keeps costs optimized and ensures that these tasks run in reproducible environments. It also improves data scientist productivity by allowing these jobs to run in \"the background\" and provides resiliancy if something happens to your notebook environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/jobs.png \"Jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLflow workflow](img/mlflow-diagram.png \"MLflow\")\n",
    "\n",
    "[Amazon SageMaker with MLflow](https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow.html) is a capability of Amazon SageMaker that lets you create, manage, analyze, and compare your machine learning experiments. \n",
    "\n",
    "Machine learning is an iterative process that requires experimenting with various combinations of data, algorithms, and parameters, while observing their impact on model accuracy. The iterative nature of ML experimentation results in numerous model training runs and versions, making it challenging to track the best performing models and their configurations. The complexity of managing and comparing iterative training runs increases with generative artificial intelligence (generative AI), where experimentation involves not only fine-tuning models but also exploring creative and diverse outputs. Researchers must adjust hyperparameters, select suitable model architectures, and curate diverse datasets to optimize both the quality and creativity of the generated content. Evaluating generative AI models requires both quantitative and qualitative metrics, adding another layer of complexity to the experimentation process.\n",
    "\n",
    "Use MLflow with Amazon SageMaker to track, organize, view, analyze, and compare iterative ML experimentation to gain comparative insights and register and deploy your best performing models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Preparation\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The Python libraries that we'll use throughout the analysis\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install --disable-pip-version-check -q -U 'boto3==1.35.16' 'sagemaker==2.231.0' 'mlflow==2.13.2' 'sagemaker-mlflow==0.1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.processing import FrameworkProcessor, ProcessingOutput\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Create Some Necessary Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.session.Session()\n",
    "region = boto_session.region_name\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "sagemaker_execution_role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "s3_boto_client = boto_session.client(\"s3\")\n",
    "account_id = boto_session.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "print(f\"Assumed SageMaker role is {sagemaker_execution_role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Specify S3 Bucket and Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "S3_PREFIX = \"brca-her2-classifier\"\n",
    "S3_PATH = sagemaker.s3.s3_path_join(S3_BUCKET, S3_PREFIX)\n",
    "print(f\"S3 path is {S3_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Define Local Working Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(WORKING_DIR, \"data\")\n",
    "print(f\"Working directory is {WORKING_DIR}\")\n",
    "print(f\"Data directory is {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Define MLflow parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't yet, create an [MLflow tracking server](https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow-create-tracking-server-studio.html). Then, run the following cell to verfiy that your MLflow server is ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mlflow_servers = [\n",
    "    summary\n",
    "    for summary in sagemaker_boto_client.list_mlflow_tracking_servers().get(\n",
    "        \"TrackingServerSummaries\"\n",
    "    )\n",
    "    if summary.get(\"TrackingServerStatus\") == \"Created\"\n",
    "]\n",
    "tracking_server_arn = [\n",
    "    server[\"TrackingServerArn\"] for server in running_mlflow_servers\n",
    "][-1]\n",
    "running_mlflow_servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preparation  with Amazon SageMaker Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Processing allows you to run steps for data pre- or post-processing, feature engineering, data validation, or model evaluation workloads on Amazon SageMaker. Processing jobs accept data from Amazon S3 as input and store data into Amazon S3 as output.\n",
    "\n",
    "![processing](https://sagemaker.readthedocs.io/en/stable/_images/amazon_sagemaker_processing_image1.png)\n",
    "\n",
    "Here, we'll import the dataset and transform it with SageMaker Processing, which can be used to process terabytes of data in a SageMaker-managed cluster separate from the instance running your notebook server. In a typical SageMaker workflow, notebooks are only used for prototyping and can be run on relatively inexpensive and less powerful instances, while processing, training and model hosting tasks are run on separate, more powerful SageMaker-managed instances.  SageMaker Processing includes off-the-shelf support for Scikit-learn, as well as a Bring Your Own Container option, so it can be used with many different data transformation technologies and tasks.    \n",
    "\n",
    "To use SageMaker Processing, simply supply a Python data preprocessing script as shown below.  For this example, we're using a SageMaker prebuilt Scikit-learn container, which includes many common functions for processing data.  There are few limitations on what kinds of code and operations you can run, and only a minimal contract:  input and output data must be placed in specified directories.  If this is done, SageMaker Processing automatically loads the input data from S3 and uploads transformed data back to S3 when the job is complete.\n",
    "\n",
    "For this example, we'll download the raw data directly from Xenahubs as part of the processing script, so we do not need to specify an input bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Submit SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take about 5 minutes to complete. Notice that this code block references `scripts/processing/processing.py`. The processing job will run this script on a different compute instance, in this case a ml.m5.xlarge. This allows us to use a small instance for our notebook server, while still taking advantage of a more powerful instance for the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HISEQ_URL = \"https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/HiSeqV2_PANCAN.gz\"\n",
    "BRCA_CLINICAL_MATRIX_URL = (\n",
    "    \"https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/BRCA_clinicalMatrix\"\n",
    ")\n",
    "processing_run_name = f\"data-processing-job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "train_test_split_ratio = 0.2\n",
    "gene_count = 20000\n",
    "\n",
    "sklearn_processor = FrameworkProcessor(\n",
    "    estimator_cls=SKLearn,\n",
    "    framework_version=\"1.2-1\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    role=sagemaker_execution_role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "sklearn_processor.run(\n",
    "    job_name=processing_run_name,\n",
    "    code=\"scripts/processing/processing.py\",\n",
    "    dependencies=[\"scripts/processing/requirements.txt\"],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination=f\"s3://{S3_BUCKET}/{S3_PREFIX}/data/train/\",\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=\"/opt/ml/processing/output/val\",\n",
    "            destination=f\"s3://{S3_BUCKET}/{S3_PREFIX}/data/val/\",\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/output/test\",\n",
    "            destination=f\"s3://{S3_BUCKET}/{S3_PREFIX}/data/test/\",\n",
    "        ),\n",
    "    ],\n",
    "    arguments=[\n",
    "        \"--brca_clinical_matrix_url\",\n",
    "        BRCA_CLINICAL_MATRIX_URL,\n",
    "        \"--hiseq_url\",\n",
    "        HISEQ_URL,\n",
    "        \"--train_test_split_ratio\",\n",
    "        str(train_test_split_ratio),\n",
    "        \"--gene_count\",\n",
    "        str(gene_count),\n",
    "        \"--create_test_data\",\n",
    "    ],\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Download Processed Data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.download_data(\n",
    "    f\"{DATA_DIR}/output/train\",\n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix=f\"{S3_PREFIX}/data/train/train.csv\",\n",
    ")\n",
    "sagemaker_session.download_data(\n",
    "    f\"{DATA_DIR}/output/val\",\n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix=f\"{S3_PREFIX}/data/val/val.csv\",\n",
    ")\n",
    "sagemaker_session.download_data(\n",
    "    f\"{DATA_DIR}/output/test\",\n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix=f\"{S3_PREFIX}/data/test/test.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our training data is set up, we can train some models. To highlight the benefits of experiment tracking, we're going to train models using three different frameworks:\n",
    "- The random forest model from Scikit Learm\n",
    "- A multi-layer perceptron (MLP) neural network in Keras\n",
    "- The open-source XGBoost algorithm\n",
    "\n",
    "Since we're using SageMaker jobs to run our training, we don't need to install any additional libraries or spin up expensive compute resources on our notebook server. The jobs use their own dependencies and we're only charged for the time they run.\n",
    "\n",
    "First, let's define some variables that all three training jobs will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "content_type = \"text/csv\"\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{S3_BUCKET}/{S3_PREFIX}/data/train/train.csv\", content_type=content_type\n",
    ")\n",
    "\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{S3_BUCKET}/{S3_PREFIX}/data/val/val.csv\", content_type=content_type\n",
    ")\n",
    "\n",
    "model_output_path = f\"s3://{S3_BUCKET}/{S3_PREFIX}/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Train Model Using a SKLearn Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again we're passing a script (`scripts/rf_train/rf_train.py`) to run during the training job. Notice that we've also included a `requirements.txt` file in the training script directory to install additional dependencies in the training container. This is a great way to install an extra package or two without creating your own container image from scratch!\n",
    "\n",
    "Setting `wait=False` allows us to continue running the notebook while the training job runs in \"the background\" (on a different machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_job_name = f\"RF-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "n_estimators = 100\n",
    "min_samples_leaf = 3\n",
    "\n",
    "rf_estimator = SKLearn(\n",
    "    base_job_name=rf_job_name,\n",
    "    enable_sagemaker_metrics=True,\n",
    "    entry_point=\"rf_train.py\",\n",
    "    framework_version=\"1.2-1\",\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": n_estimators,\n",
    "        \"min-samples-leaf\": min_samples_leaf,\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    output_path=model_output_path,\n",
    "    role=sagemaker_execution_role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    source_dir=\"scripts/rf_train\",\n",
    "    environment={\"MLFLOW_TRACKING_ARN\": tracking_server_arn},\n",
    ")\n",
    "rf_estimator.fit(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation},\n",
    "    job_name=rf_job_name,\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Train Model using a Keras MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_job_name = f\"TF-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "tf_estimator = TensorFlow(\n",
    "    enable_sagemaker_metrics=True,\n",
    "    entry_point=\"tf_train.py\",\n",
    "    framework_version=\"2.16\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"validation:accuracy\", \"Regex\": \"Validation Accuracy: ([0-9.]+)$\"},\n",
    "        {\"Name\": \"validation:precision\", \"Regex\": \"Validation Precision: ([0-9.]+)$\"},\n",
    "        {\"Name\": \"validation:f1\", \"Regex\": \"Validation F1 Score: ([0-9.]+)$\"},\n",
    "    ],\n",
    "    output_path=model_output_path,\n",
    "    py_version=\"py310\",\n",
    "    role=sagemaker_execution_role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    source_dir=\"scripts/tf_train\",\n",
    "    environment={\"MLFLOW_TRACKING_ARN\": tracking_server_arn},\n",
    ")\n",
    "\n",
    "tf_estimator.fit(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation},\n",
    "    job_name=tf_job_name,\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Train Model Using the XGBoost Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the XGBoost training script we're about to run (scripts/rf_train/rf_train.py) with the training function we used in Notebook 1. You'll notice that the `xgb.train` call is the same in both!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're setting `wait=True` our Jupyter session will wait until this training job is finished before moving on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_job_name = f\"XGB-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "framework_version = \"1.7-1\"\n",
    "py_version = \"py3\"\n",
    "\n",
    "hyper_params_dict = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"eval_metric\": \"error\",\n",
    "    \"scale_pos_weight\": 9.0,\n",
    "    \"max_depth\": 3,\n",
    "    \"min_child_weight\": 5,\n",
    "    \"subsample\": 0.9,\n",
    "    \"verbosity\": 1,\n",
    "    \"tree_method\": \"auto\",\n",
    "}\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    enable_sagemaker_metrics=True,\n",
    "    entry_point=\"xgb_train.py\",\n",
    "    framework_version=framework_version,\n",
    "    hyperparameters=hyper_params_dict,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=model_output_path,\n",
    "    py_version=py_version,\n",
    "    role=sagemaker_execution_role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    source_dir=\"scripts/xgb_train\",\n",
    "    environment={\"MLFLOW_TRACKING_ARN\": tracking_server_arn},\n",
    ")\n",
    "\n",
    "xgb_estimator.fit(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation},\n",
    "    job_name=xgb_job_name,\n",
    "    logs=True,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Compare Model Results in MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_server_arn)\n",
    "runs = mlflow.search_runs()\n",
    "display(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll look at options for deploying this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained a model, we can allow other applications to use it for inference by deploying it. SageMaker offers several deployment options, based on your performance, cost, and data needs:\n",
    "\n",
    "![alt text](img/deployment_options.png \"SageMaker Model Deployment Options\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Deploy Model as SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-time inference endpoints are deployed to a persistent EC2 instance. This allows them to respond quickly to requests and support a wide range of custom properties. It's a good choice for models with steady usage. Deploying this endpoint will take about 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "realtime_endpoint_name = f\"her2-real-time-endpoint-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "xgb_predictor = xgb_estimator.deploy(\n",
    "    endpoint_name=realtime_endpoint_name,\n",
    "    serializer=sagemaker.serializers.CSVSerializer(),  # Helper function to serialize ndarray into buffer\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),  # Helper function to deserialize buffer into ndarray\n",
    "    wait=True,\n",
    "    instance_type=\"ml.t2.medium\",  # Instance type we want to use to host our endpoint.\n",
    "    initial_instance_count=1,  # For this example, we'll only use a single hosting instance.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Test Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "# Load a random sample of 10 records from the test data\n",
    "test_df = pd.read_csv(\"data/output/test/test.csv\", header=None).sample(n=25)\n",
    "\n",
    "# Submit the 10 samples to the inference endpoint and compare the actual and predicted values\n",
    "print(\n",
    "    f\"Sending test traffic to the endpoint {xgb_predictor.endpoint_name}. \\nPlease wait...\"\n",
    ")\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    print(\n",
    "        f\"[Actual | predicted] labels for record {i:3} are [{row[0]} | {xgb_predictor.predict([row.iloc[1:]])[0]:.3f}]\"\n",
    "    )\n",
    "    sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete endpoint\n",
    "xgb_predictor.delete_endpoint()\n",
    "\n",
    "# Delete all S3 objects\n",
    "bucket = boto_session.resource(\"s3\").Bucket(S3_BUCKET)\n",
    "bucket.objects.filter().delete()\n",
    "\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"data\", ignore_errors=True)\n",
    "shutil.rmtree(\"models\", ignore_errors=True)\n",
    "shutil.rmtree(\"generated\", ignore_errors=True)\n",
    "shutil.rmtree(\"training_reports\", ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "fcd20795596b30c7734a8efd08df92d501ca130112f67abeee93ccff645bf25b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
