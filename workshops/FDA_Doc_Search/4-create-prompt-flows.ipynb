{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Prompt Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.session.Session()\n",
    "kendra = session.client(\"kendra\")\n",
    "iam_client = session.client(\"iam\")\n",
    "lambda_client = session.client(\"lambda\")\n",
    "bedrock_agents_clients = session.client(\"bedrock-agent\")\n",
    "agents_runtime_client = boto3.client(\"bedrock-agent-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Create Kendra retriever Lambda function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Lambda execution role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "try:\n",
    "    role = iam_client.create_role(\n",
    "        RoleName=\"HASearchLambdaExecutionRole\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\"Service\": \"lambda.amazonaws.com\"},\n",
    "                        \"Action\": \"sts:AssumeRole\",\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "except:\n",
    "    role = iam_client.get_role(RoleName=\"HASearchLambdaExecutionRole\")\n",
    "\n",
    "print(role)\n",
    "\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=\"HASearchLambdaExecutionRole\",\n",
    "    PolicyArn=\"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\",\n",
    ")\n",
    "\n",
    "iam_client.put_role_policy(\n",
    "    RoleName=\"HASearchLambdaExecutionRole\",\n",
    "    PolicyName=\"HASearchLambdaExecutionPolicy\",\n",
    "    PolicyDocument=json.dumps(\n",
    "        {\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [\n",
    "                {\"Effect\": \"Allow\", \"Action\": [\"kendra:query\"], \"Resource\": [\"*\"]}\n",
    "            ],\n",
    "        }\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile retrieve_kendra.py\n",
    "\n",
    "import boto3\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(\"INFO\")\n",
    "boto_session = boto3.session.Session()\n",
    "kendra = boto_session.client(\"kendra\")\n",
    "\n",
    "\n",
    "def convert_json_to_xml(json_data: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Convert JSON data to XML format for Anthropic Claude prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    docs = \"<documents>\"\n",
    "    for i, snippet in enumerate(json_data, start=1):\n",
    "        item = f\"<document id='{i}'>\"\n",
    "        for k, v in snippet.items():\n",
    "            item += f\"<{k}>{v}</{k}>\"\n",
    "        item += \"</document>\"\n",
    "        docs += item\n",
    "    docs += \"</documents>\"\n",
    "    return docs\n",
    "\n",
    "\n",
    "def format_kendra_retrieve_response(result: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Format the Kendra retrieve response to a more readable format.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for retrieve_result in result[\"ResultItems\"]:\n",
    "        if retrieve_result[\"ScoreAttributes\"][\"ScoreConfidence\"] in [\n",
    "            \"LOW\",\n",
    "            \"NOT_AVAILABLE\",\n",
    "        ]:\n",
    "            continue\n",
    "        item = {}\n",
    "        item[\"Id\"] = retrieve_result.get(\"DocumentId\")\n",
    "        item[\"Title\"] = retrieve_result.get(\"DocumentTitle\").get(\"Text\")\n",
    "        item[\"Content\"] = retrieve_result.get(\"DocumentExcerpt\").get(\"Text\")\n",
    "        item[\"Uri\"] = retrieve_result.get(\"DocumentURI\")\n",
    "        item[\"Confidence\"] = retrieve_result.get(\"ScoreAttributes\").get(\n",
    "            \"ScoreConfidence\"\n",
    "        )\n",
    "\n",
    "        for attribute in retrieve_result.get(\"DocumentAttributes\"):\n",
    "            if attribute.get(\"Key\") == \"_excerpt_page_number\":\n",
    "                item[\"Uri\"] = (\n",
    "                    item[\"Uri\"]\n",
    "                    + \"#page=\"\n",
    "                    + str(attribute.get(\"Value\").get(\"LongValue\"))\n",
    "                )\n",
    "                break\n",
    "\n",
    "        for attribute in retrieve_result.get(\"DocumentAttributes\"):\n",
    "            if attribute.get(\"Key\") in [\n",
    "                \"ApplicationNumber\",\n",
    "                \"BrandName\",\n",
    "                \"GenericName\",\n",
    "                \"ManufacturerName\",\n",
    "                \"Submission\",\n",
    "                \"_category\",\n",
    "            ]:\n",
    "                item[attribute[\"Key\"].replace(\"_\", \"\")] = attribute.get(\"Value\").get(\n",
    "                    \"StringValue\"\n",
    "                )\n",
    "        item[\"Category\"] = item.pop(\"category\")\n",
    "        output.append(item)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def lambda_handler(event, context) -> dict:\n",
    "\n",
    "    logger.info(event)\n",
    "\n",
    "    query = event.get(\"node\").get(\"inputs\")[0].get(\"value\")\n",
    "    logging.info(query)\n",
    "\n",
    "    kendra_index = event.get(\"kendra_index_id\", os.environ[\"KENDRA_INDEX_ID\"])\n",
    "    page_size = event.get(\"page_size\", 50)\n",
    "\n",
    "    result = kendra.query(\n",
    "        QueryText=query,\n",
    "        IndexId=kendra_index,\n",
    "        PageSize=page_size,\n",
    "        QueryResultTypeFilter='DOCUMENT',\n",
    "    )\n",
    "\n",
    "    json_results = format_kendra_retrieve_response(result)\n",
    "    logger.info(json_results)\n",
    "\n",
    "    xml_results = convert_json_to_xml(json_results)\n",
    "\n",
    "    return {\n",
    "        \"json_results\": json_results,\n",
    "        \"xml_results\": xml_results\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieve_kendra import lambda_handler\n",
    "\n",
    "event = {\n",
    "    \"node\": {\n",
    "        \"name\": \"LambdaFunctionNode_1\",\n",
    "        \"inputs\": [\n",
    "            {\n",
    "                \"name\": \"codeHookInput\",\n",
    "                \"expression\": \"$.data\",\n",
    "                \"value\": \"What are the approved indications for Mounjaro?\",\n",
    "                \"type\": \"STRING\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"flow\": {\n",
    "        \"aliasId\": \"TSTALIASID\",\n",
    "        \"arn\": \"arn:aws:bedrock:us-east-1:112233445566:flow/MOCK\",\n",
    "    },\n",
    "    \"messageVersion\": \"1.0\",\n",
    "}\n",
    "\n",
    "lambda_handler(event, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "FUNCTION_NAME = \"retrieve_kendra\"\n",
    "\n",
    "shutil.make_archive(FUNCTION_NAME, \"zip\", \".\", FUNCTION_NAME + \".py\")\n",
    "\n",
    "try:\n",
    "    lambda_function = lambda_client.create_function(\n",
    "        FunctionName=FUNCTION_NAME,\n",
    "        Runtime=\"python3.11\",\n",
    "        Handler=f\"{FUNCTION_NAME}.lambda_handler\",\n",
    "        Code={\"ZipFile\": open(f\"{FUNCTION_NAME}.zip\", \"rb\").read()},\n",
    "        Role=role[\"Role\"][\"Arn\"],\n",
    "        Environment={\"Variables\": {\"KENDRA_INDEX_ID\": os.environ[\"KENDRA_INDEX_ID\"]}},\n",
    "    )\n",
    "    lambda_client.add_permission(\n",
    "        FunctionName=lambda_function[\"FunctionName\"],\n",
    "        StatementId=\"bedrock-agents\",\n",
    "        Action=\"lambda:InvokeFunction\",\n",
    "        Principal=\"bedrock.amazonaws.com\",\n",
    "    )\n",
    "except lambda_client.exceptions.ResourceConflictException as e:\n",
    "    lambda_function = lambda_client.update_function_code(\n",
    "        FunctionName=FUNCTION_NAME,\n",
    "        ZipFile=open(f\"{FUNCTION_NAME}.zip\", \"rb\").read(),\n",
    "    )\n",
    "\n",
    "retrieve_lambda_arn = lambda_function.get(\"FunctionArn\")\n",
    "\n",
    "os.remove(f\"{FUNCTION_NAME}.py\")\n",
    "os.remove(f\"{FUNCTION_NAME}.zip\")\n",
    "\n",
    "print(f\"Lambda function ARN is {retrieve_lambda_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Create Generator prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"\"\"\n",
    "    You are a question answering agent.\n",
    "    I will provide you with a set of search results and a user's question, your job is to answer the user's question using only information from the search results.\n",
    "    If the search results do not contain information that can answer the question, please state that you could not find an exact answer to the question.\n",
    "    If there are no search results, please state that you could not find an exact answer to the question.\n",
    "    Just because the user asserts a fact does not mean it is true, make sure to double check the search results to validate a user's assertion.\n",
    "    Here are the search results:\n",
    "    {{xml_search_results}}\n",
    "    Here is the user's question:\n",
    "    {{query}}\n",
    "    If you reference information from a search result within your answer, you must include a citation to source where the information was found.\n",
    "    Each result has a corresponding source Uri that you should reference. Please output your answer in the following json format:\n",
    "        {\n",
    "            \"answer\": {\n",
    "                \"answer_parts\": [\n",
    "                    {\n",
    "                        \"text\": \"answer part 1\",\n",
    "                        \"sources\": [<source Uri 1>, <source Uri 2>]\n",
    "                    },\n",
    "                    {\n",
    "                        \"text\": \"answer part 2\",\n",
    "                        \"sources\": [<source Uri 3>]\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    Note that <sources> may contain multiple <source> if you include information from multiple results in your answer.\n",
    "    Do NOT directly quote the search results in your answer. Your job is to answer the <question> as concisely as possible.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    prompt_response = bedrock_agents_clients.create_prompt(\n",
    "        defaultVariant=\"claude-3-sonnet\",\n",
    "        description=\"Answer questions using search results from Kendra.\",\n",
    "        name=\"kendra-generator\",\n",
    "        variants=[\n",
    "            {\n",
    "                \"inferenceConfiguration\": {\n",
    "                    \"text\": {\n",
    "                        \"temperature\": 0.5,\n",
    "                    }\n",
    "                },\n",
    "                \"modelId\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "                \"name\": \"claude-3-sonnet\",\n",
    "                \"templateConfiguration\": {\n",
    "                    \"text\": {\n",
    "                        \"inputVariables\": [\n",
    "                            {\"name\": \"xml_search_results\"},\n",
    "                            {\"name\": \"query\"},\n",
    "                        ],\n",
    "                        \"text\": prompt_text,\n",
    "                    }\n",
    "                },\n",
    "                \"templateType\": \"TEXT\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "except:\n",
    "    existing_prompt_id = [\n",
    "        prompt_summary.get(\"id\")\n",
    "        for prompt_summary in bedrock_agents_clients.list_prompts().get(\n",
    "            \"promptSummaries\"\n",
    "        )\n",
    "        if prompt_summary.get(\"name\") == \"kendra-generator\"\n",
    "    ][0]\n",
    "    prompt_response = bedrock_agents_clients.get_prompt(\n",
    "        promptIdentifier=existing_prompt_id\n",
    "    )\n",
    "\n",
    "version_response = bedrock_agents_clients.create_prompt_version(\n",
    "    promptIdentifier=prompt_response[\"id\"]\n",
    ")\n",
    "\n",
    "generator_prompt_arn = version_response.get(\"arn\")\n",
    "print(f\"Generator prompt ARN is {generator_prompt_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Create Format Answer Lambda Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile format_answer.py\n",
    "\n",
    "import logging\n",
    "import json\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(\"INFO\")\n",
    "\n",
    "def format_generate_response(response: str) -> str:\n",
    "    \"\"\"Format the response from the generate task\"\"\"\n",
    "    import json\n",
    "    import re\n",
    "\n",
    "    output = []\n",
    "    text = response\n",
    "    text = re.sub(r\"\\n\\s*\", \"\", text)\n",
    "    text = re.sub(r\"(,|\\n)]\", \"]\", text)\n",
    "    text = re.sub(r\"(,|\\n)}\", \"}\", text)\n",
    "    print(text)\n",
    "\n",
    "    try:\n",
    "        text = re.search(r\"{.*}\", text).group()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        output.append({\"text\": \"\", \"sources\": []})\n",
    "        return output\n",
    "    for answer_part in json.loads(text)[\"answer\"][\"answer_parts\"]:\n",
    "        print(answer_part)\n",
    "        part = {}\n",
    "        part[\"text\"] = answer_part[\"text\"]\n",
    "        part[\"sources\"] = []\n",
    "        for source in answer_part[\"sources\"]:\n",
    "            part[\"sources\"].append(source)\n",
    "            part[\"sources\"] = list(set(part[\"sources\"]))\n",
    "        output.append(part)\n",
    "\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "def lambda_handler(event, context) -> dict:\n",
    "\n",
    "    logger.info(event)\n",
    "\n",
    "    answer_parts = format_generate_response(event.get(\"node\").get(\"inputs\")[0].get(\"value\"))\n",
    "    logger.info(answer_parts)\n",
    "    return json.dumps(answer_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from format_answer import lambda_handler\n",
    "\n",
    "example = \"\"\"This is a test {\"answer\": {\"answer_parts\": [\n",
    "{\"text\": \"Mounjaro (tirzepatide) is indicated as an adjunct to diet and exercise to improve glycemic control in adults with type 2 diabetes mellitus.\", \n",
    "\"sources\": [\"http://www.accessdata.fda.gov/drugsatfda_docs/label/2022/215866s000lbl.pdf\",\"http://www.accessdata.fda.gov/drugsatfda_docs/label/2023/215866Orig1s002s006lbl.pdf\",\"https://www.accessdata.fda.gov/drugsatfda_docs/nda/2022/215866Orig1s000lbl.pdf\"]},\n",
    "{\"text\": \"Mounjaro has limitations of use - it has not been studied in patients with a history of pancreatitis and is not indicated for use in patients with type 1 diabetes mellitus.\", \n",
    "\"sources\": [\"http://www.accessdata.fda.gov/drugsatfda_docs/label/2022/215866s000lbl.pdf\", \"http://www.accessdata.fda.gov/drugsatfda_docs/label/2023/215866Orig1s002s006lbl.pdf\", \"https://www.accessdata.fda.gov/drugsatfda_docs/nda/2022/215866Orig1s000lbl.pdf\"]}\n",
    "]}}\"\"\"\n",
    "\n",
    "event = {\n",
    "    \"node\": {\n",
    "        \"name\": \"LambdaFunctionNode_1\",\n",
    "        \"inputs\": [\n",
    "            {\n",
    "                \"name\": \"codeHookInput\",\n",
    "                \"expression\": \"$.data\",\n",
    "                \"value\": example,\n",
    "                \"type\": \"OBJECT\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"flow\": {\n",
    "        \"aliasId\": \"TSTALIASID\",\n",
    "        \"arn\": \"arn:aws:bedrock:us-east-1:112233445566:flow/MOCK\",\n",
    "    },\n",
    "    \"messageVersion\": \"1.0\",\n",
    "}\n",
    "\n",
    "lambda_handler(event, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "FUNCTION_NAME = \"format_answer\"\n",
    "\n",
    "shutil.make_archive(FUNCTION_NAME, \"zip\", \".\", FUNCTION_NAME + \".py\")\n",
    "\n",
    "try:\n",
    "    lambda_function = lambda_client.create_function(\n",
    "        FunctionName=FUNCTION_NAME,\n",
    "        Runtime=\"python3.11\",\n",
    "        Handler=f\"{FUNCTION_NAME}.lambda_handler\",\n",
    "        Code={\"ZipFile\": open(f\"{FUNCTION_NAME}.zip\", \"rb\").read()},\n",
    "        Role=role[\"Role\"][\"Arn\"],\n",
    "        Environment={\"Variables\": {\"KENDRA_INDEX_ID\": os.environ[\"KENDRA_INDEX_ID\"]}},\n",
    "    )\n",
    "    lambda_client.add_permission(\n",
    "        FunctionName=lambda_function[\"FunctionName\"],\n",
    "        StatementId=\"bedrock-agents\",\n",
    "        Action=\"lambda:InvokeFunction\",\n",
    "        Principal=\"bedrock.amazonaws.com\",\n",
    "    )\n",
    "except lambda_client.exceptions.ResourceConflictException as e:\n",
    "    lambda_function = lambda_client.update_function_code(\n",
    "        FunctionName=FUNCTION_NAME,\n",
    "        ZipFile=open(f\"{FUNCTION_NAME}.zip\", \"rb\").read(),\n",
    "    )\n",
    "\n",
    "format_lambda_arn = lambda_function.get(\"FunctionArn\")\n",
    "\n",
    "os.remove(f\"{FUNCTION_NAME}.py\")\n",
    "os.remove(f\"{FUNCTION_NAME}.zip\")\n",
    "\n",
    "print(f\"Lambda function ARN is {format_lambda_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Create Prompt Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create IAM role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "try:\n",
    "    role = iam_client.create_role(\n",
    "        RoleName=\"HASearchPromptFlowRole\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\"Service\": \"bedrock.amazonaws.com\"},\n",
    "                        \"Action\": \"sts:AssumeRole\",\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "except:\n",
    "    role = iam_client.get_role(RoleName=\"HASearchPromptFlowRole\")\n",
    "\n",
    "print(role)\n",
    "\n",
    "iam_client.put_role_policy(\n",
    "    RoleName=\"HASearchPromptFlowRole\",\n",
    "    PolicyName=\"HASearchPromptFlowPolicy\",\n",
    "    PolicyDocument=json.dumps(\n",
    "        {\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [\n",
    "                {\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Action\": [\n",
    "                        \"bedrock:GetFlow\",\n",
    "                        \"bedrock:GetPrompt\",\n",
    "                        \"bedrock:InvokeModel\",\n",
    "                    ],\n",
    "                    \"Resource\": [\"*\"],\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    create_flow_response = bedrock_agents_clients.create_flow(\n",
    "        definition={\n",
    "            \"connections\": [\n",
    "                {\n",
    "                    \"configuration\": {\n",
    "                        \"data\": {\n",
    "                            \"sourceOutput\": \"document\",\n",
    "                            \"targetInput\": \"codeHookInput\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"name\": \"FlowInputNodeFlowInputNode0ToRetrieveLambdaFunctionNode0\",\n",
    "                    \"source\": \"FlowInputNode\",\n",
    "                    \"target\": \"Retrieve\",\n",
    "                    \"type\": \"Data\",\n",
    "                },\n",
    "                {\n",
    "                    \"configuration\": {\n",
    "                        \"data\": {\n",
    "                            \"sourceOutput\": \"functionResponse\",\n",
    "                            \"targetInput\": \"xml_search_results\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"name\": \"RetrieveLambdaFunctionNode0ToGeneratePromptsNode0\",\n",
    "                    \"source\": \"Retrieve\",\n",
    "                    \"target\": \"Generate\",\n",
    "                    \"type\": \"Data\",\n",
    "                },\n",
    "                {\n",
    "                    \"configuration\": {\n",
    "                        \"data\": {\n",
    "                            \"sourceOutput\": \"functionResponse\",\n",
    "                            \"targetInput\": \"document\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"name\": \"RetrieveLambdaFunctionNode0ToSearchOutputNode0\",\n",
    "                    \"source\": \"Retrieve\",\n",
    "                    \"target\": \"SearchOutputNode\",\n",
    "                    \"type\": \"Data\",\n",
    "                },\n",
    "                {\n",
    "                    \"configuration\": {\n",
    "                        \"data\": {\"sourceOutput\": \"document\", \"targetInput\": \"query\"}\n",
    "                    },\n",
    "                    \"name\": \"FlowInputNodeFlowInputNode0ToGeneratePromptsNode1\",\n",
    "                    \"source\": \"FlowInputNode\",\n",
    "                    \"target\": \"Generate\",\n",
    "                    \"type\": \"Data\",\n",
    "                },\n",
    "                {\n",
    "                    \"configuration\": {\n",
    "                        \"data\": {\n",
    "                            \"sourceOutput\": \"modelCompletion\",\n",
    "                            \"targetInput\": \"codeHookInput\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"name\": \"GeneratePromptsNode0ToFormatLambdaFunctionNode0\",\n",
    "                    \"source\": \"Generate\",\n",
    "                    \"target\": \"Format\",\n",
    "                    \"type\": \"Data\",\n",
    "                },\n",
    "                {\n",
    "                    \"configuration\": {\n",
    "                        \"data\": {\n",
    "                            \"sourceOutput\": \"functionResponse\",\n",
    "                            \"targetInput\": \"document\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"name\": \"FormatLambdaFunctionNode0ToFlowOutputNodeFlowOutputNode0\",\n",
    "                    \"source\": \"Format\",\n",
    "                    \"target\": \"FlowOutputNode\",\n",
    "                    \"type\": \"Data\",\n",
    "                },\n",
    "            ],\n",
    "            \"nodes\": [\n",
    "                {\n",
    "                    \"configuration\": {\"input\": {}},\n",
    "                    \"name\": \"FlowInputNode\",\n",
    "                    \"outputs\": [{\"name\": \"document\", \"type\": \"String\"}],\n",
    "                    \"type\": \"Input\",\n",
    "                },\n",
    "                {\n",
    "                    \"configuration\": {\n",
    "                        \"lambdaFunction\": {\"lambdaArn\": retrieve_lambda_arn}\n",
    "                    },\n",
    "                    \"inputs\": [\n",
    "                        {\n",
    "                            \"expression\": \"$.data\",\n",
    "                            \"name\": \"codeHookInput\",\n",
    "                            \"type\": \"String\",\n",
    "                        }\n",
    "                    ],\n",
    "                    \"name\": \"Retrieve\",\n",
    "                    \"outputs\": [{\"name\": \"functionResponse\", \"type\": \"Object\"}],\n",
    "                    \"type\": \"LambdaFunction\",\n",
    "                },\n",
    "                {\n",
    "                    \"configuration\": {\n",
    "                        \"prompt\": {\n",
    "                            \"sourceConfiguration\": {\n",
    "                                \"resource\": {\"promptArn\": generator_prompt_arn}\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"inputs\": [\n",
    "                        {\n",
    "                            \"expression\": \"$.data.xml_results\",\n",
    "                            \"name\": \"xml_search_results\",\n",
    "                            \"type\": \"String\",\n",
    "                        },\n",
    "                        {\"expression\": \"$.data\", \"name\": \"query\", \"type\": \"String\"},\n",
    "                    ],\n",
    "                    \"name\": \"Generate\",\n",
    "                    \"outputs\": [{\"name\": \"modelCompletion\", \"type\": \"String\"}],\n",
    "                    \"type\": \"Prompt\",\n",
    "                },\n",
    "                {\n",
    "                    \"configuration\": {\n",
    "                        \"lambdaFunction\": {\"lambdaArn\": format_lambda_arn}\n",
    "                    },\n",
    "                    \"inputs\": [\n",
    "                        {\n",
    "                            \"expression\": \"$.data\",\n",
    "                            \"name\": \"codeHookInput\",\n",
    "                            \"type\": \"String\",\n",
    "                        }\n",
    "                    ],\n",
    "                    \"name\": \"Format\",\n",
    "                    \"outputs\": [{\"name\": \"functionResponse\", \"type\": \"String\"}],\n",
    "                    \"type\": \"LambdaFunction\",\n",
    "                },\n",
    "                {\n",
    "                    \"configuration\": {\"output\": {}},\n",
    "                    \"inputs\": [\n",
    "                        {\"expression\": \"$.data\", \"name\": \"document\", \"type\": \"String\"}\n",
    "                    ],\n",
    "                    \"name\": \"FlowOutputNode\",\n",
    "                    \"type\": \"Output\",\n",
    "                },\n",
    "                {\n",
    "                    \"configuration\": {\"output\": {}},\n",
    "                    \"inputs\": [\n",
    "                        {\n",
    "                            \"expression\": \"$.data.json_results\",\n",
    "                            \"name\": \"document\",\n",
    "                            \"type\": \"Array\",\n",
    "                        }\n",
    "                    ],\n",
    "                    \"name\": \"SearchOutputNode\",\n",
    "                    \"type\": \"Output\",\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        description=\"Health authority search+RAG example using an Amazon Kendra knowledge base retriever.\",\n",
    "        executionRoleArn=role.get(\"Role\").get(\"Arn\"),\n",
    "        name=\"HA-search-flow\",\n",
    "    )\n",
    "except:\n",
    "    existing_flow_id = [\n",
    "        flow_summary.get(\"id\")\n",
    "        for flow_summary in bedrock_agents_clients.list_flows().get(\"flowSummaries\")\n",
    "        if flow_summary.get(\"name\") == \"HA-search-flow\"\n",
    "    ][0]\n",
    "    create_flow_response = bedrock_agents_clients.get_flow(\n",
    "        flowIdentifier=existing_flow_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_agents_clients.get_flow(flowIdentifier=create_flow_response.get(\"id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_agents_clients.prepare_flow(\n",
    "    flowIdentifier=create_flow_response.get(\"id\")\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_version_response = bedrock_agents_clients.create_flow_version(\n",
    "    flowIdentifier=create_flow_response.get(\"id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    flow_alias_response = bedrock_agents_clients.create_flow_alias(\n",
    "        flowIdentifier=create_flow_response.get(\"id\"),\n",
    "        name=\"Health-Authority-QA\",\n",
    "        routingConfiguration=[\n",
    "            {\"flowVersion\": flow_version_response.get(\"version\")},\n",
    "        ],\n",
    "    )\n",
    "except:\n",
    "    existing_flow_alias = [\n",
    "        flow_alias_summary.get(\"id\")\n",
    "        for flow_alias_summary in bedrock_agents_clients.list_flow_aliases(\n",
    "            flowIdentifier=create_flow_response.get(\"id\")\n",
    "        ).get(\"flowAliasSummaries\")\n",
    "        if flow_alias_summary.get(\"name\") == \"Health-Authority-QA\"\n",
    "    ][0]\n",
    "    print(existing_flow_alias)\n",
    "    flow_alias_response = bedrock_agents_clients.get_flow_alias(\n",
    "        aliasIdentifier=existing_flow_alias,\n",
    "        flowIdentifier=create_flow_response.get(\"id\"),\n",
    "    )\n",
    "flow_alias_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Invoke prompt flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agents_runtime_client.invoke_flow(\n",
    "    flowAliasIdentifier=flow_alias_response.get(\"id\"),\n",
    "    flowIdentifier=create_flow_response.get(\"id\"),\n",
    "    inputs=[\n",
    "        {\n",
    "            \"content\": {\"document\": \"What are the approved indications for Mounjaro?\"},\n",
    "            \"nodeName\": \"FlowInputNode\",\n",
    "            \"nodeOutputName\": \"document\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "for event in invoke_response[\"responseStream\"]:\n",
    "    if \"flowOutputEvent\" in event:\n",
    "        print(event[\"flowOutputEvent\"][\"content\"][\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
