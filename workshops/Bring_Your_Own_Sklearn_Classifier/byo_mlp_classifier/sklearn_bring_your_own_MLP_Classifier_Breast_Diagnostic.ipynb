{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Whether a Breast Cancer Sample is Benign or Malignant\n",
    "\n",
    "## Learning Objectives:\n",
    "\n",
    "\n",
    "1. Understand what SageMaker Script Mode is, and how it can be leveraged.\n",
    "2. Read in data from S3 to SageMaker\n",
    "3. User prebuilt SageMaker containers to build, train, and deploy customer sklearn model\n",
    "4. Use batch transform to perform inferences and measure model performance.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "This is a breast cancer diagnoses dataset, where, for each sample, the sample is diagnosed as \"Benign\" or \"Malignant\". For each sample, a number of features are given as well. The source of the dataset is the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic).\n",
    "\n",
    "For this model, we will build, train and deploy a [Multi-layer Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) using the sklearn library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we have the right version of sagemaker\n",
    "%pip install sagemaker==2.48.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and create necessary clients\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import model_selection\n",
    "import s3fs\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "BUCKET = sagemaker_session.default_bucket()\n",
    "PREFIX = \"breast_cancer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the sample data\n",
    "S3Downloader.download(\n",
    "    s3_uri=\"s3://sagemaker-sample-files/datasets/tabular/breast_cancer/wdbc.csv\",\n",
    "    local_path=\"data\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "df_data = pandas.read_csv(\n",
    "    \"data/wdbc.csv\",\n",
    "    names=[\n",
    "        \"id\",\n",
    "        \"diagnosis\",\n",
    "        \"radius_mean\",\n",
    "        \"texture_mean\",\n",
    "        \"perimeter_mean\",\n",
    "        \"area_mean\",\n",
    "        \"smoothness_mean\",\n",
    "        \"compactness_mean\",\n",
    "        \"concavity_mean\",\n",
    "        \"concave points_mean\",\n",
    "        \"symmetry_mean\",\n",
    "        \"fractal_dimension_mean\",\n",
    "        \"radius_se\",\n",
    "        \"texture_se\",\n",
    "        \"perimeter_se\",\n",
    "        \"area_se\",\n",
    "        \"smoothness_se\",\n",
    "        \"compactness_se\",\n",
    "        \"concavity_se\",\n",
    "        \"concave points_se\",\n",
    "        \"symmetry_se\",\n",
    "        \"fractal_dimension_se\",\n",
    "        \"radius_worst\",\n",
    "        \"texture_worst\",\n",
    "        \"perimeter_worst\",\n",
    "        \"area_worst\",\n",
    "        \"smoothness_worst\",\n",
    "        \"compactness_worst\",\n",
    "        \"concavity_worst\",\n",
    "        \"concave points_worst\",\n",
    "        \"symmetry_worst\",\n",
    "        \"fractal_dimension_worst\",\n",
    "    ],\n",
    ")\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names for analysis\n",
    "features = list(set(df_data.columns) - set([\"id\", \"diagnosis\"]))\n",
    "# One-hot encode the diagnosis column\n",
    "df_data = pandas.get_dummies(df_data, columns=[\"diagnosis\"])\n",
    "# Get the data with encoded features. Malignant is now 1, Benign is 0\n",
    "df_data = df_data.rename(columns={\"diagnosis_M\": \"truth\"})\n",
    "df_data = df_data[features + [\"truth\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the feature data frame\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (70%) and test (30%) sets\n",
    "train_df, test_df = model_selection.train_test_split(df_data, test_size=0.3)\n",
    "# Move the truth column to the front of the training data set\n",
    "train_df = train_df[[\"truth\"] + features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the test data set\n",
    "x_test = test_df[features]\n",
    "y_test = test_df[\"truth\"].tolist()\n",
    "print(f\"The test data has shape {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the training data to s3 so that sagemaker can read it\n",
    "train_df.to_csv(\"data/train_data.csv\", index=False)\n",
    "training_data_path = S3Uploader.upload(\n",
    "    local_path=\"data/train_data.csv\",\n",
    "    desired_s3_uri=f\"s3://{BUCKET}/{PREFIX}\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "# Do the same for the test data\n",
    "x_test.to_csv(\"data/x_test.csv\", index=False, header=False)\n",
    "test_data_path = S3Uploader.upload(\n",
    "    local_path=\"data/x_test.csv\",\n",
    "    desired_s3_uri=f\"s3://{BUCKET}/{PREFIX}\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a training script\n",
    "%%writefile train.py\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    parser.add_argument(\"--output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    train_data=pd.read_csv(os.path.join(args.train, \"train_data.csv\"))\n",
    "\n",
    "    # Extract the labels from the first column\n",
    "    train_y = train_data[\"truth\"]\n",
    "    train_X = train_data[train_data.columns[1:len(train_data)]]\n",
    "\n",
    "    # Use scikit-learn's MLP Classifier to train the model.\n",
    "    regr = MLPClassifier(random_state=1, max_iter=500).fit(train_X, train_y)\n",
    "    regr.get_params()\n",
    "\n",
    "    # Print the coefficients of the trained classifier, and save the coefficients\n",
    "    joblib.dump(regr, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialized and return fitted model\n",
    "\n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"\n",
    "    regr = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return regr\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"return the class and the probability of the class\"\"\"\n",
    "    prediction = model.predict(input_data)\n",
    "    pred_prob = model.predict_proba(input_data) # A numpy array\n",
    "    return np.array(pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the estimator\n",
    "sklearn = SKLearn(\n",
    "    entry_point=\"train.py\",\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    role=role,\n",
    "    py_version=\"py3\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kick off the training job\n",
    "sklearn.fit({\"train\": training_data_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Batch Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a batch transformer for predictions\n",
    "transformer = sklearn.transformer(\n",
    "    instance_count=1, instance_type=\"ml.m4.xlarge\", accept=\"text/csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a transform job and wait for it to finish\n",
    "batch_input_s3 = test_data_path\n",
    "transformer.transform(batch_input_s3, content_type=\"text/csv\", split_type=\"Line\")\n",
    "print(\"Waiting for transform job: \" + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the output data from S3 to local filesystem\n",
    "batch_output = transformer.output_path\n",
    "print(f\"Batch transform results saved to {batch_output}\")\n",
    "S3Downloader.download(\n",
    "    s3_uri=batch_output,\n",
    "    local_path=\"data/output\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the batch transform results\n",
    "!head data/output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predictions and measure performance\n",
    "predictions = pandas.read_csv(\"data/output/x_test.csv.out\", header=None)\n",
    "predictions.reset_index(drop=True, inplace=True)\n",
    "results = pandas.concat([predictions, pandas.Series(y_test)], axis=1)\n",
    "results.columns = [\"pred_0\", \"pred_1\", \"true\"]\n",
    "results[\"true\"] = results[\"true\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the AUC-ROC curve\n",
    "fpr, tpr, threshold = metrics.roc_curve(results[\"true\"], results[\"pred_1\"])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(fpr, tpr, \"b\", label=\"AUC = %0.2f\" % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.plot([0, 1], [0, 1], \"r--\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we used SageMaker script mode to build, train, and deploy a sklearn model."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
