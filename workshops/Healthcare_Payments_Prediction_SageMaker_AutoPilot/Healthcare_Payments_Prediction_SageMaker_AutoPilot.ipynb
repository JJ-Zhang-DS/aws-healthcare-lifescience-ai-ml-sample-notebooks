{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medicare Payment Prediction with Amazon SageMaker Autopilot\n",
    "_**Using AutoPilot to Predict Healthcare Payment Amounts**_\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Data Exploration and Quality Control](#Data-Exploration-and-Quality-Control)\n",
    "1. [Train](#Settingup)\n",
    "1. [Autopilot Results](#Results)\n",
    "1. [Host](#Host)\n",
    "1. [Cleanup](#Cleanup)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Amazon SageMaker Autopilot is an automated machine learning (commonly referred to as AutoML) solution for tabular datasets. You can use SageMaker Autopilot in different ways: on autopilot (hence the name) or with human guidance, without code through SageMaker Studio, or using the AWS SDKs. This notebook, as a first glimpse, will use the AWS SDKs to simply create and deploy a machine learning model. Feature Engineering and hyperparameter tuning can be a laborious process, especially in \"messy\" dataset, like the one discussed in this notebook. Autopilot will perform the feature engineering and hyperparameter tuning for us.\n",
    "\n",
    "Predicting payments from insurance providers for healthcare services provided is essential for providers, insurers, and patients. This notebook analzes a 2010 dataset of Medicare payments based on a sample of benificiaries. For more information about this dataset, see [here](https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/BSAPUFS/Carrier_Line_Items). For the detailed data dictionary for this dataset, see [here](https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/BSAPUFS/Downloads/2010_Carrier_Data_Dictionary.pdf) and [here](https://cpsddr.uahs.arizona.edu/File/Details/656). \n",
    "\n",
    "\n",
    "**Notes**: \n",
    "\n",
    "* Much of the code and insructions for this notebook is copied/adapted from [this](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/autopilot/autopilot_customer_churn.ipynb) AWS SageMaker example notebook.\n",
    "\n",
    "* SageMaker Autopilot jobs can be created either via API calls or via SageMaker Studio. This notebook will rely excusivley on creating the jobs via the API interface\n",
    "\n",
    "* This notebook taks about 1 hour to run; however, You can example the results of a pre-run job in the candidate generation noteook, data exploration notebook, and variable importance report.\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "_This notebook was created and tested on an ml.m4.xlarge notebook instance._\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll import the Python libraries we'll need for the remainder of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer\n",
    "import boto3\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats \n",
    "import math\n",
    "from io import StringIO\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --ignore-installed boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "BUCKET=sagemaker_session.default_bucket()\n",
    "session = sagemaker.Session()\n",
    "PREFIX='autopilot_healthcare_sample' #this is the \"directory\" path to the file\n",
    "INPUT_FILE='healthcare_data_sample.csv'\n",
    "data_location=f'{BUCKET}/{PREFIX}/{INPUT_FILE}'\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "# This is the client we will use to interact with SageMaker AutoPilot\n",
    "sm = boto3.Session().client(service_name='sagemaker',region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data\n",
    "Insurers (including Medicare and Medicaid), maintain records of healthcare payments\n",
    "The dataset we use is publicly available and is available [here](http://go.cms.gov/19xxPN4 ).\n",
    "\n",
    "Let's download that dataset now:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in the data to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthcare_payment_df = pandas.read_csv(INPUT_FILE,low_memory=False) #read all the data to memory\n",
    "healthcare_payment_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes/columns (following verbaitim the data dictionary [here](https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/BSAPUFS/Downloads/2010_Carrier_Data_Dictionary.pdf) of this dataset are:\n",
    "\n",
    "- `BENE_SEX_IDENT_CD`: This field indicates the sex of the beneficiary (Male or Female)\n",
    "- `BENE_AGE_CAT_CD`: This categorical variable is based on the beneficiary's age at end of the reference year (2010).\n",
    "- `CAR_LINE_ICD9_DGNS_CD`: The patient’s diagnosis associated with each line item\n",
    "- `CAR_LINE_HCPCS_CD`: Healthcare Common Procedure Coding System (HCPCS) codes to identify items and services\n",
    "- `CAR_LINE BETOS_CD`: The Berenson‐Eggers Type of Service (BETOS) code for the line item based on generally agreed upon clinically meaningful groupings of procedures and\n",
    "services.\n",
    "- `CAR_LINE_PRVDR_TYPE_CD`: Identifies the type of provider furnishing the service for the line item.\n",
    "- `CAR_LINE_SRVC_CNT`:  Provides the count of the total number of services processed for the line\n",
    "item\n",
    "- `CAR_LINE_CMS_TYPE_SRVC_CD`: Indicates the type of service for the line item\n",
    "- `CAR_LINE_PLACE_OF_SRVC_CD`: The place of service for the line item.\n",
    "- `CAR_HCPCS_PMT_AMT`: Contains the payment made by Medicare for the line item. The values are provided after rounding to the nearest unit\n",
    "- `CAR_LINE_CNT`: Contains the number of carrier line items associated with each profile\n",
    "\n",
    "The attribute `CAR_HCPCS_PMT_AMT`, is known as the target attribute or response variable–the attribute that we want the ML model to predict.\n",
    "\n",
    "\n",
    "Note an important aspect of this dataset is that it is of mixed-types. Some columns (e.g. `CAR_LINE_BETOS_CD`) are strings, while others (e.g. `BENE_AGE_CAT_CD`) are numeric but categorical; others (e.g. `CAR_LINE_SRVC_CNT`) are cardinal. Manually processing these different feature types is time consuming; **Autopilot will perform this preprocessing for us**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reserve some data for calling inference on the model\n",
    "\n",
    "Divide the data into training and testing splits. The training split is used by SageMaker Autopilot. The testing split is reserved to perform inference using the suggested model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = healthcare_payment_df.sample(frac=0.8,random_state=200)\n",
    "test_data = healthcare_payment_df.drop(train_data.index)\n",
    "test_data_no_target = test_data.drop(columns=['CAR_HCPS_PMT_AMT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll upload these files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train_data.csv';\n",
    "train_data.to_csv(train_file, index=False, header=True)\n",
    "!aws s3 cp train_data.csv s3://$BUCKET/$PREFIX/\n",
    "\n",
    "\n",
    "test_file = 'test_data.csv';\n",
    "test_data_no_target.to_csv(test_file, index=False, header=False)\n",
    "!aws s3 cp test_data.csv s3://$BUCKET/$PREFIX/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kick of the SageMaker Autopilot job.\n",
    "We will now kick of the SageMaker Autopilot job. SageMaker Autopilot will take care of the feature engineering, testing, and model tuning for us in a fully automated fashion. A schematic of how Autopilot handles this shown below:\n",
    "\n",
    "![alt text](img/autopilot_schematic.png \"Autopilot Schematic\")\n",
    "\n",
    "Autopilot will generate the following three outputs:\n",
    "\n",
    "1. Autogenerated code corresponding to feature transformations and ML candidates.\n",
    "2. Autogenerated code corresponding to basic exploratory data analysis.\n",
    "3. Feature explanability based on [SHAP values](https://aws.amazon.com/blogs/machine-learning/explaining-amazon-sagemaker-autopilot-models-with-shap/).\n",
    "4. The ML model candidates. \n",
    "\n",
    "Autopilot takes about 1 hour to run this analysis, but you can explore the **pre-computed** notebooks now if you wish.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure the Autopilot Job\n",
    "input_data_config = [{\n",
    "      'DataSource': {\n",
    "        'S3DataSource': {\n",
    "          'S3DataType': 'S3Prefix',\n",
    "          'S3Uri': 's3://{}/{}/train_data.csv'.format(BUCKET,PREFIX)\n",
    "        }\n",
    "      },\n",
    "      'TargetAttributeName': 'CAR_HCPS_PMT_AMT'\n",
    "    }\n",
    "  ]\n",
    "\n",
    "output_data_config = {\n",
    "    'S3OutputPath': 's3://{}/{}/output'.format(BUCKET,PREFIX)\n",
    "  }\n",
    "auto_ml_job_config={'CompletionCriteria':{'MaxAutoMLJobRuntimeInSeconds': 900},\n",
    "                    \"Mode\":'ENSEMBLING' #change to HYPERPARAMETER_TUNING if you want to\n",
    "                   }\n",
    "                                      \n",
    "#Create the Job\n",
    "from time import gmtime, strftime, sleep\n",
    "timestamp_suffix = strftime('%d-%H-%M-%S', gmtime())\n",
    "\n",
    "auto_ml_job_name = 'automl-health-' + timestamp_suffix\n",
    "print('AutoMLJobName: ' + auto_ml_job_name)\n",
    "\n",
    "sm.create_auto_ml_job(AutoMLJobName=auto_ml_job_name,\n",
    "                      InputDataConfig=input_data_config,\n",
    "                      OutputDataConfig=output_data_config,\n",
    "                      AutoMLJobConfig=auto_ml_job_config,\n",
    "                      ProblemType='Regression',\n",
    "                      AutoMLJobObjective={ 'MetricName': 'MSE'},\n",
    "                      RoleArn=role,\n",
    "                     GenerateCandidateDefinitionsOnly=False)\n",
    "\n",
    "print ('JobStatus - Secondary Status')\n",
    "print('------------------------------')\n",
    "\n",
    "\n",
    "#Track the job progress\n",
    "describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "print (describe_response['AutoMLJobStatus'] + \" - \" + describe_response['AutoMLJobSecondaryStatus'])\n",
    "job_run_status = describe_response['AutoMLJobStatus']\n",
    "    \n",
    "while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    describe_response = sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)\n",
    "    job_run_status = describe_response['AutoMLJobStatus']\n",
    "    \n",
    "    print (describe_response['AutoMLJobStatus'] + \" - \" + describe_response['AutoMLJobSecondaryStatus'])\n",
    "    sleep(30)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_candidate=sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)[\"BestCandidate\"]\n",
    "best_candidate_name = best_candidate['CandidateName']\n",
    "#Next we will find the best candidate created by Autopilot . Feel free to further explore more the candidate generation notebook, data exploration notebook, and the feature explanability notebook. \n",
    "\n",
    "#Copy Over the candidate generation and data exploration notebooks, if using HYPERPARAMETER_TUNING mode\n",
    "\n",
    "#\n",
    "#print(best_candidate)\n",
    "#print('\\n')\n",
    "#print(\"CandidateName: \" + best_candidate_name)\n",
    "#print(\"FinalAutoMLJobObjectiveMetricName: \" + best_candidate['FinalAutoMLJobObjectiveMetric']['MetricName'])\n",
    "#print(\"FinalAutoMLJobObjectiveMetricValue: \" + str(best_candidate['FinalAutoMLJobObjectiveMetric']['Value']))\n",
    "    \n",
    "#candidate_generation_notebook=describe_response['AutoMLJobArtifacts']['CandidateDefinitionNotebookLocation']\n",
    "#os.system(f'''aws s3 cp {candidate_generation_notebook} .''')\n",
    "#data_exploration_notebook=describe_response['AutoMLJobArtifacts']['DataExplorationNotebookLocation']\n",
    "#os.system(f'''aws s3 cp {data_exploration_notebook} .''')\n",
    "##download the shap report\n",
    "#os.system(f'''aws s3 cp {best_candidate[\"CandidateProperties\"]['CandidateArtifactLocations']['Explainability']}/{best_candidate_name}/report.ipynb .''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sm.describe_auto_ml_job(AutoMLJobName=auto_ml_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Batch Transformation Job\n",
    "SageMaker supports many different ways to do [model deployments](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html). For this job, we will deploy the model as a [Batch Transformation](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'automl-healthcare-model-' + timestamp_suffix\n",
    "\n",
    "model = sm.create_model(Containers=best_candidate['InferenceContainers'],\n",
    "                            ModelName=model_name,\n",
    "                            ExecutionRoleArn=role)\n",
    "\n",
    "print('Model ARN corresponding to the best candidate is : {}'.format(model['ModelArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_s3_path=f's3://{BUCKET}/{PREFIX}/test_data.csv'\n",
    "transform_job_name = 'automl-health-transform-' + timestamp_suffix\n",
    "\n",
    "transform_input = {\n",
    "        'DataSource': {\n",
    "            'S3DataSource': {\n",
    "                'S3DataType': 'S3Prefix',\n",
    "                'S3Uri': test_data_s3_path\n",
    "            }\n",
    "        },\n",
    "        'ContentType': 'text/csv',\n",
    "        'CompressionType': 'None',\n",
    "        'SplitType': 'Line'\n",
    "    }\n",
    "\n",
    "transform_output = {\n",
    "        'S3OutputPath': 's3://{}/{}/inference-results'.format(BUCKET,PREFIX),\n",
    "    }\n",
    "\n",
    "transform_resources = {\n",
    "        'InstanceType': 'ml.m5.4xlarge',\n",
    "        'InstanceCount': 1\n",
    "    }\n",
    "\n",
    "sm.create_transform_job(TransformJobName = transform_job_name,\n",
    "                        ModelName = model_name,\n",
    "                        TransformInput = transform_input,\n",
    "                        TransformOutput = transform_output,\n",
    "                        TransformResources = transform_resources\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('JobStatus')\n",
    "print('----------')\n",
    "\n",
    "\n",
    "describe_response = sm.describe_transform_job(TransformJobName = transform_job_name)\n",
    "job_run_status = describe_response['TransformJobStatus']\n",
    "print (job_run_status)\n",
    "\n",
    "while job_run_status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    describe_response = sm.describe_transform_job(TransformJobName = transform_job_name)\n",
    "    job_run_status = describe_response['TransformJobStatus']\n",
    "    print (job_run_status)\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_output_file=f\"{describe_response['TransformOutput']['S3OutputPath']}/test_data.csv.out\"\n",
    "!aws s3 cp $the_output_file ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model Performance\n",
    "**After** you have have deployed a model based on the candidates generated by autopilot (which you can see in the autogenerated candidate definition notebook), it will return the name of the endpoint created. We will now test the endpoint performance on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df=pandas.read_csv('test_data.csv.out',header=None)\n",
    "predictions_df=pandas.concat([predictions_df.reset_index()[0],test_data.reset_index()['CAR_HCPS_PMT_AMT']],axis=1,ignore_index=True)\n",
    "predictions_df.columns=[\"Prediction\",\"True\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=seaborn.regplot(x=predictions_df[\"True\"], y=predictions_df[\"Prediction\"])\n",
    "ax.set(ylim=(0, 1000),xlim=(0,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the statistical significance and Spearman Rho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the Spearman Rho\n",
    "spearman_rho=stats.spearmanr(predictions_df['Prediction'],predictions_df[\"True\"])[0]\n",
    "spearman_rho_p=stats.spearmanr(predictions_df['Prediction'],predictions_df[\"True\"])[1]\n",
    "\n",
    "print(f'''Spearman Rho: {spearman_rho}''')\n",
    "print(f'''P-value: {spearman_rho_p}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a clear, statistically very significant positive correlation between the predicted payment amount and the true payment amount. Of course, the model is not perfect; examining and modifying the feature engineering and hyper parameter tuning notebook generated by autopilot might even futher improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
