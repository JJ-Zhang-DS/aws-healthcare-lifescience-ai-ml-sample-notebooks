{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ab7591-1443-4854-881a-f0d37a7ad1d6",
   "metadata": {},
   "source": [
    "# Deploy pre-trained ESM-2 model to Inferentia2\n",
    "\n",
    "Note: This notebook was last tested in SageMaker Studio on the PyTorch 1.13 Python 3.9 CPU Optimized image on a ml.m5.large instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f5ab1-119a-482d-9377-84cc8088fec9",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Install neuronx and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b670bb6-2414-4b1a-81fa-213e21945c13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "apt-get install gpg-agent -y\n",
    "wget -qO - https://apt.repos.neuron.amazonaws.com/GPG-PUB-KEY-AMAZON-AWS-NEURON.PUB | apt-key add -\n",
    "add-apt-repository https://apt.repos.neuron.amazonaws.com\n",
    "apt-get update -y\n",
    "apt-get install aws-neuronx-dkms=2.* aws-neuronx-collectives=2.* aws-neuronx-runtime-lib=2.* aws-neuronx-tools=2.* -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981be8bf-4e67-40fd-a900-6e6319ec1227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -q --upgrade pip\n",
    "%pip install -q --upgrade --extra-index-url https://pip.repos.neuron.amazonaws.com \\\n",
    "  neuronx-cc==2.* torch-neuronx torch sagemaker boto3 awscli transformers accelerate boto3 --no-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc16165-cb4b-4c31-a279-0e13f31d6552",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Compile pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdde14f-e621-4d0c-9a5c-267945b2c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_neuronx\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoConfig\n",
    "import timeit\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "print(\"Preparing example input\")\n",
    "sequence = (\n",
    "    \"KALTARQQEVFDLIRD<mask>ISQTGMPPTRAEIAQRLGFRSPNAAEEHLKALARKGVIEIVSGASRGIRLLQEE\"\n",
    ")\n",
    "max_length = 128\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "tokenized_sequence = tokenizer.encode_plus(\n",
    "    sequence,\n",
    "    max_length=max_length,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "tracing_input = tokenized_sequence[\"input_ids\"], tokenized_sequence[\"attention_mask\"]\n",
    "\n",
    "print(\"Loading pre-trained model\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    \"facebook/esm2_t12_35M_UR50D\", return_dict=False\n",
    ")\n",
    "model.eval()\n",
    "model_load_end_time = timer()\n",
    "\n",
    "print(\"Beginning model trace\")\n",
    "neuron_model = torch_neuronx.trace(model, tracing_input)\n",
    "neuron_model.eval()\n",
    "model_trace_end_time = timer()\n",
    "print(\n",
    "    f\"Model trace completed in {round(model_trace_end_time - model_load_end_time, 3)} seconds.\"\n",
    ")\n",
    "\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Process completed in {round(end_time - start_time, 3)} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f428b1f3-5b74-49fe-aa01-b2ce38d538b5",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Assemble model package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92364e-2aab-4a01-b917-2a83fefbc1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "boto_session = boto3.session.Session(\n",
    "    profile_name=\"aws-hcls-ml-sa-Admin\", region_name=\"us-west-2\"\n",
    ")\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "sagemaker_execution_role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "print(f\"Assumed SageMaker role is {sagemaker_execution_role}\")\n",
    "\n",
    "S3_PREFIX = \"compiled-model\"\n",
    "S3_PATH = sagemaker.s3.s3_path_join(\"s3://\", S3_BUCKET, S3_PREFIX)\n",
    "print(f\"S3 path is {S3_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726aeda-01a4-49bf-bf23-eab98275d80e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neuron_model.save(\"neuron_compiled_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7cfaf-e7fb-4910-b3e2-6c21813d6560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar -czvf model.tar.gz neuron_compiled_model.pt\n",
    "!rm neuron_compiled_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea90c472-9c00-4b8c-8a5d-4a145cfb3ca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s3_model_uri = sagemaker_session.upload_data(\"model.tar.gz\", S3_BUCKET, S3_PREFIX)\n",
    "s3_model_uri = \"s3://sagemaker-us-west-2-111918798052/compiled-model/model.tar.gz\"\n",
    "print(f\"Model artifact uploaded to {s3_model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3098b58-1a34-44a8-bf08-1afcae4320b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm 'model.tar.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c91e85-e9d9-465c-9681-eb9d1797dca3",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Define inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dca6f59-d163-404d-961a-ad56e21b5741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/inf2-deploy/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/inference/inf2/requirements.txt\n",
    "\n",
    "transformers\n",
    "torch\n",
    "torch-neuronx --extra-index-url https://pip.repos.neuron.amazonaws.com\n",
    "accelerate\n",
    "neuronx-cc==2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ff1e5c6-b9fa-4780-943f-3a0ff58b77ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/inf2-deploy/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/inference/inf2/inference.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "JSON_CONTENT_TYPE = \"application/json\"\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\" Load the model from HuggingFace \"\"\"\n",
    "    tokenizer_init = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "    model_file = os.path.join(model_dir, \"neuron_compiled_model.pt\")\n",
    "    model_neuron = torch.jit.load(model_file) ## This is throwing some errors during inf2 deployment\n",
    "    return (model_neuron, tokenizer_init)\n",
    "\n",
    "\n",
    "def input_fn(serialized_input_data, content_type=JSON_CONTENT_TYPE):\n",
    "    \"\"\" Process the request payload \"\"\"\n",
    "    \n",
    "    if content_type == JSON_CONTENT_TYPE:\n",
    "        input_data = json.loads(serialized_input_data)\n",
    "        return input_data.pop(\"inputs\", input_data)\n",
    "    else:\n",
    "        raise Exception(\"Requested unsupported ContentType in Accept: \" + content_type)\n",
    "        return\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model_and_tokenizer):\n",
    "    \"\"\" Run model inference \"\"\"\n",
    "    \n",
    "    model_bert, tokenizer = model_and_tokenizer\n",
    "    max_length = 128\n",
    "    tokenized_sequence = tokenizer.encode_plus(\n",
    "        input_data,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    prediction_input = (\n",
    "        tokenized_sequence[\"input_ids\"],\n",
    "        tokenized_sequence[\"attention_mask\"],\n",
    "    )\n",
    "    output = neuron_model(*prediction_input)[0]\n",
    "    mask_token_index = (tokenized_sequence.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
    "    mask_index_predictions = output[0, mask_token_index]\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(mask_index_predictions)\n",
    "    return {\n",
    "        list(tokenizer.get_vocab().keys())[idx]: round(v.item(), 3)\n",
    "        for idx, v in enumerate(probs[0])\n",
    "    }\n",
    "\n",
    "\n",
    "def output_fn(prediction_output, accept=JSON_CONTENT_TYPE):\n",
    "    \"\"\" Process the response payload \"\"\"\n",
    "    if accept == JSON_CONTENT_TYPE:\n",
    "        return json.dumps(prediction_output), accept\n",
    "\n",
    "    raise Exception(\"Requested unsupported ContentType in Accept: \" + accept)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821c118-fe6b-45f1-903d-c90eaae929fd",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Deploy model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "328baaf5-28ff-42f3-8a2e-f8d576179c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "ecr_image = \"763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference-neuronx:1.13.1-neuronx-py310-sdk2.12.0-ubuntu20.04\"\n",
    "\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=s3_model_uri,\n",
    "    role=sagemaker_execution_role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    source_dir=\"scripts/inf2-deploy\",\n",
    "    entry_point=\"inference.py\",\n",
    "    image_uri=ecr_image,\n",
    ")\n",
    "\n",
    "# Let SageMaker know that we've already compiled the model via neuron-cc\n",
    "pytorch_model._is_compiled_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9ee9841-f510-4186-a362-92ff9f24848c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------!CPU times: user 3.01 s, sys: 884 ms, total: 3.89 s\n",
      "Wall time: 24min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = pytorch_model.deploy(\n",
    "    instance_type=\"ml.inf2.xlarge\", initial_instance_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c23e55-c855-4f49-8ca9-d980e8c72a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()\n",
    "\n",
    "test_seq = \"MAAAVVLAAGLRAARRAVAATGVRGGQVRGAAGVT<mask>GNEVAKAQQATPGGAAPTIFSRILDKSLPADILYEDQQCLVFRDVAPQAPVHFLVIPKKPIPRISQAEEEDQQLLGHLLLVAKQTAKAEGLGDGYRLVINDGKLGAQSVYHLHIHVLGGRQLQWPPG\"\n",
    "sample = {\"inputs\": test_seq}\n",
    "predictor.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "107bb09b-23a4-4837-8288-87803fddf8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    predictor.delete_endpoint()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e6ef3-9cee-4388-a73e-f32fdb4c5672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
