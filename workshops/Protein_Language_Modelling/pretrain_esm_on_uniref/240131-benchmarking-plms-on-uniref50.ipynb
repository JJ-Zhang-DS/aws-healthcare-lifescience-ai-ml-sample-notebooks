{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6e243f-a130-46b9-8f7a-0205c6886e70",
   "metadata": {},
   "source": [
    "# Benchmarking Protein Language Model Pretraining on UniRef50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2755ba40-e905-4b29-b3a7-6d19458d5889",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e6acb7-e78c-4ce3-a0ae-0a7fe440d392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 uri is s3://sagemaker-us-west-2-111918798052/plm-uniref50-benchmarking\n",
      "Assumed SageMaker role is arn:aws:iam::111918798052:role/bloyal-esm-training-230722-SageMakerExecutionRole-SGS3MFJIVY26\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "from time import strftime\n",
    "\n",
    "boto_session = boto3.session.Session()\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "REGION_NAME = sagemaker_session.boto_region_name\n",
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "S3_PREFIX = \"plm-uniref50-benchmarking\"\n",
    "S3_FOLDER = sagemaker.s3.s3_path_join(\"s3://\", S3_BUCKET, S3_PREFIX)\n",
    "print(f\"S3 uri is {S3_FOLDER}\")\n",
    "\n",
    "EXPERIMENT_NAME = \"uniref50-benchmarking\"\n",
    "\n",
    "SAGEMAKER_EXECUTION_ROLE = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "print(f\"Assumed SageMaker role is {SAGEMAKER_EXECUTION_ROLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e11905-1cd4-4e9d-828a-233f6901887e",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3609b7d1-d703-44b3-9001-cf9adb96321f",
   "metadata": {},
   "source": [
    "## 2.1. Download UniRef50 FASTA File and Convert to Partitioned CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66c5b8-1b3f-4f2a-a3e2-7cb548a65ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "from sagemaker.processing import ProcessingOutput\n",
    "\n",
    "raw_data_uri = os.path.join(S3_FOLDER, \"data\", \"raw\", \"big\")\n",
    "\n",
    "processor = PyTorchProcessor(\n",
    "    base_job_name=\"fasta-processing\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    framework_version=\"2.0.0\",\n",
    "    py_version=\"py310\",\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "processor.run(\n",
    "    arguments=[\n",
    "        \"--source\",\n",
    "        \"https://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref50/uniref50.fasta.gz\",\n",
    "        \"--output_dir\",\n",
    "        \"/opt/ml/processing/output\",\n",
    "        \"--max_records_per_partition\",\n",
    "        \"1000000\"\n",
    "    ],\n",
    "    code=\"get_fasta.py\",\n",
    "    source_dir=\"scripts/processing\",\n",
    "\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/output\",  # When the job finishes, SageMaker will copy data from here...\n",
    "            destination=raw_data_uri,  # ...to here\n",
    "        )\n",
    "    ],\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4784b96-86c1-4597-b3d4-28908f72ce65",
   "metadata": {},
   "source": [
    "## 2.2. Convert CSVs to HuggingFace Dataset and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37e83d-5f05-487a-b6df-d7caabc7ef52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data_uri = os.path.join(S3_FOLDER, \"data\", \"raw\")\n",
    "raw_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275c864-f12e-433b-b95c-03d1e365a437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "hf_data_uri = os.path.join(S3_FOLDER, \"data\", \"processed\", \"arrow\")\n",
    "\n",
    "processor = PyTorchProcessor(\n",
    "    base_job_name=\"hf-tokenization\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.9xlarge\",\n",
    "    framework_version=\"2.0.0\",\n",
    "    py_version=\"py310\",\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    volume_size_in_gb=512\n",
    ")\n",
    "\n",
    "processor.run(\n",
    "    arguments=[\n",
    "        \"--model_name_or_path\",\n",
    "        \"facebook/esm2_t30_150M_UR50D\",\n",
    "        \"--low_cpu_mem_usage\",\n",
    "        \"True\",\n",
    "        \"--max_seq_length\",\n",
    "        \"512\",\n",
    "        \"--preprocessing_num_workers\",\n",
    "        \"24\",\n",
    "        \"--line_by_line\",\n",
    "        \"True\",\n",
    "        \"--pad_to_max_length\",\n",
    "        \"True\",\n",
    "        \"--train_dir\",\n",
    "        \"/opt/ml/processing/input\",\n",
    "        \"--output_dir\",\n",
    "        \"/opt/ml/processing/output\",\n",
    "    ],\n",
    "    code=\"hf_tokenization.py\",\n",
    "    source_dir=\"scripts/processing\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=os.path.join(raw_data_uri, 'csv'),  # When the job starts, SageMaker will copy data from here...\n",
    "            destination=\"/opt/ml/processing/input\",  # ...to here\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/output\",  # When the job finishes, SageMaker will copy data from here...\n",
    "            destination=hf_data_uri,  # ...to here\n",
    "        )\n",
    "    ],\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3114c4d4-833c-4ec0-b4ce-4f35a4d3dc01",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694ccb9c-3606-4d49-9d90-dad0ef008105",
   "metadata": {},
   "source": [
    "## 4.1. Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3848a877-422c-4a5d-9384-9dfe9bbbaaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# metric definition to extract the results\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"epoch.*=\\D*(.*?)$\"},\n",
    "    {\n",
    "        \"Name\": \"max_train_gpu_utilization\",\n",
    "        \"Regex\": \"max_train_gpu_utilization.*=\\D*(.*?)$\",\n",
    "    },\n",
    "    {\"Name\": \"train_loss\", \"Regex\": \"train_loss.*=\\D*(.*?)$\"},\n",
    "    {\"Name\": \"train_runtime\", \"Regex\": \"train_runtime.*=\\D*(.*?)$\"},\n",
    "    {\"Name\": \"train_samples\", \"Regex\": \"train_samples.*=\\D*(.*?)$\"},\n",
    "    {\n",
    "        \"Name\": \"train_samples_per_second\",\n",
    "        \"Regex\": \"train_samples_per_second.*=\\D*(.*?)$\",\n",
    "    },\n",
    "    {\"Name\": \"train_steps_per_second\", \"Regex\": \"train_steps_per_second.*=\\D*(.*?)$\"},\n",
    "    {\"Name\": \"eval_accuracy\", \"Regex\": \"eval_accuracy.*=\\D*(.*?)$\"},\n",
    "    {\"Name\": \"eval_loss\", \"Regex\": \"eval_loss.*=\\D*(.*?)$\"},\n",
    "    {\"Name\": \"eval_runtime\", \"Regex\": \"eval_runtime.*=\\D*(.*?)$\"},\n",
    "    {\"Name\": \"eval_samples\", \"Regex\": \"eval_samples.*=\\D*(.*?)$\"},\n",
    "    {\"Name\": \"eval_samples_per_second\", \"Regex\": \"eval_samples_per_second.*=\\D*(.*?)$\"},\n",
    "    {\"Name\": \"eval_steps_per_second\", \"Regex\": \"eval_steps_per_second.*=\\D*(.*?)$\"},\n",
    "    {\"Name\": \"eval_perplexity\", \"Regex\": \"perplexity.*=\\D*(.*?)$\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa116c8-1e42-4e86-96f5-b2ddfc825066",
   "metadata": {},
   "source": [
    "### 4.2. Train 150M Parameter ESM-2 on UniRef50 using HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65411da-3b68-40c5-8da5-1e5e51a12809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "experiment_name = \"240112-esm-training-full-data\"\n",
    "\n",
    "hyperparameters = {\n",
    "    \"bf16\": True,\n",
    "    \"config_name\": \"facebook/esm2_t30_150M_UR50D\",\n",
    "    \"dataloader_num_workers\": 8,\n",
    "    \"do_eval\": False,\n",
    "    \"do_preprocess\": False,\n",
    "    \"do_train\": True,\n",
    "    \"gradient_accumulation_steps\": 16,\n",
    "    \"logging_steps\": 16,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"output_dir\": \"/opt/ml/model\",\n",
    "    \"per_device_train_batch_size\": 24,\n",
    "    \"tokenizer_name\": \"facebook/esm2_t30_150M_UR50D\",\n",
    "    \"dataset_dir\": \"/opt/ml/input/data/training\",\n",
    "    \"torch_compile\": True,\n",
    "}\n",
    "\n",
    "p4_estimator = HuggingFace(\n",
    "    base_job_name=\"p4-hf\",\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    entry_point=\"run_mlm.py\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p4d.24xlarge\",\n",
    "    metric_definitions=metric_definitions,\n",
    "    pytorch_version=\"2.0.0\",\n",
    "    py_version=\"py310\",\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    source_dir=\"scripts/training/cuda\",\n",
    "    transformers_version=\"4.28.1\",\n",
    ")\n",
    "\n",
    "with Run(\n",
    "    experiment_name=experiment_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    p4_estimator.fit(\n",
    "        {\n",
    "            \"training\": TrainingInput(s3_data=hf_data_uri, input_mode=\"File\"),\n",
    "        },\n",
    "        wait=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613441f-3d4b-4c8d-8f06-8754d38a82d2",
   "metadata": {},
   "source": [
    "### 4.3 Train 150M Parameter ESM-2 on UniRef50 using Trn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac8eec5a-b8d2-4dbb-a5e3-a82b828578d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: trn1-training-2024-02-02-03-56-38-065\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "\n",
    "neuron_cache = os.path.join(S3_FOLDER, \"parallel-neuron-cache\")\n",
    "\n",
    "IMAGE_URI = f\"763104351884.dkr.ecr.{REGION_NAME}.amazonaws.com/huggingface-pytorch-training-neuronx:1.13.1-transformers4.34.1-neuronx-py310-sdk2.15.0-ubuntu20.04\"\n",
    "\n",
    "MODEL_ID=\"facebook/esm2_t30_150M_UR50D\"\n",
    "\n",
    "# Additional training parameters\n",
    "hyperparameters = {\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"model_id\": MODEL_ID,\n",
    "    \"per_device_train_batch_size\": 6,\n",
    "    \"bf16\": True,\n",
    "    \"logging_steps\": 8,\n",
    "    \"optim\": \"adamw_torch\",\n",
    "    \"gradient_accumulation_steps\": 16,\n",
    "    \"device\": \"xla\",\n",
    "}\n",
    "\n",
    "# creates Hugging Face estimator\n",
    "trn1_estimator = PyTorch(\n",
    "    base_job_name=\"trn1-training\",\n",
    "    entry_point=\"torch_xla_train.py\",\n",
    "    source_dir=\"scripts/training/neuron\",\n",
    "    instance_type=\"ml.trn1.32xlarge\",\n",
    "    instance_count=1,\n",
    "    image_uri=IMAGE_URI,\n",
    "    output_path=f\"{S3_FOLDER}/output\",\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    checkpoint_local_path=\"/opt/ml/checkpoints\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},\n",
    "    environment={\n",
    "        \"NEURON_COMPILE_CACHE_URL\": neuron_cache,\n",
    "        \"FI_EFA_FORK_SAFE\": \"1\",\n",
    "        \"XLA_USE_BF16\": \"1\",\n",
    "    },\n",
    "    tags=[{\"Key\": \"project\", \"Value\": \"esm-benchmarking\"}],\n",
    ")\n",
    "\n",
    "with Run(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    trn1_estimator.fit(\n",
    "        {\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=hf_data_uri, \n",
    "                input_mode=\"File\"\n",
    "            ),\n",
    "        },\n",
    "        wait=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
