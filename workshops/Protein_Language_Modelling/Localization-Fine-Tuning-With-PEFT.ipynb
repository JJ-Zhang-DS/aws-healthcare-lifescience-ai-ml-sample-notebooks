{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee72f818-0ded-401d-b350-3dcb00346260",
   "metadata": {},
   "source": [
    "# Use Amazon SageMaker for Parameter-Efficient Fine Tuning of the ESM-2 Protein Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f779d-16c6-48ae-bc6f-290855d42346",
   "metadata": {},
   "source": [
    "Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "SPDX-License-Identifier: MIT-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea37b37-5093-44ec-9235-d8ba3186bb90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Note: We recommend running this notebook on a **ml.m5.large** instance with the **Data Science 3.0** image.\n",
    "\n",
    "### What is a Protein?\n",
    "\n",
    "Proteins are complex molecules that are essential for life. The shape and structure of a protein determines what it can do in the body. Knowing how a protein is folded and how it works helps scientists design drugs that target it. For example, if a protein causes disease, a drug might be made to block its function. The drug needs to fit into the protein like a key in a lock. Understanding the protein's molecular structure reveals where drugs can attach. This knowledge helps drive the discovery of innovative new drugs.\n",
    "\n",
    "![Proteins are made up of long chains of amino acids](img/protein.png)\n",
    "\n",
    "### What is a Protein Language Model?\n",
    "\n",
    "Proteins are made up of linear chains of molecules called amino acids, each with its own chemical structure and properties. If we think of each amino acid in a protein like a word in a sentence, it becomes possible to analyze them using methods originally developed for analyzing human language. Scientists have trained these so-called, \"Protein Language Models\", or pLMs, on millions of protein sequences from thousands of organisms. With enough data, these models can begin to capture the underlying evolutionary relationships between different amino acid sequences.\n",
    "\n",
    "It can take a lot of time and compute to train a pLM from scratch for a certain task. For example, a team at Tsinghua University [recently described](https://www.biorxiv.org/content/10.1101/2023.07.05.547496v3) training a 100 Billion-parameter pLM on 768 A100 GPUs for 164 days! Fortunately, in many cases we can save time and resources by adapting an existing pLM to our needs. This technique is called \"fine-tuning\" and also allows us to borrow advanced tools from other types of language modeling\n",
    "\n",
    "### What is LoRA?\n",
    "\n",
    "One such method originally developed in 2021 for language analysis is [\"Low-Rank Adaptation of Large Language Models\"](https://www.biorxiv.org/content/10.1101/2023.07.05.547496v3), or \"LoRA\". This method adapts large pre-trained language models to new tasks. It does this by changing only a small part of the model. This makes the method very efficient. The small changed part targets the most important information needed for the new task. This allows quick customization of the model for new uses.\n",
    "\n",
    "`peft` is an open source library from HuggingFace to easily run parameter-efficient fine tuning jobs. That includes the use of LoRA. In addition, we'll use int-8 quantization to further increase efficiency.\n",
    "LoRA + quantization enables us to use less GPU memory (VRAM) to train large language models, giving us more compute flexibility.\n",
    "\n",
    "### What is ESM-2?\n",
    "\n",
    "[ESM-2](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1) is a pLM trained using unsupervied masked language modelling on 250 Million protein sequences by researchers at [Facebook AI Research (FAIR)](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1). It is available in several sizes, ranging from 8 Million to 15 Billion parameters. The smaller models are suitable for various sequence and token classification tasks. The FAIR team also adapted the 3 Billion parameter version into the ESMFold protein structure prediction algorithm. They have since used ESMFold to predict the struture of [more than 700 Million metagenomic proteins](https://esmatlas.com/about). \n",
    "\n",
    "ESM-2 is a powerful pLM. However, it has traditionally required multiple A100 GPU chips to fine-tune. In this notebook, we demonstrate how to use QLoRA to fine-tune ESM-2 in on an inexpensive Amazon SageMaker training instance. We will use ESM-2 to predict [subcellular localization](https://academic.oup.com/nar/article/50/W1/W228/6576357). Understanding where proteins appear in cells can help us understand their role in disease and find new drug targets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75cb75-18ed-4211-aa13-3edfccd59e4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 1. Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f744fde-5624-46e2-b5a5-6d6dc1c58b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -q -U --disable-pip-version-check -r notebook-requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2497ac7-2c19-4668-9bf5-40c1636ce44b",
   "metadata": {},
   "source": [
    "Load the sagemaker package and create some service clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a0ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datasets import Dataset, DatasetDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.huggingface import HuggingFace, HuggingFaceModel\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from time import strftime\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173667ca-7637-4c44-9a97-a4c7ecb076f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto_session = boto3.session.Session()\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "s3 = boto_session.client(\"s3\")\n",
    "sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "sagemaker_execution_role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "REGION_NAME = sagemaker_session.boto_region_name\n",
    "print(f\"Assumed SageMaker role is {sagemaker_execution_role}\")\n",
    "\n",
    "S3_PREFIX = \"esm-loc-ft\"\n",
    "S3_PATH = sagemaker.s3.s3_path_join(\"s3://\", S3_BUCKET, S3_PREFIX)\n",
    "print(f\"S3 path is {S3_PATH}\")\n",
    "\n",
    "EXPERIMENT_NAME = \"esm-loc-ft-\" + strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(f\"Experiment name is {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09081bc9-1dd0-490c-a0b0-07207cbbaebc",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 2. Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b083b46-c53a-4e3b-bd3a-11cb149b5ae2",
   "metadata": {},
   "source": [
    "We'll use a version of the [DeepLoc-2 data set](https://services.healthtech.dtu.dk/services/DeepLoc-2.0/) to fine tune our localization model. It consists of several thousand protein sequences, each with one or more experimentally-observed location labels. This data was extracted by the DeepLoc team at Technical University of Denmark from the public [UniProt sequence database](https://www.uniprot.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65745694-51ca-47bb-89fa-6cf97a9dfd41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://services.healthtech.dtu.dk/services/DeepLoc-2.0/data/Swissprot_Train_Validation_dataset.csv\"\n",
    ").drop([\"Unnamed: 0\", \"Partition\"], axis=1)\n",
    "df[\"Membrane\"] = df[\"Membrane\"].astype(\"float32\")\n",
    "\n",
    "# filter for sequences between 100 and 512 amino acides\n",
    "df = df[df[\"Sequence\"].apply(lambda x: len(x)).between(100, 512)]\n",
    "train = df.sample(frac=0.8)\n",
    "df = df.drop(train.index)\n",
    "val = df.sample(frac=0.5)\n",
    "test = df.drop(val.index)\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_pandas(train, split=\"train\"),\n",
    "        \"test\": Dataset.from_pandas(test, split=\"test\"),\n",
    "        \"validation\": Dataset.from_pandas(val, split=\"validation\"),\n",
    "    }\n",
    ")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b064d2-b2c4-4354-b87b-c44a66ece6c3",
   "metadata": {},
   "source": [
    "Let's look at the length distribution of our training sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2b4bc2-50f6-4d0f-939b-ca6cbbd67047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(train[\"Sequence\"].apply(lambda x: len(x)).sort_values(), bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4de99-aadc-4ca9-90b3-0a340a3d96aa",
   "metadata": {},
   "source": [
    "Identify the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d44f457-b515-4697-80f9-3b79b50f2829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [\n",
    "    label\n",
    "    for label in dataset[\"train\"].features.keys()\n",
    "    if label not in [\"ACC\", \"Kingdom\", \"Membrane\", \"Sequence\"]\n",
    "]\n",
    "id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447f4051-8f4d-45bb-939e-5f24cf252022",
   "metadata": {},
   "source": [
    "Next, we tokenize the sequences and trim them to a max length of 512 amino acids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941e433-ef3e-4d3b-9b73-19e2545eff6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t36_3B_UR50D\")\n",
    "\n",
    "\n",
    "def preprocess_data(examples, max_length=512):\n",
    "    text = examples[\"Sequence\"]\n",
    "    encoding = tokenizer(\n",
    "        text, padding=\"max_length\", truncation=True, max_length=max_length\n",
    "    )\n",
    "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "    labels_matrix = np.zeros((len(text), len(labels)))\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "    encoding[\"labels\"] = labels_matrix.tolist()\n",
    "    return encoding\n",
    "\n",
    "\n",
    "encoded_dataset = dataset.map(\n",
    "    preprocess_data,\n",
    "    batched=True,\n",
    "    num_proc=os.cpu_count(),\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n",
    "encoded_dataset.set_format(\"torch\")\n",
    "print(encoded_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33176a99-52de-45f8-ab38-c4a86812a7bc",
   "metadata": {},
   "source": [
    "Look at an example record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472268de-85c1-4ea9-894b-8d0e6087257a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example = encoded_dataset[\"train\"][0]\n",
    "print(tokenizer.decode(example[\"input_ids\"]))\n",
    "print(example[\"labels\"])\n",
    "print([id2label[idx] for idx, label in enumerate(example[\"labels\"]) if label == 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519980a9-32ef-4b44-a2d5-ca54bcf89790",
   "metadata": {},
   "source": [
    "Finally, we upload the processed training, test, and validation data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd371e0-2481-47c9-9c3b-4755fd51e4cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_dataset[\"train\"].save_to_disk(S3_PATH + \"/data/train\")\n",
    "encoded_dataset[\"test\"].save_to_disk(S3_PATH + \"/data/test\")\n",
    "encoded_dataset[\"validation\"].save_to_disk(S3_PATH + \"/data/validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef0f40-a011-4f19-8b40-418fbd3962b7",
   "metadata": {},
   "source": [
    "If you already have your training and test data prepared in a csv, save the paths in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133b9e14-3896-4a63-929f-55efe0079b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_s3_uri = S3_PATH + \"/data/train\"\n",
    "test_s3_uri = S3_PATH + \"/data/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbc9cf1-76d0-4c01-9dc3-b4a0f0802a03",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 3. Submit SageMaker Training Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c1f99-4f6b-492c-9be0-973f941df9f4",
   "metadata": {},
   "source": [
    "Next, we'll process the 3 Billion-parameter model with LoRA and train on a ml.g5.2xlarge instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c5ff7-f4c2-46c5-9639-788584059586",
   "metadata": {},
   "source": [
    "Define the metrics for SageMaker to extract from the job logs and send to SageMaker Experiments. You can customize these to log more or fewer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429cc003-7218-4933-962c-a2bb68cedf1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"'epoch': ([0-9.]*)\"},\n",
    "    {\"Name\": \"train_loss\", \"Regex\": \"'loss': ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"learning_rate\", \"Regex\": \"'learning_rate': ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"train_runtime\", \"Regex\": \"'train_runtime': ([0-9.e-]*)\"},\n",
    "    {\n",
    "        \"Name\": \"train_samples_per_second\",\n",
    "        \"Regex\": \"'train_samples_per_second': ([0-9.e-]*)\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"train_steps_per_second\",\n",
    "        \"Regex\": \"'train_steps_per_second': ([0-9.e-]*)\",\n",
    "    },\n",
    "    {\"Name\": \"eval_loss\", \"Regex\": \"'eval_loss': ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"eval_accuracy\", \"Regex\": \"'eval_accuracy': ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"eval_f1\", \"Regex\": \"'eval_f1': ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"eval_roc_auc\", \"Regex\": \"'eval_roc_auc': ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"eval_runtime\", \"Regex\": \"'eval_runtime': ([0-9.e-]*)\"},\n",
    "    {\n",
    "        \"Name\": \"eval_samples_per_second\",\n",
    "        \"Regex\": \"'eval_samples_per_second': ([0-9.e-]*)\",\n",
    "    },\n",
    "    {\"Name\": \"eval_steps_per_second\", \"Regex\": \"'eval_steps_per_second': ([0-9.e-]*)\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc23c03c-0abf-4c9d-b7ce-3837c3c6af6f",
   "metadata": {},
   "source": [
    "### 3.1. Fine-Tune ESM-2 3B on ml.g5.2xlarge using LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd96073-8068-460a-9176-d87f232d094a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Additional training parameters\n",
    "hyperparameters = {\n",
    "    \"epochs\": 2,\n",
    "    \"max_length\": 512,\n",
    "    \"model_id\": \"facebook/esm2_t36_3B_UR50D\",\n",
    "    \"num_labels\": 10,\n",
    "    \"problem_type\": \"multi_label_classification\",\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"per_device_eval_batch_size\": 32,\n",
    "    \"gradient_accumulation_steps\": 16,\n",
    "}\n",
    "\n",
    "# creates Hugging Face estimator\n",
    "huggingface_estimator_g5_3b = HuggingFace(\n",
    "    base_job_name=\"esm-3B-loc-ft-lora\",\n",
    "    entry_point=\"lora-train.py\",\n",
    "    source_dir=\"scripts/training/peft\",\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    instance_count=1,\n",
    "    transformers_version=\"4.28\",\n",
    "    pytorch_version=\"2.0\",\n",
    "    py_version=\"py310\",\n",
    "    output_path=f\"{S3_PATH}/output\",\n",
    "    role=sagemaker_execution_role,\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    checkpoint_local_path=\"/opt/ml/checkpoints\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    tags=[{\"Key\": \"project\", \"Value\": \"esm-ft\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f89d80-3b2f-4360-8a47-ccf5f0120891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with Run(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    huggingface_estimator_g5_3b.fit(\n",
    "        {\n",
    "            \"train\": TrainingInput(s3_data=train_s3_uri, input_mode=\"File\"),\n",
    "            \"test\": TrainingInput(s3_data=test_s3_uri, input_mode=\"File\"),\n",
    "        },\n",
    "        wait=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba110cf-b9fe-4e70-8443-671a3a8a88fc",
   "metadata": {},
   "source": [
    "This training job will take 2 to 3 hours to finish on a ml.g5.2xlarge instance type.\n",
    "\n",
    "You can view metrics and debugging information for both of these runs in SageMaker Experiments. On the left-side navigation panel, select the Home icon, then \"Experiments\". From there, you can select your experiment name and training job name and view the Debugger insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253c9aa3-e09f-41d8-a069-a184204c2c0c",
   "metadata": {},
   "source": [
    "### 3.2. (Optional) Fine-Tune ESM-2 3B on ml.p4d.24xlarge without LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46c938-0e6b-4d1d-9213-455423c0d545",
   "metadata": {},
   "source": [
    "Uncomment the next cell to fine-tune ESM-2 3B without LoRA. Because of the model size, this requires a ml.p4d.24xlarge instance type with 8xA100 GPUs. To speed up our training, we can use data-distributed parallel (DDP) training to share the samples across all GPU chips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f297e4df-3a02-4b2c-9e01-0fb7831c5653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Additional training parameters\n",
    "# hyperparameters = {\n",
    "#     \"epochs\": 2,\n",
    "#     \"max_length\": 512,\n",
    "#     \"model_id\": \"facebook/esm2_t36_3B_UR50D\",\n",
    "#     \"num_labels\": 10,\n",
    "#     \"problem_type\": \"multi_label_classification\",\n",
    "#     \"per_device_train_batch_size\": 32,\n",
    "#     \"optim\": \"adamw_torch\",\n",
    "#     \"per_device_eval_batch_size\": 32,\n",
    "# }\n",
    "\n",
    "# # creates Hugging Face estimator\n",
    "# huggingface_estimator_p4d_3b = HuggingFace(\n",
    "#     base_job_name=\"esm-3B-p4d-loc-ft-no-lora\",\n",
    "#     entry_point=\"train.py\",\n",
    "#     source_dir=\"scripts/training/peft\",\n",
    "#     instance_type=\"ml.p4d.24xlarge\",\n",
    "#     instance_count=1,\n",
    "#     transformers_version=\"4.28.1\",\n",
    "#     pytorch_version=\"2.0.0\",\n",
    "#     py_version=\"py310\",\n",
    "#     output_path=f\"{S3_PATH}/output\",\n",
    "#     role=sagemaker_execution_role,\n",
    "#     hyperparameters=hyperparameters,\n",
    "#     metric_definitions=metric_definitions,\n",
    "#     checkpoint_local_path=\"/opt/ml/checkpoints\",\n",
    "#     sagemaker_session=sagemaker_session,\n",
    "#     tags=[{\"Key\": \"project\", \"Value\": \"esm-ft\"}],\n",
    "# )\n",
    "\n",
    "# with Run(\n",
    "#     experiment_name=EXPERIMENT_NAME,\n",
    "#     sagemaker_session=sagemaker_session,\n",
    "# ) as run:\n",
    "#     huggingface_estimator_p4d_3b.fit(\n",
    "#         {\n",
    "#             \"train\": TrainingInput(s3_data=train_s3_uri, input_mode=\"File\"),\n",
    "#             \"test\": TrainingInput(s3_data=test_s3_uri, input_mode=\"File\"),\n",
    "#         },\n",
    "#         wait=False,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca12bb0-8bec-4e33-b2a6-0542ba13b50e",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Deploy LoRA Model as Real-Time Inference Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e17487-bd97-4cc6-a116-06945d15402c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    model_data=huggingface_estimator_g5_3b.model_uri,\n",
    "    role=sagemaker_execution_role,\n",
    "    transformers_version=\"4.28.1\",\n",
    "    pytorch_version=\"2.0.0\",\n",
    "    py_version=\"py310\",\n",
    "    model_server_workers=1,\n",
    "    env={\"HF_TASK\": \"text-classification\"},\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\"\n",
    "    role=sagemaker_execution_role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ec68e-b12f-4dc6-a58b-947cc494ad5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_seq = \"MAAAVVLAAGLRAARRAVAATGVRGGQVRGAAGVTDGNEVAKAQQATPGGAAPTIFSRILDKSLPADILYEDQQCLVFRDVAPQAPVHFLVIPKKPIPRISQAEEEDQQLLGHLLLVAKQTAKAEGLGDGYRLVINDGKLGAQSVYHLHIHVLGGRQLQWPPG\"\n",
    "sample = {\"inputs\": test_seq}\n",
    "predictor.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f4e10a-0152-4e03-931c-cb2820a8e337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    predictor.delete_endpoint()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e573c-4c2d-4fc8-bb22-827342f47666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
