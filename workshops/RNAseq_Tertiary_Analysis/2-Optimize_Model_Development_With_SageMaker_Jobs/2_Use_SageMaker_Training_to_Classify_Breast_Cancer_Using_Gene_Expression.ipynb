{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2: Breast Cancer Classification using Gene Expression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Use SageMaker processing, training, and hyperparameter tuning jobs to optimize cost and performance\n",
    "- Compare model performance using SageMaker Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Notes:\n",
    "This notebook was created and tested on an `ml.t3.medium (2 vCPU + 4 GiB)` notebook instance running the `Python 3 (Data Science)` kernel in SageMaker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Background](#1.-Background)\n",
    "    1. [Jobs](#1.A.-Jobs)\n",
    "    1. [Experiments](#1.B.-Experiments)\n",
    "1. [Preparation](#2.-Preparation)\n",
    "    1. [Import Python libraries](#2.A.-Import-Python-Libraries)\n",
    "    1. [Create Some Necessary Clients](#2.B.-Create-some-necessary-clients)\n",
    "    1. [Create an Experiment](#2.C.-Create-an-experiment)\n",
    "    1. [Specify S3 Bucket and Prefix](#2.D.-Specify-S3-bucket-and-prefix)\n",
    "    1. [Define Local Working Directories](#2.E.-Define-local-working-directories)\n",
    "1. [Data Preparation with Amazon SageMaker Processing](#3.-Data-Preparation-with-Amazon-SageMaker-Processing)\n",
    "    1. [Upload Raw Data to S3](#3.A.-Upload-Raw-Data-to-S3)\n",
    "    1. [Submit SageMaker Processing Job](#3.B.-Submit-SageMaker-Processing-Job)\n",
    "1. [Model Training](#4.-Model-Training)\n",
    "    1. [Train Model Using a SKLearn Random Forest Algorithm](#4.A.-Train-Model-Using-a-SKLearn-Random-Forest-Algorithm)\n",
    "    1. [Train Model using a Keras MLP](#4.B.-Train-Model-using-a-Keras-MLP)\n",
    "    1. [Train Model Using the XGBoost Algorithm](#4.C.-Train-Model-Using-the-XGBoost-Algorithm)\n",
    "1. [Model Evaluation](#5.-Model-Evaluation)\n",
    "    1. [Download and Run the Trained XGBoost Model](#5.A.-Download-and-Run-the-Trained-XGBoost-Model)\n",
    "    1. [Compare Model Results Using SageMaker Experiments](#5.B.-Compare-Model-Results-Using-SageMaker-Experiments)\n",
    "1. [Hyperparameter Optimization](#6.-Hyperparameter-Optimization)\n",
    "    1. [Submit Hyperparameter Optimization Job](#6.A-Submit-Hyperparameter-Optimization-Job)\n",
    "    1. [Add HPO Job to Experiment](#6.B-Add-HPO-Job-to-Experiment)\n",
    "    1. [Deploy Best Model](#6.C-Deploy-Best-Model)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Background\n",
    "In notebook 1 of this series, we demonstrated using RNAseq data to predict HER2 status using the compute resources on the notebook server. However, using notebook server resources to process large amounts of data or train complex models is generally not a good idea. It's possible to scale up your notebook server, but any time you spend on non-compute intensive tasks (i.e. most of your time) will be wasted. A better idea is to run your notebook on a small server and submit compute-intensive tasks to independent jobs. SageMaker provides managed services for running data processing, model training, and hyperparameter tuning jobs. In this notebook, we'll demonstrate how to leverage these services to optimize the performance and cost of our tasks.\n",
    "\n",
    "Specifically, we'll demonstrate two best practices: **Jobs** and **Experiments**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.A. SageMaker Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html) processing, training, and hyperparameter optimization (HPO) jobs allow data scientists to submit compute-heavy processes to external services. This keeps costs optimized and ensures that these tasks run in reproducible environments. It also improves data scientist productivity by allowing these jobs to run in \"the background\" and provides resiliancy if something happens to your notebook environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/jobs.png \"Jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.B. SageMaker Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/experiments.png \"Experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SageMaker Experiments](https://aws.amazon.com/blogs/aws/amazon-sagemaker-experiments-organize-track-and-compare-your-machine-learning-trainings) make it as easy as possible to track data preparation and analysis steps. Organizing your ML project into experiments helps you manage large numbers of trials and alternative algorithms. Experiments also ensure that any artifacts your generate for production use can be traced back to their source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Preparation\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The Python libraries that we'll use throughout the analysis\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.A. Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt -q -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import boto3\n",
    "from botocore.client import ClientError\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sagemaker\n",
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.search_expression import Filter, Operator, SearchExpression\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from time import strftime, sleep\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.B. Create Some Necessary Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "sm_session = sagemaker.session.Session(session)\n",
    "region = session.region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "s3 = boto3.client(\"s3\", region_name=region)\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.C. Create an Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new SageMaker experiment specific to our scientific goal, in this case to predict HER2 status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_date = strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "brca_her2_experiment = Experiment.create(\n",
    "    experiment_name=f\"BRCA-HER2-{create_date}\",\n",
    "    description=\"Predict HER2 status using TCGA RNAseq data.\",\n",
    "    tags=[{\"Key\": \"Creator\", \"Value\": \"arosalez\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.D. Specify S3 Bucket and Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = f\"brca-her2-classifier-{account_id}\"\n",
    "print(f\"S3 bucket name is {bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.E. Define Local Working Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(WORKING_DIR, \"data\")\n",
    "print(f\"Working directory is {WORKING_DIR}\")\n",
    "print(f\"Data directory is {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preparation  with Amazon SageMaker Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Processing allows you to run steps for data pre- or post-processing, feature engineering, data validation, or model evaluation workloads on Amazon SageMaker. Processing jobs accept data from Amazon S3 as input and store data into Amazon S3 as output.\n",
    "\n",
    "![processing](https://sagemaker.readthedocs.io/en/stable/_images/amazon_sagemaker_processing_image1.png)\n",
    "\n",
    "Here, we'll import the dataset and transform it with SageMaker Processing, which can be used to process terabytes of data in a SageMaker-managed cluster separate from the instance running your notebook server. In a typical SageMaker workflow, notebooks are only used for prototyping and can be run on relatively inexpensive and less powerful instances, while processing, training and model hosting tasks are run on separate, more powerful SageMaker-managed instances.  SageMaker Processing includes off-the-shelf support for Scikit-learn, as well as a Bring Your Own Container option, so it can be used with many different data transformation technologies and tasks.    \n",
    "\n",
    "To use SageMaker Processing, simply supply a Python data preprocessing script as shown below.  For this example, we're using a SageMaker prebuilt Scikit-learn container, which includes many common functions for processing data.  There are few limitations on what kinds of code and operations you can run, and only a minimal contract:  input and output data must be placed in specified directories.  If this is done, SageMaker Processing automatically loads the input data from S3 and uploads transformed data back to S3 when the job is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.A. Upload Raw Data to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directories\n",
    "WORKING_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(WORKING_DIR, \"data\")\n",
    "print(f\"Working directory is {WORKING_DIR}\")\n",
    "print(f\"Data directory is {DATA_DIR}\")\n",
    "\n",
    "# Get TCGA BRCA Gene Expression Data\n",
    "!wget https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/HiSeqV2_PANCAN.gz -nc -P $DATA_DIR/input/raw/\n",
    "!gzip -df $DATA_DIR/input/raw/HiSeqV2_PANCAN.gz\n",
    "\n",
    "# Get TCGA BRCA Phenotype Data\n",
    "!wget https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/BRCA_clinicalMatrix -nc -P $DATA_DIR/input/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if bucket already exists. If it does not, create it\n",
    "try:\n",
    "    s3.head_bucket(Bucket=bucket_name)\n",
    "except ClientError:\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "    print(f\"Created Bucket: {bucket_name} in Region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_source = sm_session.upload_data(\n",
    "    f\"{DATA_DIR}/input/raw/BRCA_clinicalMatrix\",\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=\"data/input\",\n",
    ")\n",
    "RNAseq_source = sm_session.upload_data(\n",
    "    f\"{DATA_DIR}/input/raw/HiSeqV2_PANCAN\", bucket=bucket_name, key_prefix=\"data/input\"\n",
    ")\n",
    "print(f\"Clinical phenotypes now available at {clinical_source}\")\n",
    "print(f\"Normalized expression data now available at {RNAseq_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.B. Submit SageMaker Processing Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this code block references `scripts/processing/processing.py`. The processing job will run this script on a different compute instance, in this case a ml.m5.xlarge. This allows us to use a small instance for our notebook server, while still taking advantage of a more powerful instance for the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the inputs for the processing job\n",
    "inputs = [\n",
    "    ProcessingInput(\n",
    "        source=f\"s3://{bucket_name}/data/input/\",\n",
    "        destination=\"/opt/ml/processing/input\",\n",
    "        s3_data_distribution_type=\"ShardedByS3Key\",\n",
    "    )\n",
    "]\n",
    "\n",
    "# Define the outputs for the processing job\n",
    "outputs = [\n",
    "    ProcessingOutput(\n",
    "        output_name=\"train\",\n",
    "        source=\"/opt/ml/processing/output/train\",\n",
    "        destination=f\"s3://{bucket_name}/data/output/train/\",\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"validation\",\n",
    "        source=\"/opt/ml/processing/output/val\",\n",
    "        destination=f\"s3://{bucket_name}/data/output/val/\",\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"test\",\n",
    "        source=\"/opt/ml/processing/output/test\",\n",
    "        destination=f\"s3://{bucket_name}/data/output/test/\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.20.0\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "processing_run_name = f\"Processing-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "sklearn_processor.run(\n",
    "    job_name=processing_run_name,\n",
    "    code=\"scripts/processing/processing.py\",\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    experiment_config={\n",
    "        \"ExperimentName\": brca_her2_experiment.experiment_name,\n",
    "        \"TrialComponentDisplayName\": processing_run_name,\n",
    "    },\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Processed Data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session.download_data(\n",
    "    f\"{DATA_DIR}/output/train\",\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=\"data/output/train/train.csv\",\n",
    ")\n",
    "sm_session.download_data(\n",
    "    f\"{DATA_DIR}/output/val\", bucket=bucket_name, key_prefix=\"data/output/val/val.csv\"\n",
    ")\n",
    "sm_session.download_data(\n",
    "    f\"{DATA_DIR}/output/test\",\n",
    "    bucket=bucket_name,\n",
    "    key_prefix=\"data/output/test/test.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our training data is set up, we can train some models. To highlight the benefits of experiment tracking, we're going to train models using three different frameworks:\n",
    "- The random forest model from Scikit Learm\n",
    "- A multi-layer perceptron (MLP) neural network in Keras\n",
    "- The open-source XGBoost algorithm\n",
    "\n",
    "Since we're using SageMaker jobs to run our training, we don't need to install any additional libraries or spin up expensive compute resources on our notebook server. The jobs use their own dependencies and we're only charged for the time they run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define some variables that all three training jobs will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "content_type = \"text/csv\"\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{bucket_name}/data/output/train/train.csv\", content_type=content_type\n",
    ")\n",
    "\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{bucket_name}/data/output/val/val.csv\", content_type=content_type\n",
    ")\n",
    "\n",
    "s3_input_test = sagemaker.inputs.TrainingInput(\n",
    "    f\"s3://{bucket_name}/data/output/test/test.csv\", content_type=content_type\n",
    ")\n",
    "\n",
    "model_output_path = f\"s3://{bucket_name}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.A. Train Model Using a SKLearn Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_trial = Trial.create(\n",
    "    trial_name=f\"RF-Trial-{strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "    experiment_name=brca_her2_experiment.experiment_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again we're passing a script (`scripts/rf_train/rf_train.py`) to run during the training job. Notice that we've also included a `requirements.txt` file in the training script directory to install additional dependencies in the training container. This is a great way to install an extra package or two without creating your own container image from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting `wait=False` allows us to continue running the notebook while the training job runs in \"the background\" (on a different machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_job_name = f\"RF-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "rf_estimator = SKLearn(\n",
    "    entry_point=\"rf_train.py\",\n",
    "    source_dir=\"scripts/rf_train\",\n",
    "    output_path=model_output_path,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    enable_sagemaker_metrics=True,\n",
    "    base_job_name=rf_job_name,\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": 100,\n",
    "        \"min-samples-leaf\": 3,\n",
    "    },\n",
    ")\n",
    "\n",
    "rf_estimator.fit(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation, \"test\": s3_input_test},\n",
    "    job_name=rf_job_name,\n",
    "    experiment_config={\n",
    "        \"TrialName\": rf_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": rf_job_name,\n",
    "    },\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can also run the same training script in the notebook, as long as you have the dependencies installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/rf_train/rf_train.py --n-estimators 100 \\\n",
    "                   --min-samples-leaf 3 \\\n",
    "                   --model-dir models \\\n",
    "                   --train \"data/output/train\" \\\n",
    "                   --validation \"data/output/val\" \\\n",
    "                   --test \"data/output/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.B. Train Model using a Keras MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_trial = Trial.create(\n",
    "    trial_name=f\"TF-Trial-{strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "    experiment_name=brca_her2_experiment.experiment_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_job_name = f\"TF-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "tf_estimator = TensorFlow(\n",
    "    entry_point=\"tf_train.py\",\n",
    "    source_dir=\"scripts/tf_train\",\n",
    "    output_path=model_output_path,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    enable_sagemaker_metrics=True,\n",
    "    framework_version=\"2.2\",\n",
    "    py_version=\"py37\",\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"test:accuracy\", \"Regex\": \"Accuracy: ([0-9.]+)$\"},\n",
    "        {\"Name\": \"test:precision\", \"Regex\": \"Precision: ([0-9.]+)$\"},\n",
    "        {\"Name\": \"test:f1\", \"Regex\": \"F1 Score: ([0-9.]+)$\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "tf_estimator.fit(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation, \"test\": s3_input_test},\n",
    "    job_name=tf_job_name,\n",
    "    experiment_config={\n",
    "        \"TrialName\": tf_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": tf_job_name,\n",
    "    },\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.C. Train Model Using the XGBoost Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the XGBoost training script we're about to run (scripts/rf_train/rf_train.py) with the training function we used in Notebook 1. You'll notice that the `xgb.train` call is the same in both!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're setting `wait=True` our Jupyter session will wait until this training job is finished before moving on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_trial = Trial.create(\n",
    "    trial_name=f\"XGBoost-Trial-{strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "    experiment_name=brca_her2_experiment.experiment_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_job_name = f\"XGB-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "framework_version = \"1.3-1\"\n",
    "py_version = \"py3\"\n",
    "\n",
    "hyper_params_dict = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"eval_metric\": \"error\",\n",
    "}\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    entry_point=\"xgb_train.py\",\n",
    "    source_dir=\"scripts/xgb_train\",\n",
    "    output_path=model_output_path,\n",
    "    framework_version=framework_version,\n",
    "    py_version=py_version,\n",
    "    hyperparameters=hyper_params_dict,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    # Workaround for https://github.com/aws/sagemaker-python-sdk/issues/2876\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"xgboost\", region, framework_version)\n",
    "    + \"-cpu-\"\n",
    "    + py_version,\n",
    "    enable_sagemaker_metrics=True,\n",
    ")\n",
    "\n",
    "xgb_estimator.fit(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation, \"test\": s3_input_test},\n",
    "    job_name=xgb_job_name,\n",
    "    experiment_config={\n",
    "        \"TrialName\": xgb_trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": xgb_job_name,\n",
    "    },\n",
    "    logs=True,\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.A. Download and Run the Trained XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Notebook 1, we used a confusion matrix to evaluate the accuracy of our model. Let's download our trained XGBoost model and do the same thing here.\n",
    "\n",
    "First, we download the model artifact from S3 and load it into our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session.download_data(\n",
    "    \"models\", bucket=bucket_name, key_prefix=f\"{xgb_job_name}/output/model.tar.gz\"\n",
    ")\n",
    "!tar xvfz models/model.tar.gz -C models\n",
    "\n",
    "loaded_model = pickle.load(open(\"models/xgboost-model\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read in the test data and seperate it into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_DIR}/output/test/test.csv\", \"rb\") as file:\n",
    "    test_np = np.loadtxt(file, delimiter=\",\")\n",
    "test_labels = test_np[:, 0]\n",
    "test_np = test_np[:, 1:]\n",
    "test_dm = xgb.DMatrix(test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we define a function for generating a confusion matrix and use it to analyze our test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom function for generating a confusion matrix for a given p-value\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title(\"Confusion matrix @{:.2f}\".format(p))\n",
    "    plt.ylabel(\"Actual label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "\n",
    "    if len(set(list(labels))) == 2:\n",
    "        print(\"Correctly un-detected (True Negatives): \", cm[0][0])\n",
    "        print(\"Incorrectly detected (False Positives): \", cm[0][1])\n",
    "        print(\"Misses (False Negatives): \", cm[1][0])\n",
    "        print(\"Hits (True Positives): \", cm[1][1])\n",
    "        print(\"Total: \", np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "test_predictions = loaded_model.predict(test_dm)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, np.rint(test_predictions))\n",
    "precision = precision_score(test_labels, np.rint(test_predictions))\n",
    "f1 = f1_score(test_labels, np.rint(test_predictions))\n",
    "\n",
    "plot_cm(test_labels, np.array(test_predictions))\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.B. Compare Model Results Using SageMaker Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker Experiments saves key information about our models for easy viewing and comparison in the SageMaker Studio UI.\n",
    "\n",
    "To start, click on the SageMaker Resources icon on the Studio sidebar and select `Experiments and trials` from the menu. To view information about your experiment click on the name (should start with \"BRCA-HER2-\" and then select `Open in trial component list`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/sm-resources-tab.png \"Studio Resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Trial Component list has a record for each of the training jobs, plus the processing job. You can click on a trial component name for more information about that job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/Trial-component-list.png \"Trial Component List\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the performance of our model training jobs by adding an additional metric to the table. To do this, click on the Gear on the Studio sidebar and then `test:f1` in the Metrics section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/metrics.png \"Metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the XGBoost model had the highest f1 score on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/tc-list-2.png \"Updated Trial Component List\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the same information programmatically by using the `ExperimentAnalytics` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_expression = {\n",
    "    \"Filters\": [\n",
    "        {\n",
    "            \"Name\": \"DisplayName\",\n",
    "            \"Operator\": \"Contains\",\n",
    "            \"Value\": \"Training\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "trial_component_analytics = ExperimentAnalytics(\n",
    "    sagemaker_session=sm_session,\n",
    "    experiment_name=brca_her2_experiment.experiment_name,\n",
    "    search_expression=search_expression,\n",
    "    sort_by=\"metrics.test:f1.last\",\n",
    "    sort_order=\"Descending\",\n",
    "    metric_names=[\"test:f1\"],\n",
    "    parameter_names=[\"SageMaker.InstanceType\"],\n",
    ")\n",
    "\n",
    "trial_component_analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we saw that our XGBoost classifier gave the best results on our test dataset. However, we can likely improve its accuracy further through hyperparameter optimization (HPO). During HPO, we repeatedly train our model with small changes to one or more parameters each time. SageMaker Training is a great fit for this because it allows us to run multiple training jobs in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.A. Submit Hyperparameter Optimization Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll look at different values of the `alpha` and `eta` hyperparameters to see if we can decrease the error of our model on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"alpha\": IntegerParameter(0, 250, scaling_type=\"Auto\"),\n",
    "    \"eta\": ContinuousParameter(0.1, 0.5, scaling_type=\"Auto\"),\n",
    "}\n",
    "\n",
    "hpo_tuner = HyperparameterTuner(\n",
    "    xgb_estimator,\n",
    "    objective_metric_name=\"validation:error\",\n",
    "    objective_type=\"Minimize\",\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=10,\n",
    ")\n",
    "\n",
    "hpo_tuner.fit(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation, \"test\": s3_input_test},\n",
    "    include_cls_metadata=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View tuning job results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner_description = hpo_tuner.describe()\n",
    "objective_name = tuner_description[\"HyperParameterTuningJobConfig\"][\n",
    "    \"HyperParameterTuningJobObjective\"\n",
    "][\"MetricName\"]\n",
    "tuner = hpo_tuner.analytics()\n",
    "tuning_results = tuner.dataframe().sort_values(by=\"FinalObjectiveValue\")\n",
    "tuning_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize what impact our hyperparameter tuning had on the model error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle(\"Hyperparameter tuning results\")\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "ax1.scatter(tuning_results.alpha, tuning_results.FinalObjectiveValue)\n",
    "ax1.set_xlabel(\"alpha\")\n",
    "ax1.set_ylabel(objective_name)\n",
    "\n",
    "ax2.scatter(tuning_results.eta, tuning_results.FinalObjectiveValue)\n",
    "ax2.set_xlabel(\"eta\")\n",
    "ax2.set_ylabel(objective_name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data suggests that `alpha` less than 100 and `eta` values around 0.5 lead to the lowest error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B. Add HPO Job to Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HPO training jobs automatically create new, unassigned trial components in SageMaker Experiments. To view them alongside our other trials, we need to manually associated them to our experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpo_trial = Trial.create(\n",
    "    trial_name=f\"HPO-Trial-{strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "    experiment_name=brca_her2_experiment.experiment_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for the training job names that contain the tuning job name (and have \"SageMakerTrainingJob\" as the source type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_arn_filter = Filter(\n",
    "    name=\"TrialComponentName\",\n",
    "    operator=Operator.CONTAINS,\n",
    "    value=tuner_description[\"HyperParameterTuningJobName\"],\n",
    ")\n",
    "source_type_filter = Filter(\n",
    "    name=\"Source.SourceType\", operator=Operator.EQUALS, value=\"SageMakerTrainingJob\"\n",
    ")\n",
    "\n",
    "search_expression = SearchExpression(filters=[source_arn_filter, source_type_filter])\n",
    "\n",
    "trial_component_search_results = list(\n",
    "    TrialComponent.search(search_expression=search_expression)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate the trial components with the trial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tc in trial_component_search_results:\n",
    "    print(\n",
    "        f\"Associating trial component {tc.trial_component_name} with trial {hpo_trial.trial_name}.\"\n",
    "    )\n",
    "    hpo_trial.add_trial_component(tc.trial_component_name)\n",
    "    sleep(0.5)  # sleep to avoid throttling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can view the HPO jobs in the SageMaker Studio UI alongside the training jobs we created above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](img/hpo_tc.png \"Trial Component List with HPO jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.C. Deploy Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deploy the best model we first create an estimator from the HPO object, then call `deploy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = hpo_tuner.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this endpoint to make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.serializer = CSVSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "test_df = pd.read_csv(f\"{DATA_DIR}/output/test/test.csv\")\n",
    "\n",
    "print(f\"Prediction for test record 1 is {predictor.predict(test_df.iloc[0,1:])[0]}\")\n",
    "print(f\"Actual label is {test_df.iloc[0,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up your endpoint to avoide ongoing charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook, we'll look at deployment options in more detail."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
