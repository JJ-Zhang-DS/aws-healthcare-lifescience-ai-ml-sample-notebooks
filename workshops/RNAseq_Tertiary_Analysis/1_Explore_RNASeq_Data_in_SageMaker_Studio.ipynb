{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Train a Breast Cancer Classifier using Gene Expression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Download and explore RNAseq data from the Cancer Genome Atlas in a SageMaker Studio Notebook.\n",
    "- Train a classifier using the open-source XGBoost library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Notes\n",
    "This notebook was last tested on a `ml.t3.medium (2 vCPU + 4 GiB)` instance running the `Python 3 (Data Science)` kernel in SageMaker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Background](#1.-Background)\n",
    "2. [Data Preparation](#2.-Data-Preparation)\n",
    "    1. [Download and Unzip Data](#2.1.-Download-and-Unzip-Data)\n",
    "    2. [Load Normalized Gene Expression Data](#2.2.-Load-Normalized-Gene-Expression-Data)\n",
    "    3. [Load Phenotype Data](#2.3.-Load-Phenotype-Data)\n",
    "    4. [Merge the Normalized Gene Expression and Phenotype Data](#2.4.-Merge-the-Normalized-Gene-Expression-and-Phenotype-Data)\n",
    "    5. [Encode Target Variable](#2.5.-Encode-Target-Variable)\n",
    "    6. [Split the Data into Training-Validation-Test Sets](#2.6.-Split-the-Data-into-Training-Validation-Test-Sets)\n",
    "3. [Model Training](#3.-Model-Training)\n",
    "    1. [Train XGBoost Model](#3.1.-Train-XGBoost-Model)\n",
    "    2. [Evaluate the Model Performance](#3.2.-Evaluate-the-Model-Performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increase in biological sequence data and development of sophisticated analysis techniques promises to dramatically improve healthcare. The \"Central Dogma\" of biology claims that the human body operates by transcribing DNA into messenger RNA, which is then translated into proteins. Each step in this process is managed by sequence information. So, the hope of bioinformatics is to decode these sequences and provide insight into their effect and possible alteration.\n",
    "\n",
    "![alt text](img/640px-Gene_structure_eukaryote_2_annotated.png \"Central Dogma\")\n",
    "\n",
    "*The structure and expression of a eukaryotic protein-coding gene. WikiJournal of Medicine 4 (1). DOI:10.15347/wjm/2017.002. ISSN 20024436. [(Wikimedia Commons)](https://commons.wikimedia.org/wiki/File:Gene_structure_eukaryote_2_annotated.svg)*\n",
    "\n",
    "One of the more recent advances in sequence analysis is RNA sequencing (RNAseq). By using high-throughput sequencers, scientists can now capture a \"snapshot\" of what mRNA is present in a sample, and thus what genes are expressed, at any given time. RNAseq does not require prior knowledge of what genes to target and can capture alternatively-spliced variants which have been shown to have a significant impact on disease.\n",
    "\n",
    "In this notebook, we'll demonstrate using RNAseq data from the [Cancer Genome Atlas](https://www.nature.com/articles/nature11412) to predict HER2 status, a binary classification task. Breast cancers cells that overexpress the HER2 receptor[(HER2+)](https://www.cancer.org/cancer/breast-cancer/understanding-a-breast-cancer-diagnosis/breast-cancer-her2-status.html) are responsive to HER2-directed therapies like Herceptin.\n",
    "\n",
    "![alt text](img/overexpression.png \"HER2 Overexpression\")\n",
    "\n",
    "These targeted therapies have significantly improved the survival rate of HER2+ breast cancer patients.\n",
    "\n",
    "![alt text](img/brca_stats.png \"Breast cancer statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we download and combine two datasets from the [UCSC Xena platform](http://xena.ucsc.edu/), based on [The Cancer Genome Atlas](https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga):\n",
    "\n",
    "* [Normalized Gene Expression Data (1,218 samples)](https://xenabrowser.net/datapages/?dataset=TCGA.BRCA.sampleMap%2FHiSeqV2_PANCAN&host=https%3A%2F%2Ftcga.xenahubs.net&removeHub=https%3A%2F%2Fxena.treehouse.gi.ucsc.edu%3A443): TCGA breast invasive carcinoma (BRCA) gene expression data measured experimentally using the IlluminaHiSeq RNAseq platform, mean-normalized (per gene) across all TCGA cohorts. Values in this dataset are generated at UCSC by combining gene expression RNAseq values of all TCGA cohorts. Values for each gene are then mean-centered per gene the data split back into cohorts.\n",
    "\n",
    "* [Phenotypes (1,247 samples)](https://xenabrowser.net/datapages/?dataset=TCGA.BRCA.sampleMap%2FBRCA_clinicalMatrix&host=https%3A%2F%2Ftcga.xenahubs.net&removeHub=https%3A%2F%2Fxena.treehouse.gi.ucsc.edu%3A443): TCGA breast invasive carcinoma (BRCA) clinically-observed phenotypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --disable-pip-version-check -U -q 'xgboost==2.1.0' 'seaborn==0.13.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define working directories\n",
    "WORKING_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(WORKING_DIR, \"data\")\n",
    "print(f\"Working directory is {WORKING_DIR}\")\n",
    "print(f\"Data directory is {DATA_DIR}\")\n",
    "\n",
    "HISEQ_URI = \"https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/HiSeqV2_PANCAN.gz\"\n",
    "BRCA_CLINICAL_MATRIX_URI = (\n",
    "    \"https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/BRCA_clinicalMatrix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Load Normalized Gene Expression Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in RNAseq data file\n",
    "genom = pd.read_csv(HISEQ_URI, compression=\"gzip\", sep=\"\\t\")\n",
    "\n",
    "print(\n",
    "    f\"The gene expression data has {genom.shape[0]} records (genes) and {genom.shape[1]} columns (samples)\\n\"\n",
    ")\n",
    "\n",
    "# Extract list of sample identifiers\n",
    "genom_identifiers = genom[\"sample\"].values.tolist()\n",
    "\n",
    "# Print the first few records\n",
    "print(\"Example gene expression data:\")\n",
    "genom.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Load Phenotype Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phenotypes = pd.read_csv(BRCA_CLINICAL_MATRIX_URI, sep=\"\\t\")\n",
    "print(\n",
    "    f\"The phenotype data has {phenotypes.shape[0]} records (samples) and {phenotypes.shape[1]} columns (phenotypes).\\n\"\n",
    ")\n",
    "\n",
    "# Print the first few records\n",
    "print(\"Example phenotype data:\")\n",
    "phenotypes.loc[[0, 100, 200, 300, 400, 500]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of potential phenotypic values to choose as targets. For this example, let's focus our attention on `HER2_Final_Status_nature2012`.\n",
    "\n",
    "Let's replace any missing HER2 values with `Negative`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes_subset = phenotypes[\n",
    "    [\"sampleID\", \"HER2_Final_Status_nature2012\"]\n",
    "].reset_index(drop=True)\n",
    "print(\n",
    "    f\"Of the {phenotypes_subset.shape[0]} records, only {phenotypes_subset.dropna().shape[0]} have complete HER2 values. Let's replace the missing values with 'Negative'.\\n\"\n",
    ")\n",
    "\n",
    "phenotypes_subset.fillna(\"Negative\", inplace=True)\n",
    "print(\"Example phenotype data:\")\n",
    "phenotypes_subset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Merge the Normalized Gene Expression and Phenotype Data\n",
    "\n",
    "The gene expression and phenotype data are oriented in different directions, so let's transpose the former before we merge them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genom_transpose = (\n",
    "    genom.set_index(\"sample\")\n",
    "    .transpose()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"sampleID\"})\n",
    ")\n",
    "print(\n",
    "    f\"Transposing the gene expression data changes its shape from {genom.shape[0]} x {genom.shape[1]} to {genom_transpose.shape[0]} x {genom_transpose.shape[1]}.\\n\"\n",
    ")\n",
    "\n",
    "# Merge the phenotype data with the transposed gene expression data on `sampleID`\n",
    "df = pd.merge(phenotypes_subset, genom_transpose, on=\"sampleID\", how=\"outer\")\n",
    "print(\n",
    "    f\"The merged data set has {df.shape[0]} records (samples) and {df.shape[1]} columns (features).\\n\"\n",
    ")\n",
    "\n",
    "# Let's look at the results for 6 specific samples.\n",
    "print(\"Example transposed gene expression data:\")\n",
    "df.loc[[0, 100, 200, 300, 400, 500]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Encode Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = [0 if t == \"Negative\" else 1 for t in df[\"HER2_Final_Status_nature2012\"]]\n",
    "df.insert(loc=1, column=\"target\", value=df.pop(\"target\"))\n",
    "\n",
    "# Drop any rows with NaN values\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove the original target values and sample IDs to avoid data leakage\n",
    "df = df.drop([\"HER2_Final_Status_nature2012\", \"sampleID\"], axis=1)\n",
    "\n",
    "df.loc[[0, 100, 200, 300, 400, 500]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the distribution between our positive and negative classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"How many of the samples are positive for HER2?\")\n",
    "print(df.target.value_counts())\n",
    "\n",
    "# count examples in each class to estimate scale_pos_weight value\n",
    "counter = Counter(df.target)\n",
    "scale_pos_weight = counter[0] / counter[1]\n",
    "print(f\"Ratio of positive to negative classes is {scale_pos_weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's review the transformed test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Split the Data into Training-Validation-Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold out 20% of the data for testing\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"target\"])\n",
    "\n",
    "# Hold out an additional 20% of the training data for validaton\n",
    "train_df, val_df = train_test_split(\n",
    "    train_df, test_size=0.2, stratify=train_df[\"target\"]\n",
    ")\n",
    "\n",
    "# Convert labels and features into DMatrix objects for XGBoost\n",
    "train_labels = train_df.pop(\"target\")\n",
    "validation_labels = val_df.pop(\"target\")\n",
    "test_labels = test_df.pop(\"target\")\n",
    "\n",
    "dtrain = xgb.DMatrix(data=train_df, label=train_labels)\n",
    "dval = xgb.DMatrix(data=val_df, label=validation_labels)\n",
    "dtest = xgb.DMatrix(data=test_df, label=test_labels)\n",
    "\n",
    "print(\n",
    "    f\"The training data has {train_df.shape[0]} records and {train_df.shape[1]} columns.\"\n",
    ")\n",
    "print(\n",
    "    f\"The validation data has {val_df.shape[0]} records and {val_df.shape[1]} columns.\"\n",
    ")\n",
    "print(f\"The test data has {test_df.shape[0]} records and {test_df.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params_dict = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"eval_metric\": \"error\",\n",
    "    \"max_depth\": 3,\n",
    "    \"min_child_weight\": 5,\n",
    "    \"subsample\": 0.9,\n",
    "    \"verbosity\": 1,\n",
    "    \"tree_method\": \"auto\",\n",
    "    \"predictor\": \"auto\",\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "}\n",
    "\n",
    "evals_result = {}\n",
    "booster = xgb.train(\n",
    "    params=hyper_params_dict,\n",
    "    dtrain=dtrain,\n",
    "    evals=[(dtrain, \"train\"), (dval, \"validation\")],\n",
    "    num_boost_round=15,\n",
    "    evals_result=evals_result,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(evals_result[\"train\"][\"error\"], label=\"train\")\n",
    "plt.plot(evals_result[\"validation\"][\"error\"], label=\"val\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty good, but it does seem like we're hitting some bias. Next, we'll evaluate model accuracy on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = booster.predict(dtest)\n",
    "accuracy = accuracy_score(test_labels, np.rint(test_predictions))\n",
    "accuracy = accuracy_score(test_labels, np.rint(test_predictions))\n",
    "precision = precision_score(test_labels, np.rint(test_predictions))\n",
    "f1 = f1_score(test_labels, np.rint(test_predictions))\n",
    "\n",
    "p = 0.5\n",
    "cm = confusion_matrix(test_labels, np.array(test_predictions) > p)\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion matrix @{:.2f}\".format(p))\n",
    "plt.ylabel(\"Actual label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.show()\n",
    "\n",
    "if len(set(list(test_labels))) == 2:\n",
    "    print(\"Correctly un-detected (True Negatives): \", cm[0][0])\n",
    "    print(\"Incorrectly detected (False Positives): \", cm[0][1])\n",
    "    print(\"Misses (False Negatives): \", cm[1][0])\n",
    "    print(\"Hits (True Positives): \", cm[1][1])\n",
    "    print(\"Total: \", np.sum(cm[1]))\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook, we'll look at some SageMaker features to improve the cost and performance of this process."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
