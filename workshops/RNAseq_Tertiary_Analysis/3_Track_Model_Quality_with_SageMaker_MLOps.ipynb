{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3. Track Model Quality with SageMaker MLOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Automate Machine Learning Operations (MLOps) with SageMaker Pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Notes:\n",
    "This notebook was created and tested on an `ml.t3.medium (2 vCPU + 4 GiB)` notebook instance running the `Python 3.0 (Data Science)` kernel in SageMaker Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## 1. Background\n",
    "\n",
    "In Notebook 2 of this series, we demonstrated how SageMaker Processing, Training, and Hyperparameter Optimization (HPO) jobs can make the development of new machine learning (ML) models faster and more cost efficient. In this notebook, we'll look at some best practices for deploying and managing your models into production. Many of these practices fall into the category of \"Machine Learning Operations\", or \"MLOps\" and are increasingly a part of many [regulatory and quality requirements](https://www.fda.gov/files/medical%20devices/published/US-FDA-Artificial-Intelligence-and-Machine-Learning-Discussion-Paper.pdf).\n",
    "\n",
    "MLOps plays a key role in the **Model Deployment** and **Model Monitoring/Maintenance** phases of the Machine Learning Lifecycle. For more information, please refer to the [Machine Learning Best Practices in Healthcare and Life Sciences Whitepaper](https://d1.awsstatic.com/whitepapers/ML-best-practices-health-science.pdf?did=wp_card&trk=wp_card).\n",
    "\n",
    "![Machine Learning Life Cycle - Part 1](img/MLLC2.png \"ML Life Cycle - Part 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "[Amazon SageMaker Model Building Pipelines](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines.html) is a tool for building machine learning pipelines that take advantage of direct SageMaker integration. Because of this integration, you can create a pipeline and set up SageMaker Projects for orchestration using a tool that handles much of the step creation and management for you. You can manage these pipelines in the SageMaker Studio UI and automatically capture data and model lineage.\n",
    "\n",
    "One of the challenges with deploying ML solutions is that their effectiveness can change over time.  For example, perhaps the distribution of your data shifts from year-to-year? Or the boundaries of a classification category? In these cases, you want to be able to quickly retrain and deploy new versions of your model, either on a schedule or in response to some event.\n",
    "\n",
    "Amazon SageMaker Pipelines allows us to define reproducible ML processes that we can trigger at will. In this example, we'll use the processing, training, and registration artifacts from above to create a pipeline and demonstrate how to execute it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Preparation\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The Python libraries that we'll use throughout the analysis\n",
    "- The S3 bucket and prefix that you want to use for training and model data.  This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install --disable-pip-version-check -q -U 'boto3==1.35.16' 'sagemaker==2.231.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Create Some Necessary Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.session.Session()\n",
    "region = boto_session.region_name\n",
    "sagemaker_session = sagemaker.session.Session(boto_session)\n",
    "sagemaker_execution_role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "s3_boto_client = boto_session.client(\"s3\")\n",
    "account_id = boto_session.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "print(f\"Assumed SageMaker role is {sagemaker_execution_role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Specify S3 Bucket and Prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET = sagemaker_session.default_bucket()\n",
    "S3_PREFIX = \"brca-her2-classifier\"\n",
    "S3_PATH = sagemaker.s3.s3_path_join(S3_BUCKET, S3_PREFIX)\n",
    "print(f\"S3 path is {S3_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Define Local Working Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(WORKING_DIR, \"data\")\n",
    "print(f\"Working directory is {WORKING_DIR}\")\n",
    "print(f\"Data directory is {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7. Define MLflow parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that you have a running MLFlow server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mlflow_servers = [\n",
    "    summary\n",
    "    for summary in sagemaker_boto_client.list_mlflow_tracking_servers().get(\n",
    "        \"TrackingServerSummaries\"\n",
    "    )\n",
    "    if summary.get(\"TrackingServerStatus\") == \"Created\"\n",
    "]\n",
    "tracking_server_arn = [\n",
    "    server[\"TrackingServerArn\"] for server in running_mlflow_servers\n",
    "][-1]\n",
    "running_mlflow_servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8. Define pipeline inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "\n",
    "hiseq_uri = ParameterString(\n",
    "    name=\"HiSeqURI\",\n",
    "    default_value=\"https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/HiSeqV2_PANCAN.gz\",\n",
    ")\n",
    "brca_clinical_matrix_uri = ParameterString(\n",
    "    name=\"BRCAClinicalURI\",\n",
    "    default_value=\"https://tcga.xenahubs.net/download/TCGA.BRCA.sampleMap/BRCA_clinicalMatrix\",\n",
    ")\n",
    "train_test_split_ratio = ParameterFloat(name=\"TrainTestSplit\", default_value=0.2)\n",
    "gene_count = ParameterInteger(name=\"GeneCount\", default_value=2000)\n",
    "\n",
    "s3_bucket = ParameterString(\n",
    "    name=\"S3Bucket\", default_value=sagemaker_session.default_bucket()\n",
    ")\n",
    "s3_prefix = ParameterString(name=\"S3Prefix\", default_value=\"brca-classifier-pipeline\")\n",
    "\n",
    "# What instance type to use for processing.\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "# What instance type to use for training.\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9. Define additional pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "pipeline_session = PipelineSession()\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"PT1H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Define Data Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import FrameworkProcessor, ProcessingOutput\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "sklearn_processor = FrameworkProcessor(\n",
    "    estimator_cls=SKLearn,\n",
    "    framework_version=\"1.2-1\",\n",
    "    instance_count=1,\n",
    "    instance_type=processing_instance_type,\n",
    "    role=sagemaker_execution_role,\n",
    "    sagemaker_session=pipeline_session,  ########## Pipelines-specific\n",
    ")\n",
    "\n",
    "processing_step_args = sklearn_processor.run(\n",
    "    job_name=f\"data-processing-job-{strftime('%Y-%m-%d-%H-%M-%S')}\",\n",
    "    code=\"scripts/processing/pipeline-processing.py\",\n",
    "    dependencies=[\"scripts/processing/requirements.txt\"],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/output/train\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3:/\",\n",
    "                    s3_bucket,\n",
    "                    s3_prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"train\",\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=\"/opt/ml/processing/output/val\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3:/\",\n",
    "                    s3_bucket,\n",
    "                    s3_prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"validation\",\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/output/test\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3:/\",\n",
    "                    s3_bucket,\n",
    "                    s3_prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"test\",\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    arguments=[\n",
    "        \"--brca_clinical_matrix_url\",\n",
    "        brca_clinical_matrix_uri.to_string(),\n",
    "        \"--hiseq_url\",\n",
    "        hiseq_uri.to_string(),\n",
    "        \"--train_test_split_ratio\",\n",
    "        train_test_split_ratio.to_string(),\n",
    "        \"--gene_count\",\n",
    "        gene_count.to_string(),\n",
    "        \"--create_test_data\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"ProcessBRCAData\", step_args=processing_step_args, cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Define Model Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "content_type = \"text/csv\"\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(\n",
    "    step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "    content_type=content_type,\n",
    ")\n",
    "\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(\n",
    "    step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "    content_type=content_type,\n",
    ")\n",
    "\n",
    "model_output_path = f\"s3://{S3_BUCKET}/{S3_PREFIX}/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "xgb_job_name = f\"XGB-Training-Job-{strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "\n",
    "framework_version = \"1.7-1\"\n",
    "py_version = \"py3\"\n",
    "\n",
    "hyper_params_dict = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"eval_metric\": \"error\",\n",
    "    \"scale_pos_weight\": 9.0,\n",
    "    \"max_depth\": 3,\n",
    "    \"min_child_weight\": 5,\n",
    "    \"subsample\": 0.9,\n",
    "    \"verbosity\": 1,\n",
    "    \"tree_method\": \"auto\",\n",
    "}\n",
    "\n",
    "xgb_estimator = XGBoost(\n",
    "    enable_sagemaker_metrics=True,\n",
    "    entry_point=\"xgb_train.py\",\n",
    "    framework_version=framework_version,\n",
    "    hyperparameters=hyper_params_dict,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=model_output_path,\n",
    "    py_version=py_version,\n",
    "    role=sagemaker_execution_role,\n",
    "    sagemaker_session=pipeline_session,  ########## Pipelines-specific\n",
    "    source_dir=\"scripts/xgb_train\",\n",
    "    environment={\"MLFLOW_TRACKING_ARN\": tracking_server_arn},\n",
    ")\n",
    "\n",
    "training_step_args = xgb_estimator.fit(\n",
    "    {\"train\": s3_input_train, \"validation\": s3_input_validation},\n",
    "    job_name=xgb_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainXGBoost\", step_args=training_step_args, cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Model Registration Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model = Model(\n",
    "    image_uri=xgb_estimator.training_image_uri(),\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=sagemaker_execution_role,\n",
    ")\n",
    "\n",
    "register_model_step_args = model.register(\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=\"brca\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "step_model_create = ModelStep(\n",
    "    name=\"BRCAModelCreationStep\", step_args=register_model_step_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline_name = \"BRCAPipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        hiseq_uri,\n",
    "        brca_clinical_matrix_uri,\n",
    "        train_test_split_ratio,\n",
    "        gene_count,\n",
    "        s3_bucket,\n",
    "        s3_prefix,\n",
    "        processing_instance_type,\n",
    "        training_instance_type,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_model_create],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=sagemaker_execution_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_execution = pipeline.list_executions()[\"PipelineExecutionSummaries\"][0]\n",
    "latest_execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.build_parameters_from_execution(latest_execution[\"PipelineExecutionArn\"])"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "fcd20795596b30c7734a8efd08df92d501ca130112f67abeee93ccff645bf25b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
