{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Multiple Models in Parallel Using SageMaker Training\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "1. Kick off multiple SageMaker Training jobs in parallel for scalable parallel training.\n",
    "2. Register SageMaker build models in [the SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html).\n",
    "3. Use [SageMaker Experiments](https://aws.amazon.com/blogs/aws/amazon-sagemaker-experiments-organize-track-and-compare-your-machine-learning-trainings/) to organize and track the muliple models.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook will demonstrate how SageMaker Training jobs can be used in a scalable fashion to kick off parallel training jobs. This has the advantage that jobs can be run in parallel without concerns about RAM or similair constraints. \n",
    "\n",
    "The underlying dataset used is a processed version of retrieved from here: https://healthdata.gov/dataset/medicare-hospital-spending-claim where we seek to determine average hospital Medicare spending based on certain features.\n",
    "\n",
    "In this workshop, we will deploy different models partitioned by state; where a seperate model is built based on what state in the USA the hospital is located it. We will register the models in the SageMaker Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sagemaker==2.74.0 sagemaker-experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load needed libraries and create a location where models and data will be located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas\n",
    "from random import random\n",
    "import s3fs\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from smexperiments.experiment import Experiment\n",
    "from sagemaker.s3 import S3Downloader\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker.s3 import S3Uploader, S3Downloader\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker\n",
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "import time\n",
    "\n",
    "logger = logging.getLogger(\"log\")\n",
    "# set logs if not done already\n",
    "if not logger.handlers:\n",
    "    logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "BUCKET = sagemaker_session.default_bucket()\n",
    "PREFIX = \"multiple_models_\" + str(random()).replace(\".\", \"\")\n",
    "print(f\"The S3 location is {BUCKET}/{PREFIX}\")\n",
    "WORKING_DIR = os.getcwd()\n",
    "# logger.info(f\"The bucket is {BUCKET}\")\n",
    "# logger.info(f\"The prefix is is {PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for data\n",
    "os.makedirs(os.path.join(WORKING_DIR, \"data\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3Downloader.download(\n",
    "    s3_uri=\"s3://aws-hcls-ml/workshop/immersion_day_workshop_data_DO_NOT_DELETE/data/processed_Medicare_Hospital_Spending_by_Claim.csv\",\n",
    "    local_path=\"data\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pandas.read_csv(\"data/processed_Medicare_Hospital_Spending_by_Claim.csv\")\n",
    "df_1 = df_1.rename(columns={\"Avg_Hosp\": \"truth\"})\n",
    "df_1 = df_1.drop(columns=\"Facility ID\")\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new SageMaker experiment to track our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_date = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "experiment_name = f\"medicare-hospital-spending-{create_date}\"\n",
    "medicare_spend_experiment = Experiment.create(\n",
    "    experiment_name=experiment_name,\n",
    "    description=\"Predict Medicare hospital spending\",\n",
    "    tags=[{\"Key\": \"Creator\", \"Value\": \"Alejandro Rosalez\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for training script\n",
    "os.makedirs(os.path.join(WORKING_DIR, \"scripts\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scripts/train.py\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "logger = logging.getLogger(\"log\")\n",
    "#set logs if not done already\n",
    "if not logger.handlers:\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Sagemaker specific arguments. Defaults are set in the environment variables.\n",
    "    parser.add_argument(\"--output-data-dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    df=pd.read_csv(os.path.join(args.train, \"train_data.csv\"), engine=\"python\")\n",
    "    train_data, test_data = train_test_split(df, test_size=0.2)\n",
    "\n",
    "    # labels are in the first column\n",
    "    train_y = train_data[\"truth\"]\n",
    "    train_X = train_data[train_data.columns[1:len(train_data)]]\n",
    "    test_y = test_data[\"truth\"]\n",
    "    test_X = test_data[test_data.columns[1:len(test_data)]]    \n",
    "    \n",
    "    # Now use scikit-learn's MLP MLPRegressor to train the model.\n",
    "    regr = MLPRegressor(random_state=1, max_iter=500).fit(train_X, train_y)\n",
    "    print(regr.loss_curve_)\n",
    "    \n",
    "    # Evaluate model performance on test data\n",
    "    print(\"Evaluating model\")\n",
    "    # Initialize the experiment tracker\n",
    "    try:\n",
    "        my_tracker = Tracker.load()\n",
    "    except ValueError:\n",
    "        my_tracker = Tracker.create()\n",
    "               \n",
    "        \n",
    "    # Evaluate training loss\n",
    "    for epoch, value in enumerate(regr.loss_curve_):\n",
    "        my_tracker.log_metric(metric_name=\"train:loss\", value=value, iteration_number=epoch)\n",
    "    \n",
    "    # Evaluate test performance\n",
    "    test_predictions = regr.predict(test_X)\n",
    "    rmse = mean_squared_error(test_y, test_predictions)\n",
    "    my_tracker.log_metric(metric_name=\"test:rmse\", value=rmse)  \n",
    "    print(f\"RMSE: {rmse:.2f}\")        \n",
    "    my_tracker.close()    \n",
    "\n",
    "    # Save the coefficients of the trained regression model\n",
    "    joblib.dump(regr, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialized and return fitted model\n",
    "\n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"\n",
    "    regr = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return regr\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"return the class and the probability of the class\"\"\"\n",
    "    #logger.info(type(input_data))\n",
    "    #logger.info(input_data)\n",
    "    if np.array(input_data).ndim==1: #if only one dimension, reshape\n",
    "        input_data=np.array(input_data).reshape(1,-1)\n",
    "    prediction = model.predict(input_data)\n",
    "    #pred_prob = model.predict_proba(input_data) #a numpy array\n",
    "    return np.array(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"sagemaker-experiments\\njoblib\" > scripts/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Uncomment to test training script locally\n",
    "# df_1.to_csv(\"data/train_data.csv\", index=False)\n",
    "# os.makedirs(os.path.join(WORKING_DIR, \"output\"), exist_ok=True)\n",
    "# !python scripts/train.py --output-data-dir \"output\" \\\n",
    "#     --model-dir \"output\" \\\n",
    "#     --train \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Training\n",
    "Now we will kick of the training jobs. Since we are creating multiple jobs, we will copy each file to a unique location in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the estimator\n",
    "sklearn = SKLearn(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"scripts\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    role=role,\n",
    "    py_version=\"py3\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    enable_sagemaker_metrics=True,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_states = list(set(df_1[\"State\"].tolist()))\n",
    "all_jobs_info = []\n",
    "for i in range(0, 10):  # create models for the first 10 states only\n",
    "    the_state = the_states[i]\n",
    "    df_just_that_state = df_1[df_1[\"State\"] == the_state]\n",
    "    df_just_that_state.to_csv(\"data/train_data.csv\", index=False)\n",
    "    just_state_prefix = f\"state-{str(the_state).zfill(2)}-\" + str(random()).replace(\n",
    "        \".\", \"\"\n",
    "    )\n",
    "\n",
    "    # Create a trial and associate it to the experiment defined above\n",
    "    rf_trial = Trial.create(\n",
    "        trial_name=just_state_prefix, experiment_name=experiment_name\n",
    "    )\n",
    "    # Upload the training data to S3\n",
    "    S3Uploader.upload(\n",
    "        local_path=\"data/train_data.csv\",\n",
    "        desired_s3_uri=f\"s3://{BUCKET}/{PREFIX}/{just_state_prefix}/train_data.csv\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    "\n",
    "    job_name = \"training-job-\" + just_state_prefix\n",
    "    model_info = sklearn.fit(\n",
    "        {\"train\": f\"s3://{BUCKET}/{PREFIX}/{just_state_prefix}/train_data.csv\"},\n",
    "        experiment_config={\n",
    "            \"TrialName\": just_state_prefix,\n",
    "            \"TrialComponentDisplayName\": f\"{just_state_prefix}-train\",\n",
    "        },\n",
    "        wait=False,\n",
    "        job_name=job_name,\n",
    "    )\n",
    "    all_jobs_info.append(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "def training_results(all_jobs_info):\n",
    "    return [\n",
    "        sm_client.describe_training_job(TrainingJobName=i) for i in all_jobs_info\n",
    "    ]\n",
    "\n",
    "for job_result in training_results(all_jobs_info):\n",
    "    print(f\"{job_result['TrainingJobName']} - {job_result['TrainingJobStatus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing on, wait for all of the model training jobs to complete. You can track them in either the SageMaker console, or the Experiments view in SageMaker Studio, or re-run the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register the Models\n",
    "Now that the S3 model artifacts have been created, we will register them with the SageMaker Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model artifact locations\n",
    "the_training_results = training_results(all_jobs_info)\n",
    "the_model_artifacts = [\n",
    "    the_training_results[i][\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "    for i in range(0, len(the_training_results))\n",
    "]\n",
    "the_model_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register a model package group\n",
    "model_package_group_name = \"hospital-spending-states-models\" + str(round(time.time()))\n",
    "model_package_group_input_dict = {\n",
    "    \"ModelPackageGroupName\": model_package_group_name,\n",
    "    \"ModelPackageGroupDescription\": \"Group of Models for Hospital Spending By State\",\n",
    "}\n",
    "create_model_pacakge_group_response = sm_client.create_model_package_group(\n",
    "    **model_package_group_input_dict\n",
    ")\n",
    "print(\n",
    "    \"ModelPackageGroup Arn : {}\".format(\n",
    "        create_model_pacakge_group_response[\"ModelPackageGroupArn\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model package versions (one per state)\n",
    "all_model_arns = []\n",
    "for i in range(0, len(all_jobs_info)):\n",
    "    create_model_package_input_dict = {\n",
    "        \"ModelPackageGroupName\": model_package_group_name,\n",
    "        \"ModelPackageDescription\": f\"State {i} Model\",\n",
    "        \"ModelApprovalStatus\": \"PendingManualApproval\",\n",
    "        \"InferenceSpecification\": {\n",
    "            \"Containers\": [\n",
    "                {\"Image\": sklearn.image_uri, \"ModelDataUrl\": the_model_artifacts[i]}\n",
    "            ],\n",
    "            \"SupportedContentTypes\": [\"text/csv\"],\n",
    "            \"SupportedResponseMIMETypes\": [\"text/csv\"],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    create_mode_package_response = sm_client.create_model_package(\n",
    "        **create_model_package_input_dict\n",
    "    )\n",
    "    model_package_arn = create_mode_package_response[\"ModelPackageArn\"]\n",
    "    all_model_arns.append(model_package_arn)\n",
    "    print(\"ModelPackage Version ARN : {}\".format(model_package_arn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model package registration has completed, let's approve the first model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_update_input_dict = {\n",
    "    \"ModelPackageArn\": all_model_arns[0],\n",
    "    \"ModelApprovalStatus\": \"Approved\",\n",
    "}\n",
    "model_package_update_response = sm_client.update_model_package(\n",
    "    **model_package_update_input_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will deploy the first model to an endpoint for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model = SKLearnModel(\n",
    "    model_data=the_model_artifacts[0],\n",
    "    role=role,\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"scripts\",\n",
    "    framework_version=\"0.23-1\",\n",
    ")\n",
    "\n",
    "predictor = sklearn_model.deploy(instance_type=\"ml.c5.xlarge\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model deployment will take about 5 minutes to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the endpoint with sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, try calling the endpoing using the `predict` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_payload = df_1.iloc()[0][1:].tolist()\n",
    "predictor.predict(data=the_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, try calling the endpoint via http using the `invoke_endppoint` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(the_payload),\n",
    ")\n",
    "result = response[\"Body\"]\n",
    "final_prediction = json.loads(result.read())[0]\n",
    "print(final_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
